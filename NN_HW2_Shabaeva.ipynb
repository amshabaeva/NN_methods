{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №2 (построение собственных сетей CNN + FFN)\n",
    "\n",
    "#### Настя Шабаева, БКЛ181\n",
    "\n",
    "### Импорт необходимого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "import ipdb\n",
    "from torchmetrics import F1\n",
    "from torchmetrics.functional import f1, recall, accuracy, precision\n",
    "\n",
    "import gensim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных\n",
    "\n",
    "Данные я скачала отдельно (два файла 'positive.csv' и 'negative.csv'). Сначала достаем данные из файла (берем только сам текст и тон (положительный твит или отрицательный)) и объединяем все данные в одну переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = pd.read_csv('positive.csv', encoding='utf-8', sep=';', header=None,  names=[0,1,2,'text','tone',5,6,7,8,9,10,11])\n",
    "neg_tweets = pd.read_csv('negative.csv', encoding='utf-8', sep=';', header=None, names=[0,1,2,'text','tone',5,6,7,8,9,10,11] )\n",
    "neg_tweets['tone'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226834\n"
     ]
    }
   ],
   "source": [
    "all_tweets_data = pos_tweets.append(neg_tweets)\n",
    "print(len(all_tweets_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перемешиваем данные и берем только первые 100000 твитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = shuffle(all_tweets_data[['text','tone']])[:100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим выборку на обучающую и тестовую (в соотношении 9 к 1). Дальше пример первых 10 твитов обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences = train_test_split(tweets_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21745</td>\n",
       "      <td>RT @massquerrade: @MeetPrettyShit твой юн &amp;lt;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32399</td>\n",
       "      <td>@serialfandom @iamsolitude ладно я хочу спать....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13383</td>\n",
       "      <td>@Ricosmosss да вообщем ничего важного с: мне н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24014</td>\n",
       "      <td>RT @Odkhuu_D: @nominod багшийг дуурайгаарай:) ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95622</td>\n",
       "      <td>@syn_thesi_zer ахаха, нет, я просто опоздал сн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68939</td>\n",
       "      <td>RT @kota_Oo_oO: @loss_courage #Снаступающимтви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110492</td>\n",
       "      <td>@RadiopAshA Ну не испокон. Только в этом тысяч...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90556</td>\n",
       "      <td>RT @_Do_or_Die__: скорость меньше\\nчем у джаст...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90928</td>\n",
       "      <td>Каждый вечер об этом говорю:D да на самом деле...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57240</td>\n",
       "      <td>Как сказал Артём Фомичев, что колонка скоро бу...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  tone\n",
       "21745   RT @massquerrade: @MeetPrettyShit твой юн &lt;...     1\n",
       "32399   @serialfandom @iamsolitude ладно я хочу спать....     1\n",
       "13383   @Ricosmosss да вообщем ничего важного с: мне н...     1\n",
       "24014   RT @Odkhuu_D: @nominod багшийг дуурайгаарай:) ...     1\n",
       "95622   @syn_thesi_zer ахаха, нет, я просто опоздал сн...     1\n",
       "68939   RT @kota_Oo_oO: @loss_courage #Снаступающимтви...     0\n",
       "110492  @RadiopAshA Ну не испокон. Только в этом тысяч...     1\n",
       "90556   RT @_Do_or_Die__: скорость меньше\\nчем у джаст...     0\n",
       "90928   Каждый вечер об этом говорю:D да на самом деле...     1\n",
       "57240   Как сказал Артём Фомичев, что колонка скоро бу...     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция простейшего препроцессинга текстов: делим твиты на токены, приводим к нижнему регистру и удаляем всю пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь уникальных токенов, а потом оставляем только те токены, которые встретились больше 2 раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего уникальных токенов: 202799\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in tweets_data['text']:\n",
    "    vocab.update(preprocess(text))\n",
    "print('всего уникальных токенов:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "уникальных токенов, втретившихся больше 2 раз: 32470\n"
     ]
    }
   ],
   "source": [
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 2:\n",
    "        filtered_vocab.add(word)\n",
    "print('уникальных токенов, втретившихся больше 2 раз:', len(filtered_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь, в ключах которого токены (встретившиеся больше 2 раз), в значениях их индексы word2id, для спецсимвола паддинга дефолтный индекс - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32471\n"
     ]
    }
   ],
   "source": [
    "print(len(word2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем обратный словарь для того, чтобы раскодировать последовательность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если возможно, просим торч использовать gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектура I\n",
    "### Приведение данных в вид, подходящий для \"отправки\" в нейросеть\n",
    "\n",
    "Приводим данные в такой вид, чтобы их потом можно было отдать нейросети. То есть создаем класс TweetsDataset, наследующийся от Dataset. В нем есть несколько обязательных методов, метод, который делает минимальный препроцессинг текста (отдельно такой метод уже создавался, когда собирали словарь word2id), и метод, в котором добавляются паддинги, в котором значения, которые мы будем предсказваться, представяляюся в виде тензора)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, word2id, DEVICE):\n",
    "        self.dataset = dataset['text'].values\n",
    "        self.word2id = word2id\n",
    "        self.length = dataset.shape[0]\n",
    "        self.target = dataset['tone'].values\n",
    "        self.device = DEVICE\n",
    "\n",
    "    def __len__(self): #это обязательный метод, он должен уметь считать длину датасета\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index): #еще один обязательный метод. По индексу возвращает элемент выборки\n",
    "        tokens = self.preprocess(self.dataset[index]) # токенизируем\n",
    "        ids = torch.LongTensor([self.word2id[token] for token in tokens if token in self.word2id])\n",
    "        y = [self.target[index]]\n",
    "        return ids, y\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        tokens = text.lower().split()\n",
    "        tokens = [token.strip(punctuation) for token in tokens]\n",
    "        tokens = [token for token in tokens if token]\n",
    "        return tokens\n",
    "\n",
    "    def collate_fn(self, batch): #этот метод можно реализовывать и отдельно,\n",
    "    # он понадобится для DataLoader во время итерации по батчам\n",
    "        ids, y = list(zip(*batch))\n",
    "        padded_ids = pad_sequence(ids, batch_first=True).to(self.device)\n",
    "        #мы хотим применять BCELoss, он будет брать на вход predicted размера batch_size x 1 (так как для каждого семпла модель будет отдавать одно число), target размера batch_size x 1\n",
    "        y = torch.Tensor(y).to(self.device) # tuple ([1], [0], [1])  -> Tensor [[1.], [0.], [1.]] \n",
    "        return padded_ids, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучающей и для тестовой выборки создаем экземпляры Dataset (точнее того, класса, который наследует от него) и DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TweetsDataset(train_sentences, word2id, DEVICE)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_iterator = DataLoader(train_dataset, collate_fn = train_dataset.collate_fn, sampler=train_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TweetsDataset(val_sentences, word2id, DEVICE)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_iterator = DataLoader(val_dataset, collate_fn = val_dataset.collate_fn, sampler=val_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем саму модель\n",
    "\n",
    "В ней сначала создаются эмбеддинги; затем идут 2 разных сверточных слоя (в каждом разное количество фильтров и разный шаг у этих фильтров: на первом слое шаг - 2, на втором - 3; затем идет слой пуллинга; потом первая функция активации - ReLU, дальше скрытый линейный слой, сокращающий количество выходных нейронов до 1; после этого дропаут; а в конце вторая функция активации - сигмоида, которая выдает нам в результате вероятность. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        \n",
    "        super().__init__()          \n",
    "        # указываем в атрибутах класса, какие слои и активации нам понадобятся\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.bigrams = nn.Conv1d(in_channels=embedding_dim, out_channels=100, kernel_size=2, padding='same')\n",
    "        self.trigrams = nn.Conv1d(in_channels=embedding_dim, out_channels=80, kernel_size=3, padding='same')\n",
    "        self.next_conv = nn.Conv1d(in_channels=180, out_channels=90, kernel_size=3, padding='same')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden = nn.Linear(in_features=90, out_features=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, text): #необходимый метод,  в нем указываем, как именно связываются слои/активации между собой\n",
    "        # batch_size x seq_len\n",
    "        embedded = self.embedding(text)   # переводим последовательность индексов в последовательность эмбеддингов\n",
    "        # batch_size x seq_len x embedding_dim\n",
    "        embedded = embedded.transpose(1,2)\n",
    "        #batch_size x embedding_dim x seq_len\n",
    "    \n",
    "        feature_map_bigrams = self.dropout(self.relu(self.bigrams(embedded)))\n",
    "        #batch_size x filter_count2 x seq_len* \n",
    "        feature_map_trigrams = self.dropout(self.relu(self.trigrams(embedded)))\n",
    "        #batch_size x filter_count3 x seq_len*\n",
    "\n",
    "        concat = torch.cat((feature_map_bigrams, feature_map_trigrams), 1)  # конкатенация \"биграм\" и \"тиграм\"\n",
    "        next_conv = self.dropout(self.relu(self.next_conv(concat)))\n",
    "        \n",
    "        pooling = next_conv.max(2)[0]\n",
    "        \n",
    "        logits = self.hidden(pooling) \n",
    "        logits = self.out(logits)      \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции обучения и эвалюации \n",
    "\n",
    "В первой функции модель обучается: ходим по данным внутри батчей, подсчитываем градиенты, на их основе обновляем веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0 # для подсчета среднего лосса на всех батчах\n",
    "\n",
    "    model.train()  # ставим модель в обучение, явно указываем, что сейчас надо будет хранить градиенты у всех весов\n",
    "\n",
    "    for i, (texts, ys) in enumerate(iterator): #итерируемся по батчам\n",
    "        optimizer.zero_grad()  #обнуляем градиенты\n",
    "        preds = model(texts)  #прогоняем данные через модель\n",
    "        loss = criterion(preds, ys) #считаем значение функции потерь  \n",
    "        loss.backward() #считаем градиенты  \n",
    "        optimizer.step() #обновляем веса \n",
    "        epoch_loss += loss.item() #сохраняем значение функции потерь\n",
    "        if not (i + 1) % int(len(iterator)/5):\n",
    "            print(f'Train loss: {epoch_loss/i}')      \n",
    "    return  epoch_loss / len(iterator) # возвращаем среднее значение лосса по всей выборке\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой функции, можно сказать, происходит оценка модели: перемещаясь по батчам, по предсказаниям на тестовых данных считаем функцию потерь, f1, accuracy, precision и recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_metric_f1 = 0\n",
    "    epoch_metric_precision = 0\n",
    "    epoch_metric_recall = 0\n",
    "    epoch_metric_accuracy = 0\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for i, (texts, ys) in enumerate(iterator):   \n",
    "            preds = model(texts)  # делаем предсказания на тесте\n",
    "            loss = criterion(preds, ys)   # считаем значения функции ошибки для статистики  \n",
    "            epoch_loss += loss.item()\n",
    "            batch_metric_f1 = f1(preds.round().long(), ys.long(), ignore_index=0)\n",
    "            epoch_metric_f1 += batch_metric_f1\n",
    "            batch_metric_precision = precision(preds.round().long(), ys.long(), ignore_index=0)\n",
    "            epoch_metric_precision += batch_metric_precision\n",
    "            batch_metric_recall = recall(preds.round().long(), ys.long(), ignore_index=0)\n",
    "            epoch_metric_recall += batch_metric_recall\n",
    "            batch_metric_accuracy = accuracy(preds.round().long(), ys.long(), ignore_index=0)\n",
    "            epoch_metric_accuracy += batch_metric_accuracy\n",
    "\n",
    "            if not (i + 1) % int(len(iterator)/5):\n",
    "                print(f'Val loss: {epoch_loss/i}, Val f1: {epoch_metric_f1/i}, \\nVal accuracy: {epoch_metric_accuracy/i}, Val precision: {epoch_metric_precision/i}, Val recall: {epoch_metric_recall/i}\\n')\n",
    "        \n",
    "    return epoch_metric_f1 / len(iterator), epoch_metric_accuracy / len(iterator), epoch_metric_precision / len(iterator), epoch_metric_recall / len(iterator), epoch_loss / len(iterator) # возвращаем среднее значение по всей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем саму модель - экземпляр только что созданного класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(len(word2id), 180)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение и эвалюацию модели (на 20 эпохах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting Epoch 0\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n",
      "  self.padding, self.dilation, self.groups)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7704554907977581\n",
      "Train loss: 0.7223148634939482\n",
      "Train loss: 0.699070714712143\n",
      "Train loss: 0.6841595306325314\n",
      "Train loss: 0.6730034599701563\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6582629196345806, Val f1: 0.6918991804122925, \n",
      "Val accuracy: 0.6830806136131287, Val precision: 0.7013741731643677, Val recall: 0.6830806136131287\n",
      "\n",
      "Val loss: 0.6376629598212965, Val f1: 0.6731104850769043, \n",
      "Val accuracy: 0.6633949875831604, Val precision: 0.6836104393005371, Val recall: 0.6633949875831604\n",
      "\n",
      "Val loss: 0.6302162182331085, Val f1: 0.6693253517150879, \n",
      "Val accuracy: 0.6574370861053467, Val precision: 0.6820591688156128, Val recall: 0.6574370861053467\n",
      "\n",
      "Val loss: 0.6267329454421997, Val f1: 0.6647940874099731, \n",
      "Val accuracy: 0.6516832709312439, Val precision: 0.6789161562919617, Val recall: 0.6516832709312439\n",
      "\n",
      "Val loss: 0.6239372733093443, Val f1: 0.6641789674758911, \n",
      "Val accuracy: 0.6513563394546509, Val precision: 0.6779831051826477, Val recall: 0.6513563394546509\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.2311121225357056, Val f1: 1.329866886138916, \n",
      "Val accuracy: 1.3143428564071655, Val precision: 1.345762014389038, Val recall: 1.3143428564071655\n",
      "\n",
      "Val loss: 0.818977971871694, Val f1: 0.8900275230407715, \n",
      "Val accuracy: 0.8753474354743958, Val precision: 0.9056932330131531, Val recall: 0.8753474354743958\n",
      "\n",
      "Val loss: 0.7402718901634217, Val f1: 0.7845474481582642, \n",
      "Val accuracy: 0.7736019492149353, Val precision: 0.796159029006958, Val recall: 0.7736019492149353\n",
      "\n",
      "Val loss: 0.7057363476072039, Val f1: 0.7450515627861023, \n",
      "Val accuracy: 0.7306864857673645, Val precision: 0.7604016065597534, Val recall: 0.7306864857673645\n",
      "\n",
      "Val loss: 0.6880821122063531, Val f1: 0.722308337688446, \n",
      "Val accuracy: 0.707630455493927, Val precision: 0.7379330992698669, Val recall: 0.707630455493927\n",
      "\n",
      "\n",
      "starting Epoch 1\n",
      "Training...\n",
      "Train loss: 0.6473669186234474\n",
      "Train loss: 0.6263851324717203\n",
      "Train loss: 0.6154341232776642\n",
      "Train loss: 0.6093396989267263\n",
      "Train loss: 0.6046360972381774\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6148717366158962, Val f1: 0.7261869311332703, \n",
      "Val accuracy: 0.670157253742218, Val precision: 0.7933698296546936, Val recall: 0.670157253742218\n",
      "\n",
      "Val loss: 0.5963411963347233, Val f1: 0.7046675682067871, \n",
      "Val accuracy: 0.6499637961387634, Val precision: 0.7699883580207825, Val recall: 0.6499637961387634\n",
      "\n",
      "Val loss: 0.5894737267494201, Val f1: 0.6979296207427979, \n",
      "Val accuracy: 0.644451379776001, Val precision: 0.7616764307022095, Val recall: 0.644451379776001\n",
      "\n",
      "Val loss: 0.5861775154498086, Val f1: 0.6951616406440735, \n",
      "Val accuracy: 0.6424993276596069, Val precision: 0.757757842540741, Val recall: 0.6424993276596069\n",
      "\n",
      "Val loss: 0.5833635245050702, Val f1: 0.6959577798843384, \n",
      "Val accuracy: 0.6436260342597961, Val precision: 0.7580784559249878, Val recall: 0.6436260342597961\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1696721315383911, Val f1: 1.3363707065582275, \n",
      "Val accuracy: 1.250641107559204, Val precision: 1.4349238872528076, Val recall: 1.250641107559204\n",
      "\n",
      "Val loss: 0.7792835632960001, Val f1: 0.8935489058494568, \n",
      "Val accuracy: 0.8311660885810852, Val precision: 0.9664602875709534, Val recall: 0.8311660885810852\n",
      "\n",
      "Val loss: 0.703250527381897, Val f1: 0.7950533628463745, \n",
      "Val accuracy: 0.7395087480545044, Val precision: 0.8598865270614624, Val recall: 0.7395087480545044\n",
      "\n",
      "Val loss: 0.6718664169311523, Val f1: 0.7566124796867371, \n",
      "Val accuracy: 0.6999195218086243, Val precision: 0.8236857056617737, Val recall: 0.6999195218086243\n",
      "\n",
      "Val loss: 0.6557534601953294, Val f1: 0.7328841090202332, \n",
      "Val accuracy: 0.676832914352417, Val precision: 0.7993902564048767, Val recall: 0.676832914352417\n",
      "\n",
      "\n",
      "starting Epoch 2\n",
      "Training...\n",
      "Train loss: 0.5997630059719086\n",
      "Train loss: 0.5785328185919559\n",
      "Train loss: 0.5702642571926116\n",
      "Train loss: 0.565799410663434\n",
      "Train loss: 0.5613430646203813\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5733285173773766, Val f1: 0.7984272241592407, \n",
      "Val accuracy: 0.786385178565979, Val precision: 0.8110788464546204, Val recall: 0.786385178565979\n",
      "\n",
      "Val loss: 0.5546090747370864, Val f1: 0.7745355367660522, \n",
      "Val accuracy: 0.764657199382782, Val precision: 0.7849257588386536, Val recall: 0.764657199382782\n",
      "\n",
      "Val loss: 0.5494524419307709, Val f1: 0.7645387053489685, \n",
      "Val accuracy: 0.7548952698707581, Val precision: 0.7747610211372375, Val recall: 0.7548952698707581\n",
      "\n",
      "Val loss: 0.5469279298141821, Val f1: 0.7596866488456726, \n",
      "Val accuracy: 0.7495576739311218, Val precision: 0.7704504132270813, Val recall: 0.7495576739311218\n",
      "\n",
      "Val loss: 0.5451514962173644, Val f1: 0.7567927241325378, \n",
      "Val accuracy: 0.74738609790802, Val precision: 0.7668004631996155, Val recall: 0.74738609790802\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1156598329544067, Val f1: 1.4448943138122559, \n",
      "Val accuracy: 1.461483120918274, Val precision: 1.4290964603424072, Val recall: 1.461483120918274\n",
      "\n",
      "Val loss: 0.7459830840428671, Val f1: 0.9524075388908386, \n",
      "Val accuracy: 0.9479560852050781, Val precision: 0.9581169486045837, Val recall: 0.9479560852050781\n",
      "\n",
      "Val loss: 0.6730341792106629, Val f1: 0.8515127897262573, \n",
      "Val accuracy: 0.8479915857315063, Val precision: 0.8557964563369751, Val recall: 0.8479915857315063\n",
      "\n",
      "Val loss: 0.6428431698254177, Val f1: 0.812904953956604, \n",
      "Val accuracy: 0.8070362210273743, Val precision: 0.8194682002067566, Val recall: 0.8070362210273743\n",
      "\n",
      "Val loss: 0.62720345126258, Val f1: 0.7878822684288025, \n",
      "Val accuracy: 0.781324028968811, Val precision: 0.7950423359870911, Val recall: 0.781324028968811\n",
      "\n",
      "\n",
      "starting Epoch 3\n",
      "Training...\n",
      "Train loss: 0.5488592069596052\n",
      "Train loss: 0.5306184454397722\n",
      "Train loss: 0.525384577512741\n",
      "Train loss: 0.5209565629710012\n",
      "Train loss: 0.5197310071615946\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5412646904587746, Val f1: 0.8212831020355225, \n",
      "Val accuracy: 0.8095511794090271, Val precision: 0.8334802389144897, Val recall: 0.8095511794090271\n",
      "\n",
      "Val loss: 0.5219953195615248, Val f1: 0.8006533980369568, \n",
      "Val accuracy: 0.7859816551208496, Val precision: 0.8161249160766602, Val recall: 0.7859816551208496\n",
      "\n",
      "Val loss: 0.5174365639686584, Val f1: 0.7910912036895752, \n",
      "Val accuracy: 0.7761838436126709, Val precision: 0.8068311214447021, Val recall: 0.7761838436126709\n",
      "\n",
      "Val loss: 0.5144901555865559, Val f1: 0.7871516346931458, \n",
      "Val accuracy: 0.7719922661781311, Val precision: 0.8031715154647827, Val recall: 0.7719922661781311\n",
      "\n",
      "Val loss: 0.5120962620491073, Val f1: 0.7858347296714783, \n",
      "Val accuracy: 0.771243155002594, Val precision: 0.8012965321540833, Val recall: 0.771243155002594\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0776161551475525, Val f1: 1.4838378429412842, \n",
      "Val accuracy: 1.4827499389648438, Val precision: 1.4853324890136719, Val recall: 1.4827499389648438\n",
      "\n",
      "Val loss: 0.7215290268262228, Val f1: 0.9776700139045715, \n",
      "Val accuracy: 0.9632794260978699, Val precision: 0.9934282302856445, Val recall: 0.9632794260978699\n",
      "\n",
      "Val loss: 0.6502673625946045, Val f1: 0.8760812878608704, \n",
      "Val accuracy: 0.8639699816703796, Val precision: 0.8890994787216187, Val recall: 0.8639699816703796\n",
      "\n",
      "Val loss: 0.6216912354741778, Val f1: 0.8336085081100464, \n",
      "Val accuracy: 0.820853590965271, Val precision: 0.8472610712051392, Val recall: 0.820853590965271\n",
      "\n",
      "Val loss: 0.6073892845047845, Val f1: 0.804155707359314, \n",
      "Val accuracy: 0.7895523905754089, Val precision: 0.8197574615478516, Val recall: 0.7895523905754089\n",
      "\n",
      "\n",
      "starting Epoch 4\n",
      "Training...\n",
      "Train loss: 0.5133381970226765\n",
      "Train loss: 0.49735605445775116\n",
      "Train loss: 0.4897335875034332\n",
      "Train loss: 0.48894459676386703\n",
      "Train loss: 0.4863618874833697\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.4994173590093851, Val f1: 0.849962592124939, \n",
      "Val accuracy: 0.8412655591964722, Val precision: 0.8591191172599792, Val recall: 0.8412655591964722\n",
      "\n",
      "Val loss: 0.48328277920231677, Val f1: 0.8265442848205566, \n",
      "Val accuracy: 0.8200017213821411, Val precision: 0.8335356116294861, Val recall: 0.8200017213821411\n",
      "\n",
      "Val loss: 0.479437398314476, Val f1: 0.8176950812339783, \n",
      "Val accuracy: 0.8113728165626526, Val precision: 0.8244328498840332, Val recall: 0.8113728165626526\n",
      "\n",
      "Val loss: 0.4763331715740375, Val f1: 0.8145044445991516, \n",
      "Val accuracy: 0.8082679510116577, Val precision: 0.8211804032325745, Val recall: 0.8082679510116577\n",
      "\n",
      "Val loss: 0.47589160679351716, Val f1: 0.8112446069717407, \n",
      "Val accuracy: 0.805556058883667, Val precision: 0.8173554539680481, Val recall: 0.805556058883667\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0457107424736023, Val f1: 1.504270076751709, \n",
      "Val accuracy: 1.5060126781463623, Val precision: 1.502761960029602, Val recall: 1.5060126781463623\n",
      "\n",
      "Val loss: 0.7027666171391805, Val f1: 0.9875805974006653, \n",
      "Val accuracy: 0.978668212890625, Val precision: 0.9972378611564636, Val recall: 0.978668212890625\n",
      "\n",
      "Val loss: 0.6322793006896973, Val f1: 0.8890813589096069, \n",
      "Val accuracy: 0.8852168321609497, Val precision: 0.8934076428413391, Val recall: 0.8852168321609497\n",
      "\n",
      "Val loss: 0.6044707979474749, Val f1: 0.8466736674308777, \n",
      "Val accuracy: 0.8427045941352844, Val precision: 0.8510618209838867, Val recall: 0.8427045941352844\n",
      "\n",
      "Val loss: 0.5899500979317559, Val f1: 0.819106936454773, \n",
      "Val accuracy: 0.8125406503677368, Val precision: 0.8261825442314148, Val recall: 0.8125406503677368\n",
      "\n",
      "\n",
      "starting Epoch 5\n",
      "Training...\n",
      "Train loss: 0.4760701283812523\n",
      "Train loss: 0.46185498255671875\n",
      "Train loss: 0.4573148959875107\n",
      "Train loss: 0.4529264738310629\n",
      "Train loss: 0.4525695028049605\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.4751612450927496, Val f1: 0.8713345527648926, \n",
      "Val accuracy: 0.8537797331809998, Val precision: 0.8899211883544922, Val recall: 0.8537797331809998\n",
      "\n",
      "Val loss: 0.45813705614118866, Val f1: 0.8471713662147522, \n",
      "Val accuracy: 0.8328612446784973, Val precision: 0.8623889088630676, Val recall: 0.8328612446784973\n",
      "\n",
      "Val loss: 0.45303084313869474, Val f1: 0.8372108340263367, \n",
      "Val accuracy: 0.8240686655044556, Val precision: 0.8511447310447693, Val recall: 0.8240686655044556\n",
      "\n",
      "Val loss: 0.45093646734508114, Val f1: 0.8325713276863098, \n",
      "Val accuracy: 0.8194786906242371, Val precision: 0.8465101718902588, Val recall: 0.8194786906242371\n",
      "\n",
      "Val loss: 0.449557411528769, Val f1: 0.8305313587188721, \n",
      "Val accuracy: 0.8169054985046387, Val precision: 0.8450111150741577, Val recall: 0.8169054985046387\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.021484911441803, Val f1: 1.5078519582748413, \n",
      "Val accuracy: 1.4965250492095947, Val precision: 1.5197006464004517, Val recall: 1.4965250492095947\n",
      "\n",
      "Val loss: 0.6894528865814209, Val f1: 0.9906474947929382, \n",
      "Val accuracy: 0.9710304141044617, Val precision: 1.0118956565856934, Val recall: 0.9710304141044617\n",
      "\n",
      "Val loss: 0.6205096960067749, Val f1: 0.8891693949699402, \n",
      "Val accuracy: 0.8750273585319519, Val precision: 0.9043346643447876, Val recall: 0.8750273585319519\n",
      "\n",
      "Val loss: 0.5936372876167297, Val f1: 0.8468077778816223, \n",
      "Val accuracy: 0.8330201506614685, Val precision: 0.8615860939025879, Val recall: 0.8330201506614685\n",
      "\n",
      "Val loss: 0.5798677934540643, Val f1: 0.8172786235809326, \n",
      "Val accuracy: 0.8001845479011536, Val precision: 0.8358404636383057, Val recall: 0.8001845479011536\n",
      "\n",
      "\n",
      "starting Epoch 6\n",
      "Training...\n",
      "Train loss: 0.43984926491975784\n",
      "Train loss: 0.42982937621347833\n",
      "Train loss: 0.4258214086294174\n",
      "Train loss: 0.4245531002977001\n",
      "Train loss: 0.4238331498844283\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.43837638944387436, Val f1: 0.8926841616630554, \n",
      "Val accuracy: 0.8865009546279907, Val precision: 0.8990637063980103, Val recall: 0.8865009546279907\n",
      "\n",
      "Val loss: 0.4268077422272075, Val f1: 0.866301417350769, \n",
      "Val accuracy: 0.8602215051651001, Val precision: 0.8726529479026794, Val recall: 0.8602215051651001\n",
      "\n",
      "Val loss: 0.42272116005420685, Val f1: 0.8573867678642273, \n",
      "Val accuracy: 0.8519693613052368, Val precision: 0.8631273508071899, Val recall: 0.8519693613052368\n",
      "\n",
      "Val loss: 0.41990403942207793, Val f1: 0.8535266518592834, \n",
      "Val accuracy: 0.8473854660987854, Val precision: 0.8600419759750366, Val recall: 0.8473854660987854\n",
      "\n",
      "Val loss: 0.4184160069340751, Val f1: 0.8504043817520142, \n",
      "Val accuracy: 0.8446504473686218, Val precision: 0.8564897179603577, Val recall: 0.8446504473686218\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0062650442123413, Val f1: 1.514058232307434, \n",
      "Val accuracy: 1.5134057998657227, Val precision: 1.5147463083267212, Val recall: 1.5134057998657227\n",
      "\n",
      "Val loss: 0.6809293429056803, Val f1: 0.9965593218803406, \n",
      "Val accuracy: 0.9880945086479187, Val precision: 1.0056370496749878, Val recall: 0.9880945086479187\n",
      "\n",
      "Val loss: 0.6120806097984314, Val f1: 0.8954682350158691, \n",
      "Val accuracy: 0.8900917172431946, Val precision: 0.9012130498886108, Val recall: 0.8900917172431946\n",
      "\n",
      "Val loss: 0.5856848955154419, Val f1: 0.8536115288734436, \n",
      "Val accuracy: 0.8472487330436707, Val precision: 0.8604519963264465, Val recall: 0.8472487330436707\n",
      "\n",
      "Val loss: 0.5721646282407973, Val f1: 0.8248778581619263, \n",
      "Val accuracy: 0.8157514333724976, Val precision: 0.8346341848373413, Val recall: 0.8157514333724976\n",
      "\n",
      "\n",
      "starting Epoch 7\n",
      "Training...\n",
      "Train loss: 0.4062131382524967\n",
      "Train loss: 0.39785701307383453\n",
      "Train loss: 0.39571950495243075\n",
      "Train loss: 0.3967442178904121\n",
      "Train loss: 0.39770728810912087\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.4181731101125479, Val f1: 0.9065998196601868, \n",
      "Val accuracy: 0.9024678468704224, Val precision: 0.9110632538795471, Val recall: 0.9024678468704224\n",
      "\n",
      "Val loss: 0.4043017616777709, Val f1: 0.8788946866989136, \n",
      "Val accuracy: 0.8739414811134338, Val precision: 0.8841179609298706, Val recall: 0.8739414811134338\n",
      "\n",
      "Val loss: 0.3986339497566223, Val f1: 0.8715971112251282, \n",
      "Val accuracy: 0.8651381731033325, Val precision: 0.8783657550811768, Val recall: 0.8651381731033325\n",
      "\n",
      "Val loss: 0.3966954964310376, Val f1: 0.8661271333694458, \n",
      "Val accuracy: 0.8613696694374084, Val precision: 0.8711991310119629, Val recall: 0.8613696694374084\n",
      "\n",
      "Val loss: 0.395143656148797, Val f1: 0.8640235662460327, \n",
      "Val accuracy: 0.8596514463424683, Val precision: 0.8686778545379639, Val recall: 0.8596514463424683\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 0.9975555241107941, Val f1: 1.521000623703003, \n",
      "Val accuracy: 1.535361886024475, Val precision: 1.5070688724517822, Val recall: 1.535361886024475\n",
      "\n",
      "Val loss: 0.67799112200737, Val f1: 1.002813458442688, \n",
      "Val accuracy: 1.0030041933059692, Val precision: 1.003193974494934, Val recall: 1.0030041933059692\n",
      "\n",
      "Val loss: 0.6103265702724456, Val f1: 0.8992002606391907, \n",
      "Val accuracy: 0.8998950719833374, Val precision: 0.8989578485488892, Val recall: 0.8998950719833374\n",
      "\n",
      "Val loss: 0.5842721845422473, Val f1: 0.856415331363678, \n",
      "Val accuracy: 0.8553093075752258, Val precision: 0.8581557273864746, Val recall: 0.8553093075752258\n",
      "\n",
      "Val loss: 0.5706201692422231, Val f1: 0.8270015716552734, \n",
      "Val accuracy: 0.8235615491867065, Val precision: 0.8310866951942444, Val recall: 0.8235615491867065\n",
      "\n",
      "\n",
      "starting Epoch 8\n",
      "Training...\n",
      "Train loss: 0.3871013317257166\n",
      "Train loss: 0.37427009416349005\n",
      "Train loss: 0.3707825392484665\n",
      "Train loss: 0.3709053303768386\n",
      "Train loss: 0.3727932341751598\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.3938310481607914, Val f1: 0.9189435243606567, \n",
      "Val accuracy: 0.9203134775161743, Val precision: 0.9177322387695312, Val recall: 0.9203134775161743\n",
      "\n",
      "Val loss: 0.38020876411235693, Val f1: 0.8925204873085022, \n",
      "Val accuracy: 0.8931087255477905, Val precision: 0.8922033309936523, Val recall: 0.8931087255477905\n",
      "\n",
      "Val loss: 0.37587609231472013, Val f1: 0.8855797648429871, \n",
      "Val accuracy: 0.8852663636207581, Val precision: 0.886182963848114, Val recall: 0.8852663636207581\n",
      "\n",
      "Val loss: 0.3739607436443443, Val f1: 0.8814757466316223, \n",
      "Val accuracy: 0.8809865713119507, Val precision: 0.88221675157547, Val recall: 0.8809865713119507\n",
      "\n",
      "Val loss: 0.37317623588300886, Val f1: 0.8785367012023926, \n",
      "Val accuracy: 0.8775671124458313, Val precision: 0.8797510862350464, Val recall: 0.8775671124458313\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 0.9954974055290222, Val f1: 1.5170259475708008, \n",
      "Val accuracy: 1.5252833366394043, Val precision: 1.5089174509048462, Val recall: 1.5252833366394043\n",
      "\n",
      "Val loss: 0.6808367768923441, Val f1: 0.9975190758705139, \n",
      "Val accuracy: 0.9925952553749084, Val precision: 1.0029712915420532, Val recall: 0.9925952553749084\n",
      "\n",
      "Val loss: 0.61124307513237, Val f1: 0.8987236022949219, \n",
      "Val accuracy: 0.897605299949646, Val precision: 0.9001958966255188, Val recall: 0.897605299949646\n",
      "\n",
      "Val loss: 0.5849055009228843, Val f1: 0.8560388684272766, \n",
      "Val accuracy: 0.8555499315261841, Val precision: 0.8568491339683533, Val recall: 0.8555499315261841\n",
      "\n",
      "Val loss: 0.5704324013657041, Val f1: 0.8285610675811768, \n",
      "Val accuracy: 0.8258885741233826, Val precision: 0.8316361904144287, Val recall: 0.8258885741233826\n",
      "\n",
      "\n",
      "starting Epoch 9\n",
      "Training...\n",
      "Train loss: 0.3583096116781235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3523237949067896\n",
      "Train loss: 0.35012500286102294\n",
      "Train loss: 0.3514133736268798\n",
      "Train loss: 0.35275447581495556\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.3672451600432396, Val f1: 0.9237116575241089, \n",
      "Val accuracy: 0.8911290168762207, Val precision: 0.9590432643890381, Val recall: 0.8911290168762207\n",
      "\n",
      "Val loss: 0.35399877483194525, Val f1: 0.8970213532447815, \n",
      "Val accuracy: 0.865120530128479, Val precision: 0.9316484928131104, Val recall: 0.865120530128479\n",
      "\n",
      "Val loss: 0.35224091708660127, Val f1: 0.8876185417175293, \n",
      "Val accuracy: 0.856606662273407, Val precision: 0.9212322235107422, Val recall: 0.856606662273407\n",
      "\n",
      "Val loss: 0.3496094243739968, Val f1: 0.8838041424751282, \n",
      "Val accuracy: 0.85284024477005, Val precision: 0.917352020740509, Val recall: 0.85284024477005\n",
      "\n",
      "Val loss: 0.34774128028324675, Val f1: 0.8813531994819641, \n",
      "Val accuracy: 0.8509013652801514, Val precision: 0.9143190979957581, Val recall: 0.8509013652801514\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 0.9971407055854797, Val f1: 1.4935307502746582, \n",
      "Val accuracy: 1.4457119703292847, Val precision: 1.5446557998657227, Val recall: 1.4457119703292847\n",
      "\n",
      "Val loss: 0.6878650784492493, Val f1: 0.9781158566474915, \n",
      "Val accuracy: 0.9368054866790771, Val precision: 1.0237958431243896, Val recall: 0.9368054866790771\n",
      "\n",
      "Val loss: 0.6170308768749238, Val f1: 0.8846662640571594, \n",
      "Val accuracy: 0.850511372089386, Val precision: 0.9220755696296692, Val recall: 0.850511372089386\n",
      "\n",
      "Val loss: 0.5901058529104505, Val f1: 0.8420595526695251, \n",
      "Val accuracy: 0.809620201587677, Val precision: 0.8778351545333862, Val recall: 0.809620201587677\n",
      "\n",
      "Val loss: 0.5753150482972463, Val f1: 0.8142131567001343, \n",
      "Val accuracy: 0.780690610408783, Val precision: 0.8516713976860046, Val recall: 0.780690610408783\n",
      "\n",
      "\n",
      "starting Epoch 10\n",
      "Training...\n",
      "Train loss: 0.3392939418554306\n",
      "Train loss: 0.3360663110559637\n",
      "Train loss: 0.33375139713287355\n",
      "Train loss: 0.3340380445345124\n",
      "Train loss: 0.3336737812274978\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.3420000597834587, Val f1: 0.9445605874061584, \n",
      "Val accuracy: 0.9222198724746704, Val precision: 0.9681823253631592, Val recall: 0.9222198724746704\n",
      "\n",
      "Val loss: 0.3346601218888254, Val f1: 0.9130144715309143, \n",
      "Val accuracy: 0.8918642997741699, Val precision: 0.9353721141815186, Val recall: 0.8918642997741699\n",
      "\n",
      "Val loss: 0.3306035089492798, Val f1: 0.902417004108429, \n",
      "Val accuracy: 0.8803116679191589, Val precision: 0.9259156584739685, Val recall: 0.8803116679191589\n",
      "\n",
      "Val loss: 0.3285278086342029, Val f1: 0.898722767829895, \n",
      "Val accuracy: 0.8767328262329102, Val precision: 0.9220966696739197, Val recall: 0.8767328262329102\n",
      "\n",
      "Val loss: 0.3271359783552942, Val f1: 0.8961375951766968, \n",
      "Val accuracy: 0.8742260932922363, Val precision: 0.9194162487983704, Val recall: 0.8742260932922363\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0127368569374084, Val f1: 1.4998884201049805, \n",
      "Val accuracy: 1.4648842811584473, Val precision: 1.536606788635254, Val recall: 1.4648842811584473\n",
      "\n",
      "Val loss: 0.6988704005877177, Val f1: 0.9799108505249023, \n",
      "Val accuracy: 0.9470135569572449, Val precision: 1.0156651735305786, Val recall: 0.9470135569572449\n",
      "\n",
      "Val loss: 0.6243913233280182, Val f1: 0.8846288919448853, \n",
      "Val accuracy: 0.8582426905632019, Val precision: 0.9130604863166809, Val recall: 0.8582426905632019\n",
      "\n",
      "Val loss: 0.5981561924730029, Val f1: 0.8427601456642151, \n",
      "Val accuracy: 0.8164687156677246, Val precision: 0.8716163039207458, Val recall: 0.8164687156677246\n",
      "\n",
      "Val loss: 0.5822423663404253, Val f1: 0.8165280818939209, \n",
      "Val accuracy: 0.7902011275291443, Val precision: 0.8453903794288635, Val recall: 0.7902011275291443\n",
      "\n",
      "\n",
      "starting Epoch 11\n",
      "Training...\n",
      "Train loss: 0.32066201977431774\n",
      "Train loss: 0.3129269155589017\n",
      "Train loss: 0.3156991022825241\n",
      "Train loss: 0.31357460991660163\n",
      "Train loss: 0.3145481763141496\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.32546809874475, Val f1: 0.9486164450645447, \n",
      "Val accuracy: 0.9184865951538086, Val precision: 0.9809951186180115, Val recall: 0.9184865951538086\n",
      "\n",
      "Val loss: 0.3150155038544626, Val f1: 0.9205142259597778, \n",
      "Val accuracy: 0.8924381732940674, Val precision: 0.9506387114524841, Val recall: 0.8924381732940674\n",
      "\n",
      "Val loss: 0.31313028395175935, Val f1: 0.9103441834449768, \n",
      "Val accuracy: 0.881022572517395, Val precision: 0.9419097900390625, Val recall: 0.881022572517395\n",
      "\n",
      "Val loss: 0.3111650592355586, Val f1: 0.9053019881248474, \n",
      "Val accuracy: 0.8762534856796265, Val precision: 0.936562180519104, Val recall: 0.8762534856796265\n",
      "\n",
      "Val loss: 0.3097816546048437, Val f1: 0.9029580950737, \n",
      "Val accuracy: 0.8743507862091064, Val precision: 0.9337172508239746, Val recall: 0.8743507862091064\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0132810175418854, Val f1: 1.4953911304473877, \n",
      "Val accuracy: 1.4612860679626465, Val precision: 1.5311377048492432, Val recall: 1.4612860679626465\n",
      "\n",
      "Val loss: 0.7056262195110321, Val f1: 0.9819722175598145, \n",
      "Val accuracy: 0.9464285373687744, Val precision: 1.0208929777145386, Val recall: 0.9464285373687744\n",
      "\n",
      "Val loss: 0.63111532330513, Val f1: 0.8860227465629578, \n",
      "Val accuracy: 0.8566756248474121, Val precision: 0.9178552627563477, Val recall: 0.8566756248474121\n",
      "\n",
      "Val loss: 0.603611422436578, Val f1: 0.843779444694519, \n",
      "Val accuracy: 0.8137611746788025, Val precision: 0.8766013383865356, Val recall: 0.8137611746788025\n",
      "\n",
      "Val loss: 0.587339417801963, Val f1: 0.815396785736084, \n",
      "Val accuracy: 0.7847716808319092, Val precision: 0.8490673303604126, Val recall: 0.7847716808319092\n",
      "\n",
      "\n",
      "starting Epoch 12\n",
      "Training...\n",
      "Train loss: 0.30715315230190754\n",
      "Train loss: 0.29315528815442865\n",
      "Train loss: 0.2953826546669006\n",
      "Train loss: 0.29799033011963116\n",
      "Train loss: 0.30132406630686354\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.3096557129174471, Val f1: 0.9603219032287598, \n",
      "Val accuracy: 0.963594913482666, Val precision: 0.9572924971580505, Val recall: 0.963594913482666\n",
      "\n",
      "Val loss: 0.2998257161992969, Val f1: 0.9333087801933289, \n",
      "Val accuracy: 0.9348700642585754, Val precision: 0.9319295883178711, Val recall: 0.9348700642585754\n",
      "\n",
      "Val loss: 0.29596458971500395, Val f1: 0.9243714809417725, \n",
      "Val accuracy: 0.9262901544570923, Val precision: 0.9226347208023071, Val recall: 0.9262901544570923\n",
      "\n",
      "Val loss: 0.29531422702234184, Val f1: 0.9195603728294373, \n",
      "Val accuracy: 0.9221066236495972, Val precision: 0.917206883430481, Val recall: 0.9221066236495972\n",
      "\n",
      "Val loss: 0.2944650444246474, Val f1: 0.9172614216804504, \n",
      "Val accuracy: 0.9194677472114563, Val precision: 0.9152337312698364, Val recall: 0.9194677472114563\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0402663946151733, Val f1: 1.511681318283081, \n",
      "Val accuracy: 1.5331690311431885, Val precision: 1.4908502101898193, Val recall: 1.5331690311431885\n",
      "\n",
      "Val loss: 0.7237854599952698, Val f1: 0.9916672706604004, \n",
      "Val accuracy: 0.993307888507843, Val precision: 0.9905074238777161, Val recall: 0.993307888507843\n",
      "\n",
      "Val loss: 0.6464071869850159, Val f1: 0.8947615623474121, \n",
      "Val accuracy: 0.9016363024711609, Val precision: 0.8884217143058777, Val recall: 0.9016363024711609\n",
      "\n",
      "Val loss: 0.6182682258742196, Val f1: 0.8519190549850464, \n",
      "Val accuracy: 0.8552249073982239, Val precision: 0.849192202091217, Val recall: 0.8552249073982239\n",
      "\n",
      "Val loss: 0.5996211568514506, Val f1: 0.8253834247589111, \n",
      "Val accuracy: 0.8277900218963623, Val precision: 0.8234354257583618, Val recall: 0.8277900218963623\n",
      "\n",
      "\n",
      "starting Epoch 13\n",
      "Training...\n",
      "Train loss: 0.2848442019894719\n",
      "Train loss: 0.27952359797376575\n",
      "Train loss: 0.28013019055128097\n",
      "Train loss: 0.2810047942755827\n",
      "Train loss: 0.2836578784599191\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.28763497620821, Val f1: 0.9735448360443115, \n",
      "Val accuracy: 0.973065197467804, Val precision: 0.9742769002914429, Val recall: 0.973065197467804\n",
      "\n",
      "Val loss: 0.2793070836500688, Val f1: 0.9446492791175842, \n",
      "Val accuracy: 0.9423011541366577, Val precision: 0.9472328424453735, Val recall: 0.9423011541366577\n",
      "\n",
      "Val loss: 0.2783334964513779, Val f1: 0.9346803426742554, \n",
      "Val accuracy: 0.9329627156257629, Val precision: 0.9365842342376709, Val recall: 0.9329627156257629\n",
      "\n",
      "Val loss: 0.27747958320290295, Val f1: 0.9298822283744812, \n",
      "Val accuracy: 0.9289669394493103, Val precision: 0.9309585094451904, Val recall: 0.9289669394493103\n",
      "\n",
      "Val loss: 0.2779244347697213, Val f1: 0.9252893328666687, \n",
      "Val accuracy: 0.9237425923347473, Val precision: 0.9270016551017761, Val recall: 0.9237425923347473\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0518206357955933, Val f1: 1.5017309188842773, \n",
      "Val accuracy: 1.5155987739562988, Val precision: 1.488114833831787, Val recall: 1.5155987739562988\n",
      "\n",
      "Val loss: 0.7376843690872192, Val f1: 0.989044189453125, \n",
      "Val accuracy: 0.9875094294548035, Val precision: 0.9911114573478699, Val recall: 0.9875094294548035\n",
      "\n",
      "Val loss: 0.6590381145477295, Val f1: 0.8917614221572876, \n",
      "Val accuracy: 0.8953601717948914, Val precision: 0.8886352777481079, Val recall: 0.8953601717948914\n",
      "\n",
      "Val loss: 0.6309866224016462, Val f1: 0.8509946465492249, \n",
      "Val accuracy: 0.8515380024909973, Val precision: 0.851162850856781, Val recall: 0.8515380024909973\n",
      "\n",
      "Val loss: 0.612016068564521, Val f1: 0.8247178196907043, \n",
      "Val accuracy: 0.8236284255981445, Val precision: 0.8264615535736084, Val recall: 0.8236284255981445\n",
      "\n",
      "\n",
      "starting Epoch 14\n",
      "Training...\n",
      "Train loss: 0.27499531768262386\n",
      "Train loss: 0.26894883811473846\n",
      "Train loss: 0.27068905502557755\n",
      "Train loss: 0.27165180555920104\n",
      "Train loss: 0.2732985635243711\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.27509772032499313, Val f1: 0.9780533313751221, \n",
      "Val accuracy: 0.9883636236190796, Val precision: 0.968023955821991, Val recall: 0.9883636236190796\n",
      "\n",
      "Val loss: 0.2662427985306942, Val f1: 0.9485701322555542, \n",
      "Val accuracy: 0.9569802284240723, Val precision: 0.9403732419013977, Val recall: 0.9569802284240723\n",
      "\n",
      "Val loss: 0.26473544895648954, Val f1: 0.939480721950531, \n",
      "Val accuracy: 0.9475913047790527, Val precision: 0.9315984845161438, Val recall: 0.9475913047790527\n",
      "\n",
      "Val loss: 0.2642220567856262, Val f1: 0.933386504650116, \n",
      "Val accuracy: 0.9414190053939819, Val precision: 0.9255926609039307, Val recall: 0.9414190053939819\n",
      "\n",
      "Val loss: 0.26313242883909316, Val f1: 0.9307341575622559, \n",
      "Val accuracy: 0.9393936991691589, Val precision: 0.922349750995636, Val recall: 0.9393936991691589\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0718929767608643, Val f1: 1.4991583824157715, \n",
      "Val accuracy: 1.5407590866088867, Val precision: 1.4597485065460205, Val recall: 1.5407590866088867\n",
      "\n",
      "Val loss: 0.7575180530548096, Val f1: 0.9918105006217957, \n",
      "Val accuracy: 1.0085912942886353, Val precision: 0.9760177731513977, Val recall: 1.0085912942886353\n",
      "\n",
      "Val loss: 0.6779951572418212, Val f1: 0.8958648443222046, \n",
      "Val accuracy: 0.9167971611022949, Val precision: 0.8762766122817993, Val recall: 0.9167971611022949\n",
      "\n",
      "Val loss: 0.6477988277162824, Val f1: 0.8564136624336243, \n",
      "Val accuracy: 0.8729928135871887, Val precision: 0.8409631848335266, Val recall: 0.8729928135871887\n",
      "\n",
      "Val loss: 0.6276916331715054, Val f1: 0.8300650119781494, \n",
      "Val accuracy: 0.8458893299102783, Val precision: 0.8152227997779846, Val recall: 0.8458893299102783\n",
      "\n",
      "\n",
      "starting Epoch 15\n",
      "Training...\n",
      "Train loss: 0.25813248474150896\n",
      "Train loss: 0.2521083192391829\n",
      "Train loss: 0.25378390789031985\n",
      "Train loss: 0.25632950263236887\n",
      "Train loss: 0.2582939776281516\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.2516504041850567, Val f1: 0.9851533770561218, \n",
      "Val accuracy: 0.9826958775520325, Val precision: 0.9877744913101196, Val recall: 0.9826958775520325\n",
      "\n",
      "Val loss: 0.24475325734326334, Val f1: 0.9546566009521484, \n",
      "Val accuracy: 0.95224529504776, Val precision: 0.9571797251701355, Val recall: 0.95224529504776\n",
      "\n",
      "Val loss: 0.2424687534570694, Val f1: 0.9450684189796448, \n",
      "Val accuracy: 0.942568838596344, Val precision: 0.9476903676986694, Val recall: 0.942568838596344\n",
      "\n",
      "Val loss: 0.2423808788185689, Val f1: 0.9396764636039734, \n",
      "Val accuracy: 0.9373365044593811, Val precision: 0.9421514272689819, Val recall: 0.9373365044593811\n",
      "\n",
      "Val loss: 0.2418763626899038, Val f1: 0.9371424913406372, \n",
      "Val accuracy: 0.9346469640731812, Val precision: 0.939768373966217, Val recall: 0.9346469640731812\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1024315357208252, Val f1: 1.4910156726837158, \n",
      "Val accuracy: 1.505421757698059, Val precision: 1.4769201278686523, Val recall: 1.505421757698059\n",
      "\n",
      "Val loss: 0.7862045963605245, Val f1: 0.9830288887023926, \n",
      "Val accuracy: 0.9802414774894714, Val precision: 0.986312210559845, Val recall: 0.9802414774894714\n",
      "\n",
      "Val loss: 0.7048572778701783, Val f1: 0.8874305486679077, \n",
      "Val accuracy: 0.8910058736801147, Val precision: 0.884343147277832, Val recall: 0.8910058736801147\n",
      "\n",
      "Val loss: 0.6755433167730059, Val f1: 0.847039520740509, \n",
      "Val accuracy: 0.8478937745094299, Val precision: 0.8468166589736938, Val recall: 0.8478937745094299\n",
      "\n",
      "Val loss: 0.6546362042427063, Val f1: 0.8208551406860352, \n",
      "Val accuracy: 0.8210696578025818, Val precision: 0.8211493492126465, Val recall: 0.8210696578025818\n",
      "\n",
      "\n",
      "starting Epoch 16\n",
      "Training...\n",
      "Train loss: 0.24459037277847528\n",
      "Train loss: 0.24067628248171372\n",
      "Train loss: 0.24298850178718567\n",
      "Train loss: 0.24402122110573213\n",
      "Train loss: 0.24646577487389246\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.2456184970214963, Val f1: 0.9860787987709045, \n",
      "Val accuracy: 0.9648618698120117, Val precision: 1.008334994316101, Val recall: 0.9648618698120117\n",
      "\n",
      "Val loss: 0.23627318306402725, Val f1: 0.9563146829605103, \n",
      "Val accuracy: 0.9370757937431335, Val precision: 0.9764910340309143, Val recall: 0.9370757937431335\n",
      "\n",
      "Val loss: 0.23371765285730361, Val f1: 0.9479057788848877, \n",
      "Val accuracy: 0.9288763403892517, Val precision: 0.9678497910499573, Val recall: 0.9288763403892517\n",
      "\n",
      "Val loss: 0.23305510718431047, Val f1: 0.9420291781425476, \n",
      "Val accuracy: 0.924073338508606, Val precision: 0.9608103036880493, Val recall: 0.924073338508606\n",
      "\n",
      "Val loss: 0.23132640229804174, Val f1: 0.9400203227996826, \n",
      "Val accuracy: 0.9223166704177856, Val precision: 0.9585498571395874, Val recall: 0.9223166704177856\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1316415667533875, Val f1: 1.492579698562622, \n",
      "Val accuracy: 1.4684823751449585, Val precision: 1.5175566673278809, Val recall: 1.4684823751449585\n",
      "\n",
      "Val loss: 0.8109069665273031, Val f1: 0.9785853028297424, \n",
      "Val accuracy: 0.9520302414894104, Val precision: 1.0071686506271362, Val recall: 0.9520302414894104\n",
      "\n",
      "Val loss: 0.7253768801689148, Val f1: 0.8783668279647827, \n",
      "Val accuracy: 0.860875129699707, Val precision: 0.8971101641654968, Val recall: 0.860875129699707\n",
      "\n",
      "Val loss: 0.6948664443833488, Val f1: 0.8376493453979492, \n",
      "Val accuracy: 0.8202351331710815, Val precision: 0.856370747089386, Val recall: 0.8202351331710815\n",
      "\n",
      "Val loss: 0.6732646690474616, Val f1: 0.8124340772628784, \n",
      "Val accuracy: 0.7950571179389954, Val precision: 0.8310545682907104, Val recall: 0.7950571179389954\n",
      "\n",
      "\n",
      "starting Epoch 17\n",
      "Training...\n",
      "Train loss: 0.23198422323912382\n",
      "Train loss: 0.22828835835962585\n",
      "Train loss: 0.2319548398256302\n",
      "Train loss: 0.23295308916426416\n",
      "Train loss: 0.2353658147511028\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.23509776405990124, Val f1: 0.9927033185958862, \n",
      "Val accuracy: 0.994871199131012, Val precision: 0.9906638860702515, Val recall: 0.994871199131012\n",
      "\n",
      "Val loss: 0.22783842818303543, Val f1: 0.9634897708892822, \n",
      "Val accuracy: 0.9665939807891846, Val precision: 0.9605348110198975, Val recall: 0.9665939807891846\n",
      "\n",
      "Val loss: 0.2255699709057808, Val f1: 0.9537582993507385, \n",
      "Val accuracy: 0.9564486742019653, Val precision: 0.9511914253234863, Val recall: 0.9564486742019653\n",
      "\n",
      "Val loss: 0.22321470993668285, Val f1: 0.9499073028564453, \n",
      "Val accuracy: 0.9536600708961487, Val precision: 0.9462855458259583, Val recall: 0.9536600708961487\n",
      "\n",
      "Val loss: 0.22234392095179784, Val f1: 0.9474546313285828, \n",
      "Val accuracy: 0.9514907002449036, Val precision: 0.943556547164917, Val recall: 0.9514907002449036\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1655374765396118, Val f1: 1.5004695653915405, \n",
      "Val accuracy: 1.5230903625488281, Val precision: 1.478510856628418, Val recall: 1.5230903625488281\n",
      "\n",
      "Val loss: 0.8332125544548035, Val f1: 0.9887676239013672, \n",
      "Val accuracy: 0.9956960678100586, Val precision: 0.9822245240211487, Val recall: 0.9956960678100586\n",
      "\n",
      "Val loss: 0.747564697265625, Val f1: 0.8875324130058289, \n",
      "Val accuracy: 0.8990370035171509, Val precision: 0.8766103982925415, Val recall: 0.8990370035171509\n",
      "\n",
      "Val loss: 0.7173038039888654, Val f1: 0.8474879264831543, \n",
      "Val accuracy: 0.8555004000663757, Val precision: 0.8401085734367371, Val recall: 0.8555004000663757\n",
      "\n",
      "Val loss: 0.6931281752056546, Val f1: 0.8220927119255066, \n",
      "Val accuracy: 0.8294421434402466, Val precision: 0.815300703048706, Val recall: 0.8294421434402466\n",
      "\n",
      "\n",
      "starting Epoch 18\n",
      "Training...\n",
      "Train loss: 0.22651061695069075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2239192579731797\n",
      "Train loss: 0.22503677010536194\n",
      "Train loss: 0.22447892734363897\n",
      "Train loss: 0.22499036824419386\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.2189465295523405, Val f1: 0.9947060346603394, \n",
      "Val accuracy: 0.9790745973587036, Val precision: 1.0109652280807495, Val recall: 0.9790745973587036\n",
      "\n",
      "Val loss: 0.2108605160857692, Val f1: 0.9647380709648132, \n",
      "Val accuracy: 0.9477851390838623, Val precision: 0.9824495315551758, Val recall: 0.9477851390838623\n",
      "\n",
      "Val loss: 0.2061452803015709, Val f1: 0.9571169018745422, \n",
      "Val accuracy: 0.9417198896408081, Val precision: 0.9731622338294983, Val recall: 0.9417198896408081\n",
      "\n",
      "Val loss: 0.20512474472842998, Val f1: 0.9520597457885742, \n",
      "Val accuracy: 0.9373267292976379, Val precision: 0.9673988223075867, Val recall: 0.9373267292976379\n",
      "\n",
      "Val loss: 0.20486970618367195, Val f1: 0.9489858746528625, \n",
      "Val accuracy: 0.9343237280845642, Val precision: 0.9642491936683655, Val recall: 0.9343237280845642\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.2006872296333313, Val f1: 1.4782025814056396, \n",
      "Val accuracy: 1.4664864540100098, Val precision: 1.4902596473693848, Val recall: 1.4664864540100098\n",
      "\n",
      "Val loss: 0.8759849071502686, Val f1: 0.9733131527900696, \n",
      "Val accuracy: 0.9539826512336731, Val precision: 0.9941471219062805, Val recall: 0.9539826512336731\n",
      "\n",
      "Val loss: 0.7819350004196167, Val f1: 0.8736171722412109, \n",
      "Val accuracy: 0.8584302663803101, Val precision: 0.8898155093193054, Val recall: 0.8584302663803101\n",
      "\n",
      "Val loss: 0.7510980197361538, Val f1: 0.8355183601379395, \n",
      "Val accuracy: 0.819024920463562, Val precision: 0.8532037138938904, Val recall: 0.819024920463562\n",
      "\n",
      "Val loss: 0.7263843086030748, Val f1: 0.8117437362670898, \n",
      "Val accuracy: 0.7942261099815369, Val precision: 0.8304961323738098, Val recall: 0.7942261099815369\n",
      "\n",
      "\n",
      "starting Epoch 19\n",
      "Training...\n",
      "Train loss: 0.21902579627931118\n",
      "Train loss: 0.20910266086910712\n",
      "Train loss: 0.20973228991031648\n",
      "Train loss: 0.2128807206207247\n",
      "Train loss: 0.2156239568832375\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.20288511645048857, Val f1: 1.0015660524368286, \n",
      "Val accuracy: 0.9935147166252136, Val precision: 1.0097978115081787, Val recall: 0.9935147166252136\n",
      "\n",
      "Val loss: 0.1958126507022164, Val f1: 0.973005473613739, \n",
      "Val accuracy: 0.9643042683601379, Val precision: 0.9819183349609375, Val recall: 0.9643042683601379\n",
      "\n",
      "Val loss: 0.19437879621982573, Val f1: 0.9638175368309021, \n",
      "Val accuracy: 0.9547038078308105, Val precision: 0.9731594324111938, Val recall: 0.9547038078308105\n",
      "\n",
      "Val loss: 0.19409445039371945, Val f1: 0.9585391283035278, \n",
      "Val accuracy: 0.9491611123085022, Val precision: 0.9681665301322937, Val recall: 0.9491611123085022\n",
      "\n",
      "Val loss: 0.19379403743715512, Val f1: 0.9553084373474121, \n",
      "Val accuracy: 0.9461260437965393, Val precision: 0.9647334814071655, Val recall: 0.9461260437965393\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.234795331954956, Val f1: 1.49928879737854, \n",
      "Val accuracy: 1.5013313293457031, Val precision: 1.4973695278167725, Val recall: 1.5013313293457031\n",
      "\n",
      "Val loss: 0.9028913577397665, Val f1: 0.980154812335968, \n",
      "Val accuracy: 0.9680841565132141, Val precision: 0.9932349324226379, Val recall: 0.9680841565132141\n",
      "\n",
      "Val loss: 0.8075839877128601, Val f1: 0.8829746246337891, \n",
      "Val accuracy: 0.8765046000480652, Val precision: 0.8900662660598755, Val recall: 0.8765046000480652\n",
      "\n",
      "Val loss: 0.7750090445790973, Val f1: 0.8426855802536011, \n",
      "Val accuracy: 0.8345994353294373, Val precision: 0.8515415787696838, Val recall: 0.8345994353294373\n",
      "\n",
      "Val loss: 0.7503197259373136, Val f1: 0.8170294165611267, \n",
      "Val accuracy: 0.8087478876113892, Val precision: 0.826007068157196, Val recall: 0.8087478876113892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "f1s = []\n",
    "f1s_eval = []\n",
    "accuracies = []\n",
    "accuracies_eval = []\n",
    "precisions = []\n",
    "precisions_eval = []\n",
    "recalls = []\n",
    "recalls_eval = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    print('Training...')\n",
    "    epoch_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "    print('\\nEvaluating on train...')\n",
    "    f1_on_train, accuracy_on_train, precision_on_train, recall_on_train,_ = evaluate(model, train_iterator, criterion)\n",
    "    f1s.append(f1_on_train)\n",
    "    accuracies.append(accuracy_on_train)\n",
    "    precisions.append(precision_on_train)\n",
    "    recalls.append(recall_on_train)\n",
    "    print('\\nEvaluating on test...')\n",
    "    f1_on_test, accuracy_on_test, precision_on_test, recall_on_test, epoch_loss_on_test = evaluate(model, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)\n",
    "    f1s_eval.append(f1_on_test)\n",
    "    accuracies_eval.append(accuracy_on_test)\n",
    "    precisions_eval.append(precision_on_test)\n",
    "    recalls_eval.append(recall_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6635696217417717, 0.5970789282159372, 0.5540223196148872, 0.5137656889855862, 0.48048213056542655, 0.4471133510497483, 0.41876637088981544, 0.39315483143383806, 0.36837342008948326, 0.34866856986826117, 0.33041208305142145, 0.3110760243778879, 0.2979169152677059, 0.28078451701863244, 0.2708579692989588, 0.25562297231094405, 0.24401857432993976, 0.23331775990399448, 0.22273892858488994, 0.21320214291865175] \n",
      "\n",
      " [0.6192739009857178, 0.5901781141757965, 0.564483106136322, 0.546650356054306, 0.5309550881385803, 0.5218810141086578, 0.5149481654167175, 0.5135581523180008, 0.5133891612291336, 0.5177835434675216, 0.5240181297063827, 0.5286054760217667, 0.5396590411663056, 0.5508144617080688, 0.5649224698543549, 0.5891725838184356, 0.6059382021427154, 0.6238153576850891, 0.6537458777427674, 0.6752877533435822]\n"
     ]
    }
   ],
   "source": [
    "print(losses, '\\n\\n', losses_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучается, но кажется, в какой-то момент переобучается, поскольку, например, к 20й эпохе средний loss на обучающей выборке - примерно 0.21, а на тестовой - 0.68. Попробую сделать модель с предобученными эмбеддингами и посмотреть, поменяет ли это как-то ситуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель с предобученными эмбеддингами\n",
    "Создаем модель Word2Vec и создаем с её помощью матрицу весов, которые потом будем передавать в модель CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = all_tweets_data.text.apply(preprocess).tolist()\n",
    "w2v = gensim.models.Word2Vec(texts, size=100, window=5, min_count=1)\n",
    "\n",
    "weights = np.zeros((len(word2id), 100))\n",
    "count = 0\n",
    "for word, i in word2id.items():\n",
    "    if word == 'PAD':\n",
    "        continue   \n",
    "    try:\n",
    "        weights[i] = w2v.wv[word]    \n",
    "    except KeyError:\n",
    "        count += 1\n",
    "        # oov словам сопоставляем случайный вектор\n",
    "        weights[i] = np.random.normal(0,0.1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сама модель CNN (такая же как прошлая, только с предобученными эмбеддингами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_w2v(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        \n",
    "        super().__init__()          \n",
    "        # указываем в атрибутах класса, какие слои и активации нам понадобятся\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.from_pretrained(torch.tensor(weights), freeze=True)\n",
    "        self.bigrams = nn.Conv1d(in_channels=embedding_dim, out_channels=100, kernel_size=2, padding='same')\n",
    "        self.trigrams = nn.Conv1d(in_channels=embedding_dim, out_channels=80, kernel_size=3, padding='same')\n",
    "        self.next_conv = nn.Conv1d(in_channels=180, out_channels=90, kernel_size=3, padding='same')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden = nn.Linear(in_features=90, out_features=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, text): #необходимый метод,  в нем указываем, как именно связываются слои/активации между собой\n",
    "        # batch_size x seq_len\n",
    "        embedded = self.embedding(text)   # переводим последовательность индексов в последовательность эмбеддингов\n",
    "        # batch_size x seq_len x embedding_dim\n",
    "        embedded = embedded.transpose(1,2)\n",
    "        #batch_size x embedding_dim x seq_len\n",
    "    \n",
    "        feature_map_bigrams = self.dropout(self.relu(self.bigrams(embedded)))\n",
    "        #batch_size x filter_count2 x seq_len* \n",
    "        feature_map_trigrams = self.dropout(self.relu(self.trigrams(embedded)))\n",
    "        #batch_size x filter_count3 x seq_len*\n",
    "\n",
    "        concat = torch.cat((feature_map_bigrams, feature_map_trigrams), 1)  # конкатенация \"биграм\" и \"тиграм\"\n",
    "        next_conv = self.dropout(self.relu(self.next_conv(concat)))\n",
    "        \n",
    "        pooling = next_conv.max(2)[0]\n",
    "        \n",
    "        logits = self.hidden(pooling) \n",
    "        logits = self.out(logits)      \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем экземпляр модели, запускаем обучение и эвалюацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = CNN_w2v(len(word2id), 100)\n",
    "optimizer2 = optim.Adam(model2.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model2 = model2.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting Epoch 0\n",
      "Training...\n",
      "Train loss: 0.7547885328531265\n",
      "Train loss: 0.713519275188446\n",
      "Train loss: 0.6946455681324005\n",
      "Train loss: 0.6823991759499507\n",
      "Train loss: 0.6732842759007499\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6635473668575287, Val f1: 0.6940260529518127, \n",
      "Val accuracy: 0.6974904537200928, Val precision: 0.6911640167236328, Val recall: 0.6974904537200928\n",
      "\n",
      "Val loss: 0.6448805675362096, Val f1: 0.6688497066497803, \n",
      "Val accuracy: 0.6730623841285706, Val precision: 0.6651954650878906, Val recall: 0.6730623841285706\n",
      "\n",
      "Val loss: 0.637915689945221, Val f1: 0.6636499166488647, \n",
      "Val accuracy: 0.6664307117462158, Val precision: 0.6613147854804993, Val recall: 0.6664307117462158\n",
      "\n",
      "Val loss: 0.6349708651428791, Val f1: 0.6612711548805237, \n",
      "Val accuracy: 0.6629495024681091, Val precision: 0.6600250601768494, Val recall: 0.6629495024681091\n",
      "\n",
      "Val loss: 0.6331840306520462, Val f1: 0.6594985127449036, \n",
      "Val accuracy: 0.6616628766059875, Val precision: 0.6577427983283997, Val recall: 0.6616628766059875\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.2400788068771362, Val f1: 1.3242502212524414, \n",
      "Val accuracy: 1.3383934497833252, Val precision: 1.3116776943206787, Val recall: 1.3383934497833252\n",
      "\n",
      "Val loss: 0.829123874505361, Val f1: 0.8753175735473633, \n",
      "Val accuracy: 0.8731265664100647, Val precision: 0.8783431053161621, Val recall: 0.8731265664100647\n",
      "\n",
      "Val loss: 0.7498949766159058, Val f1: 0.7785481810569763, \n",
      "Val accuracy: 0.7830605506896973, Val precision: 0.7747930884361267, Val recall: 0.7830605506896973\n",
      "\n",
      "Val loss: 0.714111966746194, Val f1: 0.7449812293052673, \n",
      "Val accuracy: 0.7465373873710632, Val precision: 0.7439966201782227, Val recall: 0.7465373873710632\n",
      "\n",
      "Val loss: 0.6955846746762594, Val f1: 0.7217638492584229, \n",
      "Val accuracy: 0.7203710675239563, Val precision: 0.7237292528152466, Val recall: 0.7203710675239563\n",
      "\n",
      "\n",
      "starting Epoch 1\n",
      "Training...\n",
      "Train loss: 0.657017819583416\n",
      "Train loss: 0.6372946573026252\n",
      "Train loss: 0.6302647411823272\n",
      "Train loss: 0.6249069322401019\n",
      "Train loss: 0.6192262846799124\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6327955760061741, Val f1: 0.7525252103805542, \n",
      "Val accuracy: 0.8029265403747559, Val precision: 0.7082960605621338, Val recall: 0.8029265403747559\n",
      "\n",
      "Val loss: 0.6143080176729144, Val f1: 0.7282547950744629, \n",
      "Val accuracy: 0.7770829796791077, Val precision: 0.6855646967887878, Val recall: 0.7770829796791077\n",
      "\n",
      "Val loss: 0.6070126247406006, Val f1: 0.7230925559997559, \n",
      "Val accuracy: 0.7700476050376892, Val precision: 0.6819016933441162, Val recall: 0.7700476050376892\n",
      "\n",
      "Val loss: 0.6038175785719458, Val f1: 0.7197203040122986, \n",
      "Val accuracy: 0.7657550573348999, Val precision: 0.6792377829551697, Val recall: 0.7657550573348999\n",
      "\n",
      "Val loss: 0.6010316092343557, Val f1: 0.7181327939033508, \n",
      "Val accuracy: 0.7639054656028748, Val precision: 0.6778666377067566, Val recall: 0.7639054656028748\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.191418170928955, Val f1: 1.4133424758911133, \n",
      "Val accuracy: 1.5097092390060425, Val precision: 1.3294856548309326, Val recall: 1.5097092390060425\n",
      "\n",
      "Val loss: 0.7944841980934143, Val f1: 0.9389643669128418, \n",
      "Val accuracy: 0.9950529932975769, Val precision: 0.8893515467643738, Val recall: 0.9950529932975769\n",
      "\n",
      "Val loss: 0.7177441954612732, Val f1: 0.8413692712783813, \n",
      "Val accuracy: 0.901832103729248, Val precision: 0.7891340851783752, Val recall: 0.901832103729248\n",
      "\n",
      "Val loss: 0.6840062141418457, Val f1: 0.8058747053146362, \n",
      "Val accuracy: 0.861265242099762, Val precision: 0.7576894164085388, Val recall: 0.861265242099762\n",
      "\n",
      "Val loss: 0.6670178373654684, Val f1: 0.7794449329376221, \n",
      "Val accuracy: 0.830741286277771, Val precision: 0.7345578670501709, Val recall: 0.830741286277771\n",
      "\n",
      "\n",
      "starting Epoch 2\n",
      "Training...\n",
      "Train loss: 0.619967382401228\n",
      "Train loss: 0.6006801417379668\n",
      "Train loss: 0.5919500410556793\n",
      "Train loss: 0.5864178502737586\n",
      "Train loss: 0.5831919695649829\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6037468574941158, Val f1: 0.7720687389373779, \n",
      "Val accuracy: 0.7776873707771301, Val precision: 0.7669035196304321, Val recall: 0.7776873707771301\n",
      "\n",
      "Val loss: 0.584397346684427, Val f1: 0.7482473254203796, \n",
      "Val accuracy: 0.7517191171646118, Val precision: 0.7451932430267334, Val recall: 0.7517191171646118\n",
      "\n",
      "Val loss: 0.5778234076499938, Val f1: 0.742567777633667, \n",
      "Val accuracy: 0.7467818260192871, Val precision: 0.7387634515762329, Val recall: 0.7467818260192871\n",
      "\n",
      "Val loss: 0.5742190355685219, Val f1: 0.739014744758606, \n",
      "Val accuracy: 0.741721510887146, Val precision: 0.7366843819618225, Val recall: 0.741721510887146\n",
      "\n",
      "Val loss: 0.5717180655116126, Val f1: 0.7381826639175415, \n",
      "Val accuracy: 0.7407066822052002, Val precision: 0.7360467910766602, Val recall: 0.7407066822052002\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1496865153312683, Val f1: 1.4266138076782227, \n",
      "Val accuracy: 1.4383187294006348, Val precision: 1.4164855480194092, Val recall: 1.4383187294006348\n",
      "\n",
      "Val loss: 0.765766421953837, Val f1: 0.9446942210197449, \n",
      "Val accuracy: 0.9464656710624695, Val precision: 0.9436150193214417, Val recall: 0.9464656710624695\n",
      "\n",
      "Val loss: 0.6916500806808472, Val f1: 0.8430835604667664, \n",
      "Val accuracy: 0.8522751927375793, Val precision: 0.8347774744033813, Val recall: 0.8522751927375793\n",
      "\n",
      "Val loss: 0.6598614624568394, Val f1: 0.8047385215759277, \n",
      "Val accuracy: 0.8106359839439392, Val precision: 0.7994853258132935, Val recall: 0.8106359839439392\n",
      "\n",
      "Val loss: 0.6443762514326308, Val f1: 0.7788118124008179, \n",
      "Val accuracy: 0.781991183757782, Val precision: 0.7761932015419006, Val recall: 0.781991183757782\n",
      "\n",
      "\n",
      "starting Epoch 3\n",
      "Training...\n",
      "Train loss: 0.5892682783305645\n",
      "Train loss: 0.5670164769346063\n",
      "Train loss: 0.557258380651474\n",
      "Train loss: 0.5529640272482118\n",
      "Train loss: 0.5496685880990255\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5689830295741558, Val f1: 0.7989349365234375, \n",
      "Val accuracy: 0.8077231049537659, Val precision: 0.790677547454834, Val recall: 0.8077231049537659\n",
      "\n",
      "Val loss: 0.5506837693127719, Val f1: 0.7782091498374939, \n",
      "Val accuracy: 0.7855693697929382, Val precision: 0.7713629007339478, Val recall: 0.7855693697929382\n",
      "\n",
      "Val loss: 0.5437616240978241, Val f1: 0.7719833850860596, \n",
      "Val accuracy: 0.7796521186828613, Val precision: 0.7648084759712219, Val recall: 0.7796521186828613\n",
      "\n",
      "Val loss: 0.5410514865348588, Val f1: 0.7683354020118713, \n",
      "Val accuracy: 0.7752972841262817, Val precision: 0.7618613243103027, Val recall: 0.7752972841262817\n",
      "\n",
      "Val loss: 0.5394093358800525, Val f1: 0.7663952112197876, \n",
      "Val accuracy: 0.7736006379127502, Val precision: 0.7596786022186279, Val recall: 0.7736006379127502\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1085944175720215, Val f1: 1.447717308998108, \n",
      "Val accuracy: 1.461483120918274, Val precision: 1.4345073699951172, Val recall: 1.461483120918274\n",
      "\n",
      "Val loss: 0.7394697467486063, Val f1: 0.9591458439826965, \n",
      "Val accuracy: 0.9560883641242981, Val precision: 0.962716281414032, Val recall: 0.9560883641242981\n",
      "\n",
      "Val loss: 0.6676661252975464, Val f1: 0.8592872619628906, \n",
      "Val accuracy: 0.8632652163505554, Val precision: 0.8558467626571655, Val recall: 0.8632652163505554\n",
      "\n",
      "Val loss: 0.6369657005582537, Val f1: 0.8230223059654236, \n",
      "Val accuracy: 0.8280989527702332, Val precision: 0.8183952569961548, Val recall: 0.8280989527702332\n",
      "\n",
      "Val loss: 0.6217391888300577, Val f1: 0.7969563007354736, \n",
      "Val accuracy: 0.8000185489654541, Val precision: 0.794255256652832, Val recall: 0.8000185489654541\n",
      "\n",
      "\n",
      "starting Epoch 4\n",
      "Training...\n",
      "Train loss: 0.5461284182965755\n",
      "Train loss: 0.5317770938078562\n",
      "Train loss: 0.5261044752597809\n",
      "Train loss: 0.5220024977157365\n",
      "Train loss: 0.5186706302421433\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5319929160177708, Val f1: 0.835326611995697, \n",
      "Val accuracy: 0.8547947406768799, Val precision: 0.8168947100639343, Val recall: 0.8547947406768799\n",
      "\n",
      "Val loss: 0.5167554923982332, Val f1: 0.8086309432983398, \n",
      "Val accuracy: 0.826660692691803, Val precision: 0.7916451692581177, Val recall: 0.826660692691803\n",
      "\n",
      "Val loss: 0.5127442896366119, Val f1: 0.7979483604431152, \n",
      "Val accuracy: 0.814605712890625, Val precision: 0.7821876406669617, Val recall: 0.814605712890625\n",
      "\n",
      "Val loss: 0.5102032307368606, Val f1: 0.7935018539428711, \n",
      "Val accuracy: 0.8114096522331238, Val precision: 0.7765979766845703, Val recall: 0.8114096522331238\n",
      "\n",
      "Val loss: 0.5084437110594341, Val f1: 0.7920252680778503, \n",
      "Val accuracy: 0.81104576587677, Val precision: 0.7741154432296753, Val recall: 0.81104576587677\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0763579607009888, Val f1: 1.4869389533996582, \n",
      "Val accuracy: 1.531566858291626, Val precision: 1.4456284046173096, Val recall: 1.531566858291626\n",
      "\n",
      "Val loss: 0.7191630601882935, Val f1: 0.983443558216095, \n",
      "Val accuracy: 0.9998086094856262, Val precision: 0.9682812094688416, Val recall: 0.9998086094856262\n",
      "\n",
      "Val loss: 0.6489178299903869, Val f1: 0.8772573471069336, \n",
      "Val accuracy: 0.9007172584533691, Val precision: 0.8557025194168091, Val recall: 0.9007172584533691\n",
      "\n",
      "Val loss: 0.6186963745525905, Val f1: 0.8403110504150391, \n",
      "Val accuracy: 0.8620611429214478, Val precision: 0.820144534111023, Val recall: 0.8620611429214478\n",
      "\n",
      "Val loss: 0.603821853796641, Val f1: 0.8152425289154053, \n",
      "Val accuracy: 0.8346695303916931, Val precision: 0.7971228361129761, Val recall: 0.8346695303916931\n",
      "\n",
      "\n",
      "starting Epoch 5\n",
      "Training...\n",
      "Train loss: 0.5054469499737024\n",
      "Train loss: 0.49852384762330487\n",
      "Train loss: 0.4941422462463379\n",
      "Train loss: 0.49190148533280215\n",
      "Train loss: 0.4907598910587175\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5074771977961063, Val f1: 0.8461965918540955, \n",
      "Val accuracy: 0.8359436392784119, Val precision: 0.8569220900535583, Val recall: 0.8359436392784119\n",
      "\n",
      "Val loss: 0.49287724224003876, Val f1: 0.8183213472366333, \n",
      "Val accuracy: 0.8065576553344727, Val precision: 0.8307037949562073, Val recall: 0.8065576553344727\n",
      "\n",
      "Val loss: 0.48878913760185244, Val f1: 0.8077952861785889, \n",
      "Val accuracy: 0.7961810231208801, Val precision: 0.8200095891952515, Val recall: 0.7961810231208801\n",
      "\n",
      "Val loss: 0.486312033080343, Val f1: 0.8037183284759521, \n",
      "Val accuracy: 0.7927905321121216, Val precision: 0.8151856660842896, Val recall: 0.7927905321121216\n",
      "\n",
      "Val loss: 0.4845501510869889, Val f1: 0.8016279935836792, \n",
      "Val accuracy: 0.7905611991882324, Val precision: 0.8132175207138062, Val recall: 0.7905611991882324\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.053042471408844, Val f1: 1.4803857803344727, \n",
      "Val accuracy: 1.4749627113342285, Val precision: 1.4861897230148315, Val recall: 1.4749627113342285\n",
      "\n",
      "Val loss: 0.7053189476331075, Val f1: 0.9841949343681335, \n",
      "Val accuracy: 0.9681141972541809, Val precision: 1.0012890100479126, Val recall: 0.9681141972541809\n",
      "\n",
      "Val loss: 0.6352040767669678, Val f1: 0.8811427354812622, \n",
      "Val accuracy: 0.8756841421127319, Val precision: 0.8873369097709656, Val recall: 0.8756841421127319\n",
      "\n",
      "Val loss: 0.6063588857650757, Val f1: 0.8420804738998413, \n",
      "Val accuracy: 0.8358955383300781, Val precision: 0.8488532304763794, Val recall: 0.8358955383300781\n",
      "\n",
      "Val loss: 0.5919087396727668, Val f1: 0.8162843585014343, \n",
      "Val accuracy: 0.8084285259246826, Val precision: 0.8247320652008057, Val recall: 0.8084285259246826\n",
      "\n",
      "\n",
      "starting Epoch 6\n",
      "Training...\n",
      "Train loss: 0.4918876625597477\n",
      "Train loss: 0.4768793908032504\n",
      "Train loss: 0.4705432051420212\n",
      "Train loss: 0.4678704689687757\n",
      "Train loss: 0.46517678492126013\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.4812100064009428, Val f1: 0.853188157081604, \n",
      "Val accuracy: 0.834960401058197, Val precision: 0.8727105855941772, Val recall: 0.834960401058197\n",
      "\n",
      "Val loss: 0.4686433998021213, Val f1: 0.8296070098876953, \n",
      "Val accuracy: 0.8130668997764587, Val precision: 0.8472073674201965, Val recall: 0.8130668997764587\n",
      "\n",
      "Val loss: 0.4634739285707474, Val f1: 0.8244732022285461, \n",
      "Val accuracy: 0.8083851337432861, Val precision: 0.8416237831115723, Val recall: 0.8083851337432861\n",
      "\n",
      "Val loss: 0.460336740337201, Val f1: 0.8202442526817322, \n",
      "Val accuracy: 0.804276168346405, Val precision: 0.8372452855110168, Val recall: 0.804276168346405\n",
      "\n",
      "Val loss: 0.459256075322628, Val f1: 0.8173468708992004, \n",
      "Val accuracy: 0.8011611700057983, Val precision: 0.8345444202423096, Val recall: 0.8011611700057983\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.034687578678131, Val f1: 1.4868597984313965, \n",
      "Val accuracy: 1.4609906673431396, Val precision: 1.5138399600982666, Val recall: 1.4609906673431396\n",
      "\n",
      "Val loss: 0.695913036664327, Val f1: 0.9806650280952454, \n",
      "Val accuracy: 0.9507617950439453, Val precision: 1.0129879713058472, Val recall: 0.9507617950439453\n",
      "\n",
      "Val loss: 0.6258527994155884, Val f1: 0.8816169500350952, \n",
      "Val accuracy: 0.8652663230895996, Val precision: 0.8994477391242981, Val recall: 0.8652663230895996\n",
      "\n",
      "Val loss: 0.5969820192881993, Val f1: 0.8425922989845276, \n",
      "Val accuracy: 0.8260459899902344, Val precision: 0.8604381680488586, Val recall: 0.8260459899902344\n",
      "\n",
      "Val loss: 0.5824393696255155, Val f1: 0.8187900185585022, \n",
      "Val accuracy: 0.8014698624610901, Val precision: 0.837384045124054, Val recall: 0.8014698624610901\n",
      "\n",
      "\n",
      "starting Epoch 7\n",
      "Training...\n",
      "Train loss: 0.4628112930804491\n",
      "Train loss: 0.44778982437018194\n",
      "Train loss: 0.4437073016166687\n",
      "Train loss: 0.44163091636415736\n",
      "Train loss: 0.43947246741680873\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.4522059764713049, Val f1: 0.8747129440307617, \n",
      "Val accuracy: 0.8584789037704468, Val precision: 0.8919274210929871, Val recall: 0.8584789037704468\n",
      "\n",
      "Val loss: 0.4384084867708611, Val f1: 0.8498115539550781, \n",
      "Val accuracy: 0.832958459854126, Val precision: 0.8676683902740479, Val recall: 0.832958459854126\n",
      "\n",
      "Val loss: 0.436953626871109, Val f1: 0.8391466736793518, \n",
      "Val accuracy: 0.8228349089622498, Val precision: 0.856475830078125, Val recall: 0.8228349089622498\n",
      "\n",
      "Val loss: 0.43516403436660767, Val f1: 0.8350862264633179, \n",
      "Val accuracy: 0.818141520023346, Val precision: 0.853141188621521, Val recall: 0.818141520023346\n",
      "\n",
      "Val loss: 0.43334566837265376, Val f1: 0.8326805830001831, \n",
      "Val accuracy: 0.8160939812660217, Val precision: 0.8503499031066895, Val recall: 0.8160939812660217\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0208116173744202, Val f1: 1.4810664653778076, \n",
      "Val accuracy: 1.4566048383712769, Val precision: 1.5064284801483154, Val recall: 1.4566048383712769\n",
      "\n",
      "Val loss: 0.6891154448191324, Val f1: 0.9763603806495667, \n",
      "Val accuracy: 0.9461259841918945, Val precision: 1.0091420412063599, Val recall: 0.9461259841918945\n",
      "\n",
      "Val loss: 0.6189784288406373, Val f1: 0.8793026208877563, \n",
      "Val accuracy: 0.8616847991943359, Val precision: 0.8985084295272827, Val recall: 0.8616847991943359\n",
      "\n",
      "Val loss: 0.5905191387448993, Val f1: 0.841299831867218, \n",
      "Val accuracy: 0.8240317702293396, Val precision: 0.8599184155464172, Val recall: 0.8240317702293396\n",
      "\n",
      "Val loss: 0.5757783850034078, Val f1: 0.820006787776947, \n",
      "Val accuracy: 0.8021940588951111, Val precision: 0.8391721248626709, Val recall: 0.8021940588951111\n",
      "\n",
      "\n",
      "starting Epoch 8\n",
      "Training...\n",
      "Train loss: 0.44090756960213184\n",
      "Train loss: 0.4279936407551621\n",
      "Train loss: 0.42174033403396605\n",
      "Train loss: 0.42007744623653925\n",
      "Train loss: 0.4197414900575365\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.43627082370221615, Val f1: 0.8887783885002136, \n",
      "Val accuracy: 0.8823807835578918, Val precision: 0.8955144882202148, Val recall: 0.8823807835578918\n",
      "\n",
      "Val loss: 0.4224818791403915, Val f1: 0.861910343170166, \n",
      "Val accuracy: 0.8530593514442444, Val precision: 0.8711637854576111, Val recall: 0.8530593514442444\n",
      "\n",
      "Val loss: 0.41896904706954957, Val f1: 0.8528260588645935, \n",
      "Val accuracy: 0.8424080014228821, Val precision: 0.8637728691101074, Val recall: 0.8424080014228821\n",
      "\n",
      "Val loss: 0.41654850564785856, Val f1: 0.8488944172859192, \n",
      "Val accuracy: 0.8383257389068604, Val precision: 0.8600138425827026, Val recall: 0.8383257389068604\n",
      "\n",
      "Val loss: 0.4152082818604651, Val f1: 0.8464102745056152, \n",
      "Val accuracy: 0.8363904356956482, Val precision: 0.8569363951683044, Val recall: 0.8363904356956482\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0130985379219055, Val f1: 1.4900147914886475, \n",
      "Val accuracy: 1.4728683233261108, Val precision: 1.5077940225601196, Val recall: 1.4728683233261108\n",
      "\n",
      "Val loss: 0.6864254474639893, Val f1: 0.9863801002502441, \n",
      "Val accuracy: 0.9636570811271667, Val precision: 1.0106391906738281, Val recall: 0.9636570811271667\n",
      "\n",
      "Val loss: 0.6168511152267456, Val f1: 0.8879365921020508, \n",
      "Val accuracy: 0.8774645924568176, Val precision: 0.8994137048721313, Val recall: 0.8774645924568176\n",
      "\n",
      "Val loss: 0.5881039925983974, Val f1: 0.8486909866333008, \n",
      "Val accuracy: 0.837703287601471, Val precision: 0.8605151772499084, Val recall: 0.837703287601471\n",
      "\n",
      "Val loss: 0.5723139577441745, Val f1: 0.8253871202468872, \n",
      "Val accuracy: 0.8140040636062622, Val precision: 0.8375623226165771, Val recall: 0.8140040636062622\n",
      "\n",
      "\n",
      "starting Epoch 9\n",
      "Training...\n",
      "Train loss: 0.4213947393000126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.40717183459888806\n",
      "Train loss: 0.4009020107984543\n",
      "Train loss: 0.39937199007219343\n",
      "Train loss: 0.39911837804885136\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.41459290869534016, Val f1: 0.9004901051521301, \n",
      "Val accuracy: 0.8861701488494873, Val precision: 0.9154819846153259, Val recall: 0.8861701488494873\n",
      "\n",
      "Val loss: 0.40197783618262317, Val f1: 0.872898280620575, \n",
      "Val accuracy: 0.8581826686859131, Val precision: 0.888388991355896, Val recall: 0.8581826686859131\n",
      "\n",
      "Val loss: 0.39793848276138305, Val f1: 0.8643532395362854, \n",
      "Val accuracy: 0.8493341207504272, Val precision: 0.8802106976509094, Val recall: 0.8493341207504272\n",
      "\n",
      "Val loss: 0.39598273608221934, Val f1: 0.8598669767379761, \n",
      "Val accuracy: 0.8440693020820618, Val precision: 0.8765546679496765, Val recall: 0.8440693020820618\n",
      "\n",
      "Val loss: 0.3957655185035297, Val f1: 0.8569408655166626, \n",
      "Val accuracy: 0.841157078742981, Val precision: 0.8736009001731873, Val recall: 0.841157078742981\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0138456225395203, Val f1: 1.4607800245285034, \n",
      "Val accuracy: 1.4261457920074463, Val precision: 1.4972491264343262, Val recall: 1.4261457920074463\n",
      "\n",
      "Val loss: 0.687801738580068, Val f1: 0.9743843078613281, \n",
      "Val accuracy: 0.9391468167304993, Val precision: 1.0128916501998901, Val recall: 0.9391468167304993\n",
      "\n",
      "Val loss: 0.6169755041599274, Val f1: 0.8798686861991882, \n",
      "Val accuracy: 0.8563068509101868, Val precision: 0.9054730534553528, Val recall: 0.8563068509101868\n",
      "\n",
      "Val loss: 0.5874979708875928, Val f1: 0.841808021068573, \n",
      "Val accuracy: 0.8199083209037781, Val precision: 0.8654331564903259, Val recall: 0.8199083209037781\n",
      "\n",
      "Val loss: 0.5708950791094038, Val f1: 0.8208038210868835, \n",
      "Val accuracy: 0.7996818423271179, Val precision: 0.8435205817222595, Val recall: 0.7996818423271179\n",
      "\n",
      "\n",
      "starting Epoch 10\n",
      "Training...\n",
      "Train loss: 0.39709048718214035\n",
      "Train loss: 0.38391498453689343\n",
      "Train loss: 0.3810352790355682\n",
      "Train loss: 0.3812246095778337\n",
      "Train loss: 0.3804177727018084\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.40006399527192116, Val f1: 0.9108855128288269, \n",
      "Val accuracy: 0.9001154899597168, Val precision: 0.9220905303955078, Val recall: 0.9001154899597168\n",
      "\n",
      "Val loss: 0.3847704033056895, Val f1: 0.8847246170043945, \n",
      "Val accuracy: 0.8774017095565796, Val precision: 0.8923566341400146, Val recall: 0.8774017095565796\n",
      "\n",
      "Val loss: 0.38017610371112825, Val f1: 0.8742157220840454, \n",
      "Val accuracy: 0.8666905760765076, Val precision: 0.882091760635376, Val recall: 0.8666905760765076\n",
      "\n",
      "Val loss: 0.37784848818138467, Val f1: 0.8704951405525208, \n",
      "Val accuracy: 0.8637208342552185, Val precision: 0.8776174187660217, Val recall: 0.8637208342552185\n",
      "\n",
      "Val loss: 0.3756260843504043, Val f1: 0.8692882061004639, \n",
      "Val accuracy: 0.8625854253768921, Val precision: 0.8763243556022644, Val recall: 0.8625854253768921\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0169847011566162, Val f1: 1.4823431968688965, \n",
      "Val accuracy: 1.470872402191162, Val precision: 1.4940038919448853, Val recall: 1.470872402191162\n",
      "\n",
      "Val loss: 0.6908060908317566, Val f1: 0.9879388213157654, \n",
      "Val accuracy: 0.9674234986305237, Val precision: 1.0098406076431274, Val recall: 0.9674234986305237\n",
      "\n",
      "Val loss: 0.6192447781562805, Val f1: 0.8895909190177917, \n",
      "Val accuracy: 0.8792828321456909, Val precision: 0.9008032083511353, Val recall: 0.8792828321456909\n",
      "\n",
      "Val loss: 0.5896492941038949, Val f1: 0.8511911630630493, \n",
      "Val accuracy: 0.8414062857627869, Val precision: 0.8616839647293091, Val recall: 0.8414062857627869\n",
      "\n",
      "Val loss: 0.5724845694171058, Val f1: 0.8294727802276611, \n",
      "Val accuracy: 0.8210536241531372, Val precision: 0.8384902477264404, Val recall: 0.8210536241531372\n",
      "\n",
      "\n",
      "starting Epoch 11\n",
      "Training...\n",
      "Train loss: 0.3756902329623699\n",
      "Train loss: 0.36814345103321655\n",
      "Train loss: 0.36482893824577334\n",
      "Train loss: 0.3658001889933401\n",
      "Train loss: 0.3650961855337733\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.37924397736787796, Val f1: 0.9167346954345703, \n",
      "Val accuracy: 0.9273858070373535, Val precision: 0.9065454602241516, Val recall: 0.9273858070373535\n",
      "\n",
      "Val loss: 0.3677459648161223, Val f1: 0.891934871673584, \n",
      "Val accuracy: 0.8982411623001099, Val precision: 0.8859947323799133, Val recall: 0.8982411623001099\n",
      "\n",
      "Val loss: 0.363934788107872, Val f1: 0.8845757246017456, \n",
      "Val accuracy: 0.8899489045143127, Val precision: 0.8795072436332703, Val recall: 0.8899489045143127\n",
      "\n",
      "Val loss: 0.3618797682114501, Val f1: 0.8808667063713074, \n",
      "Val accuracy: 0.8854203224182129, Val precision: 0.8765913844108582, Val recall: 0.8854203224182129\n",
      "\n",
      "Val loss: 0.36005248590594247, Val f1: 0.8792377710342407, \n",
      "Val accuracy: 0.8839401006698608, Val precision: 0.8747922778129578, Val recall: 0.8839401006698608\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0174797177314758, Val f1: 1.4822583198547363, \n",
      "Val accuracy: 1.490339994430542, Val precision: 1.4743225574493408, Val recall: 1.490339994430542\n",
      "\n",
      "Val loss: 0.6954398155212402, Val f1: 0.9902719855308533, \n",
      "Val accuracy: 0.9828197360038757, Val precision: 0.9983593821525574, Val recall: 0.9828197360038757\n",
      "\n",
      "Val loss: 0.6235955238342286, Val f1: 0.8921051025390625, \n",
      "Val accuracy: 0.8973466753959656, Val precision: 0.8878459930419922, Val recall: 0.8973466753959656\n",
      "\n",
      "Val loss: 0.593472787312099, Val f1: 0.8540350794792175, \n",
      "Val accuracy: 0.8577793836593628, Val precision: 0.8509929776191711, Val recall: 0.8577793836593628\n",
      "\n",
      "Val loss: 0.5750184820757972, Val f1: 0.8321011066436768, \n",
      "Val accuracy: 0.8357147574424744, Val precision: 0.8290810585021973, Val recall: 0.8357147574424744\n",
      "\n",
      "\n",
      "starting Epoch 12\n",
      "Training...\n",
      "Train loss: 0.35225979052484035\n",
      "Train loss: 0.3478127293514483\n",
      "Train loss: 0.3470823073387146\n",
      "Train loss: 0.3473172726026222\n",
      "Train loss: 0.3481834474064055\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.3540622144937515, Val f1: 0.9344732761383057, \n",
      "Val accuracy: 0.9340869188308716, Val precision: 0.9350770711898804, Val recall: 0.9340869188308716\n",
      "\n",
      "Val loss: 0.3484122464151094, Val f1: 0.9027052521705627, \n",
      "Val accuracy: 0.8999053239822388, Val precision: 0.9057083129882812, Val recall: 0.8999053239822388\n",
      "\n",
      "Val loss: 0.34453989028930665, Val f1: 0.8945940136909485, \n",
      "Val accuracy: 0.8920931220054626, Val precision: 0.8973265290260315, Val recall: 0.8920931220054626\n",
      "\n",
      "Val loss: 0.343358502903981, Val f1: 0.8895135521888733, \n",
      "Val accuracy: 0.8858435750007629, Val precision: 0.893477201461792, Val recall: 0.8858435750007629\n",
      "\n",
      "Val loss: 0.3423984795808792, Val f1: 0.8863140344619751, \n",
      "Val accuracy: 0.881914496421814, Val precision: 0.8910082578659058, Val recall: 0.881914496421814\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0274733901023865, Val f1: 1.4754939079284668, \n",
      "Val accuracy: 1.4592901468276978, Val precision: 1.4925071001052856, Val recall: 1.4592901468276978\n",
      "\n",
      "Val loss: 0.7033886512120565, Val f1: 0.9820659756660461, \n",
      "Val accuracy: 0.9610469937324524, Val precision: 1.0047004222869873, Val recall: 0.9610469937324524\n",
      "\n",
      "Val loss: 0.6300373792648315, Val f1: 0.8862656354904175, \n",
      "Val accuracy: 0.8766794204711914, Val precision: 0.8969277143478394, Val recall: 0.8766794204711914\n",
      "\n",
      "Val loss: 0.5991422619138446, Val f1: 0.8485148549079895, \n",
      "Val accuracy: 0.8387446403503418, Val precision: 0.8591476082801819, Val recall: 0.8387446403503418\n",
      "\n",
      "Val loss: 0.5799564917882284, Val f1: 0.8263652920722961, \n",
      "Val accuracy: 0.8180129528045654, Val precision: 0.8355228900909424, Val recall: 0.8180129528045654\n",
      "\n",
      "\n",
      "starting Epoch 13\n",
      "Training...\n",
      "Train loss: 0.3407184947282076\n",
      "Train loss: 0.3312100659717213\n",
      "Train loss: 0.33169076263904573\n",
      "Train loss: 0.333456716430721\n",
      "Train loss: 0.3342121378296897\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.3518406506627798, Val f1: 0.9273478388786316, \n",
      "Val accuracy: 0.8825100660324097, Val precision: 0.977372944355011, Val recall: 0.8825100660324097\n",
      "\n",
      "Val loss: 0.34196925976059656, Val f1: 0.8974957466125488, \n",
      "Val accuracy: 0.8542453646659851, Val precision: 0.9456662535667419, Val recall: 0.8542453646659851\n",
      "\n",
      "Val loss: 0.33778700709342957, Val f1: 0.8890721201896667, \n",
      "Val accuracy: 0.8464784026145935, Val precision: 0.9363973140716553, Val recall: 0.8464784026145935\n",
      "\n",
      "Val loss: 0.3357927954908627, Val f1: 0.8841213583946228, \n",
      "Val accuracy: 0.8429735898971558, Val precision: 0.9297182559967041, Val recall: 0.8429735898971558\n",
      "\n",
      "Val loss: 0.33329701565560843, Val f1: 0.8823829889297485, \n",
      "Val accuracy: 0.8417346477508545, Val precision: 0.9273996949195862, Val recall: 0.8417346477508545\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0413256883621216, Val f1: 1.4592807292938232, \n",
      "Val accuracy: 1.3733367919921875, Val precision: 1.556715965270996, Val recall: 1.3733367919921875\n",
      "\n",
      "Val loss: 0.7172936201095581, Val f1: 0.9620363712310791, \n",
      "Val accuracy: 0.8980839252471924, Val precision: 1.0366005897521973, Val recall: 0.8980839252471924\n",
      "\n",
      "Val loss: 0.6409332036972046, Val f1: 0.8707749247550964, \n",
      "Val accuracy: 0.8172489404678345, Val precision: 0.9324637651443481, Val recall: 0.8172489404678345\n",
      "\n",
      "Val loss: 0.6107023102896554, Val f1: 0.8302370309829712, \n",
      "Val accuracy: 0.7797426581382751, Val precision: 0.8881989121437073, Val recall: 0.7797426581382751\n",
      "\n",
      "Val loss: 0.5907350546783872, Val f1: 0.8077547550201416, \n",
      "Val accuracy: 0.7597098350524902, Val precision: 0.8628396391868591, Val recall: 0.7597098350524902\n",
      "\n",
      "\n",
      "starting Epoch 14\n",
      "Training...\n",
      "Train loss: 0.3309396766126156\n",
      "Train loss: 0.3198582006223274\n",
      "Train loss: 0.3173757988214493\n",
      "Train loss: 0.31799395716012413\n",
      "Train loss: 0.32035145269972937\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.3317786641418934, Val f1: 0.9484884738922119, \n",
      "Val accuracy: 0.955554187297821, Val precision: 0.9417282938957214, Val recall: 0.955554187297821\n",
      "\n",
      "Val loss: 0.32264942021080945, Val f1: 0.9187121391296387, \n",
      "Val accuracy: 0.9261485934257507, Val precision: 0.9115757346153259, Val recall: 0.9261485934257507\n",
      "\n",
      "Val loss: 0.3205416423082352, Val f1: 0.9078088998794556, \n",
      "Val accuracy: 0.9145300388336182, Val precision: 0.9013710618019104, Val recall: 0.9145300388336182\n",
      "\n",
      "Val loss: 0.3189630299361784, Val f1: 0.902931809425354, \n",
      "Val accuracy: 0.9090922474861145, Val precision: 0.8970224261283875, Val recall: 0.9090922474861145\n",
      "\n",
      "Val loss: 0.31809219327710925, Val f1: 0.9007377624511719, \n",
      "Val accuracy: 0.9066468477249146, Val precision: 0.8950724601745605, Val recall: 0.9066468477249146\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0527885556221008, Val f1: 1.4918646812438965, \n",
      "Val accuracy: 1.4999260902404785, Val precision: 1.4839084148406982, Val recall: 1.4999260902404785\n",
      "\n",
      "Val loss: 0.7227885325749716, Val f1: 0.9909054636955261, \n",
      "Val accuracy: 0.9853715896606445, Val precision: 0.9969338774681091, Val recall: 0.9853715896606445\n",
      "\n",
      "Val loss: 0.6477563619613648, Val f1: 0.8931724429130554, \n",
      "Val accuracy: 0.8984681963920593, Val precision: 0.8886550068855286, Val recall: 0.8984681963920593\n",
      "\n",
      "Val loss: 0.6151697891099113, Val f1: 0.8520949482917786, \n",
      "Val accuracy: 0.8553761839866638, Val precision: 0.8493728041648865, Val recall: 0.8553761839866638\n",
      "\n",
      "Val loss: 0.5944998893472884, Val f1: 0.8306735754013062, \n",
      "Val accuracy: 0.8348017334938049, Val precision: 0.8270711898803711, Val recall: 0.8348017334938049\n",
      "\n",
      "\n",
      "starting Epoch 15\n",
      "Training...\n",
      "Train loss: 0.30898088961839676\n",
      "Train loss: 0.3035917616251743\n",
      "Train loss: 0.305123929977417\n",
      "Train loss: 0.30669578020252397\n",
      "Train loss: 0.30759864016657784\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.3126103114336729, Val f1: 0.9532813429832458, \n",
      "Val accuracy: 0.9416491389274597, Val precision: 0.9654871225357056, Val recall: 0.9416491389274597\n",
      "\n",
      "Val loss: 0.30552470142191107, Val f1: 0.9241401553153992, \n",
      "Val accuracy: 0.9143343567848206, Val precision: 0.9343928694725037, Val recall: 0.9143343567848206\n",
      "\n",
      "Val loss: 0.30398249983787534, Val f1: 0.9136402606964111, \n",
      "Val accuracy: 0.9043323993682861, Val precision: 0.9233688116073608, Val recall: 0.9043323993682861\n",
      "\n",
      "Val loss: 0.30169446032438707, Val f1: 0.9088138937950134, \n",
      "Val accuracy: 0.8999090194702148, Val precision: 0.9181459546089172, Val recall: 0.8999090194702148\n",
      "\n",
      "Val loss: 0.3000423390240896, Val f1: 0.906609296798706, \n",
      "Val accuracy: 0.8978075385093689, Val precision: 0.9158228635787964, Val recall: 0.8978075385093689\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0619418025016785, Val f1: 1.47707998752594, \n",
      "Val accuracy: 1.449014663696289, Val precision: 1.5062663555145264, Val recall: 1.449014663696289\n",
      "\n",
      "Val loss: 0.7364908258120219, Val f1: 0.9797892570495605, \n",
      "Val accuracy: 0.9519322514533997, Val precision: 1.0097463130950928, Val recall: 0.9519322514533997\n",
      "\n",
      "Val loss: 0.6593928575515747, Val f1: 0.8832422494888306, \n",
      "Val accuracy: 0.8659942746162415, Val precision: 0.9018062353134155, Val recall: 0.8659942746162415\n",
      "\n",
      "Val loss: 0.6271262083734784, Val f1: 0.8438081741333008, \n",
      "Val accuracy: 0.8271199464797974, Val precision: 0.8616570234298706, Val recall: 0.8271199464797974\n",
      "\n",
      "Val loss: 0.6050617628627353, Val f1: 0.8231898546218872, \n",
      "Val accuracy: 0.8084898591041565, Val precision: 0.838893711566925, Val recall: 0.8084898591041565\n",
      "\n",
      "\n",
      "starting Epoch 16\n",
      "Training...\n",
      "Train loss: 0.2984409052878618\n",
      "Train loss: 0.2934033726200913\n",
      "Train loss: 0.29348387658596037\n",
      "Train loss: 0.29349142668852163\n",
      "Train loss: 0.2967827994199026\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.31227535009384155, Val f1: 0.9583984613418579, \n",
      "Val accuracy: 0.9531486630439758, Val precision: 0.9638369083404541, Val recall: 0.9531486630439758\n",
      "\n",
      "Val loss: 0.3029873316938227, Val f1: 0.9311672449111938, \n",
      "Val accuracy: 0.9279509782791138, Val precision: 0.9345760941505432, Val recall: 0.9279509782791138\n",
      "\n",
      "Val loss: 0.30007686018943786, Val f1: 0.9202221035957336, \n",
      "Val accuracy: 0.9180189371109009, Val precision: 0.922583818435669, Val recall: 0.9180189371109009\n",
      "\n",
      "Val loss: 0.29888584720554634, Val f1: 0.9154536128044128, \n",
      "Val accuracy: 0.9140381217002869, Val precision: 0.9170300364494324, Val recall: 0.9140381217002869\n",
      "\n",
      "Val loss: 0.29793604818128405, Val f1: 0.9124597907066345, \n",
      "Val accuracy: 0.9104770421981812, Val precision: 0.9146171808242798, Val recall: 0.9104770421981812\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0685449242591858, Val f1: 1.4804623126983643, \n",
      "Val accuracy: 1.4761710166931152, Val precision: 1.4847893714904785, Val recall: 1.4761710166931152\n",
      "\n",
      "Val loss: 0.7418035864830017, Val f1: 0.9806978702545166, \n",
      "Val accuracy: 0.967902660369873, Val precision: 0.9941481947898865, Val recall: 0.967902660369873\n",
      "\n",
      "Val loss: 0.6633573174476624, Val f1: 0.8833586573600769, \n",
      "Val accuracy: 0.8775733709335327, Val precision: 0.8895676732063293, Val recall: 0.8775733709335327\n",
      "\n",
      "Val loss: 0.6297927243368966, Val f1: 0.8420347571372986, \n",
      "Val accuracy: 0.834844708442688, Val precision: 0.8496187329292297, Val recall: 0.834844708442688\n",
      "\n",
      "Val loss: 0.6076075302229987, Val f1: 0.8216734528541565, \n",
      "Val accuracy: 0.8150899410247803, Val precision: 0.828672468662262, Val recall: 0.8150899410247803\n",
      "\n",
      "\n",
      "starting Epoch 17\n",
      "Training...\n",
      "Train loss: 0.2897618431597948\n",
      "Train loss: 0.2837556139989333\n",
      "Train loss: 0.2841657030582428\n",
      "Train loss: 0.28392178398459705\n",
      "Train loss: 0.2860482129312697\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.2965652570128441, Val f1: 0.962836503982544, \n",
      "Val accuracy: 0.9654067754745483, Val precision: 0.9604487419128418, Val recall: 0.9654067754745483\n",
      "\n",
      "Val loss: 0.2886079956184734, Val f1: 0.9335348606109619, \n",
      "Val accuracy: 0.9354337453842163, Val precision: 0.9318256974220276, Val recall: 0.9354337453842163\n",
      "\n",
      "Val loss: 0.2847406947612762, Val f1: 0.9252398610115051, \n",
      "Val accuracy: 0.927157461643219, Val precision: 0.9234960675239563, Val recall: 0.927157461643219\n",
      "\n",
      "Val loss: 0.28291594048044577, Val f1: 0.9203703999519348, \n",
      "Val accuracy: 0.921402096748352, Val precision: 0.919490396976471, Val recall: 0.921402096748352\n",
      "\n",
      "Val loss: 0.28198922070718946, Val f1: 0.9178906679153442, \n",
      "Val accuracy: 0.9190056920051575, Val precision: 0.9169299006462097, Val recall: 0.9190056920051575\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1003623604774475, Val f1: 1.4736993312835693, \n",
      "Val accuracy: 1.4801630973815918, Val precision: 1.4672926664352417, Val recall: 1.4801630973815918\n",
      "\n",
      "Val loss: 0.7665205995241801, Val f1: 0.9832121729850769, \n",
      "Val accuracy: 0.9762681126594543, Val precision: 0.9906759262084961, Val recall: 0.9762681126594543\n",
      "\n",
      "Val loss: 0.6882116556167602, Val f1: 0.8849565386772156, \n",
      "Val accuracy: 0.8857929110527039, Val precision: 0.8845979571342468, Val recall: 0.8857929110527039\n",
      "\n",
      "Val loss: 0.6529152904238019, Val f1: 0.8438118696212769, \n",
      "Val accuracy: 0.8431220650672913, Val precision: 0.8448596596717834, Val recall: 0.8431220650672913\n",
      "\n",
      "Val loss: 0.6299786369005839, Val f1: 0.8225363492965698, \n",
      "Val accuracy: 0.8221197128295898, Val precision: 0.8232586979866028, Val recall: 0.8221197128295898\n",
      "\n",
      "\n",
      "starting Epoch 18\n",
      "Training...\n",
      "Train loss: 0.27735695242881775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27480835444999463\n",
      "Train loss: 0.27381361663341525\n",
      "Train loss: 0.2749817135618694\n",
      "Train loss: 0.278183676302433\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.28611546847969294, Val f1: 0.9650059938430786, \n",
      "Val accuracy: 0.9618735909461975, Val precision: 0.9683010578155518, Val recall: 0.9618735909461975\n",
      "\n",
      "Val loss: 0.27661316187092755, Val f1: 0.9371946454048157, \n",
      "Val accuracy: 0.9315741062164307, Val precision: 0.9430536031723022, Val recall: 0.9315741062164307\n",
      "\n",
      "Val loss: 0.2735863247513771, Val f1: 0.9285099506378174, \n",
      "Val accuracy: 0.9225592017173767, Val precision: 0.9347074627876282, Val recall: 0.9225592017173767\n",
      "\n",
      "Val loss: 0.27127734649537216, Val f1: 0.924541711807251, \n",
      "Val accuracy: 0.917679488658905, Val precision: 0.93167644739151, Val recall: 0.917679488658905\n",
      "\n",
      "Val loss: 0.27072632188598317, Val f1: 0.9214450120925903, \n",
      "Val accuracy: 0.9141009449958801, Val precision: 0.9290620684623718, Val recall: 0.9141009449958801\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.119994044303894, Val f1: 1.4712417125701904, \n",
      "Val accuracy: 1.449014663696289, Val precision: 1.4941720962524414, Val recall: 1.449014663696289\n",
      "\n",
      "Val loss: 0.7795072992642721, Val f1: 0.976637601852417, \n",
      "Val accuracy: 0.9544480443000793, Val precision: 1.0001176595687866, Val recall: 0.9544480443000793\n",
      "\n",
      "Val loss: 0.6990727782249451, Val f1: 0.8809814453125, \n",
      "Val accuracy: 0.8702815175056458, Val precision: 0.8925280570983887, Val recall: 0.8702815175056458\n",
      "\n",
      "Val loss: 0.663542994431087, Val f1: 0.8395949602127075, \n",
      "Val accuracy: 0.8272340893745422, Val precision: 0.852784276008606, Val recall: 0.8272340893745422\n",
      "\n",
      "Val loss: 0.6402226289113363, Val f1: 0.8191264867782593, \n",
      "Val accuracy: 0.8075194358825684, Val precision: 0.8314789533615112, Val recall: 0.8075194358825684\n",
      "\n",
      "\n",
      "starting Epoch 19\n",
      "Training...\n",
      "Train loss: 0.27070982102304697\n",
      "Train loss: 0.2655145205331571\n",
      "Train loss: 0.26546894788742065\n",
      "Train loss: 0.26570726975576203\n",
      "Train loss: 0.26623744588522685\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.267356994561851, Val f1: 0.973676323890686, \n",
      "Val accuracy: 0.9766587615013123, Val precision: 0.9708315134048462, Val recall: 0.9766587615013123\n",
      "\n",
      "Val loss: 0.26133833915898297, Val f1: 0.9429711699485779, \n",
      "Val accuracy: 0.9436331987380981, Val precision: 0.942462146282196, Val recall: 0.9436331987380981\n",
      "\n",
      "Val loss: 0.25886122465133665, Val f1: 0.9335507750511169, \n",
      "Val accuracy: 0.9341567158699036, Val precision: 0.9331288933753967, Val recall: 0.9341567158699036\n",
      "\n",
      "Val loss: 0.2562906332870028, Val f1: 0.9294019341468811, \n",
      "Val accuracy: 0.9302092790603638, Val precision: 0.9287688732147217, Val recall: 0.9302092790603638\n",
      "\n",
      "Val loss: 0.256670162436508, Val f1: 0.9257420897483826, \n",
      "Val accuracy: 0.9266704320907593, Val precision: 0.9250004291534424, Val recall: 0.9266704320907593\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1549435257911682, Val f1: 1.4778060913085938, \n",
      "Val accuracy: 1.4763679504394531, Val precision: 1.4792470932006836, Val recall: 1.4763679504394531\n",
      "\n",
      "Val loss: 0.8093216419219971, Val f1: 0.9826313853263855, \n",
      "Val accuracy: 0.9731454849243164, Val precision: 0.9926382899284363, Val recall: 0.9731454849243164\n",
      "\n",
      "Val loss: 0.7279359459877014, Val f1: 0.8822253346443176, \n",
      "Val accuracy: 0.8830936551094055, Val precision: 0.8819655179977417, Val recall: 0.8830936551094055\n",
      "\n",
      "Val loss: 0.689338709626879, Val f1: 0.842217743396759, \n",
      "Val accuracy: 0.8406580090522766, Val precision: 0.8442580103874207, Val recall: 0.8406580090522766\n",
      "\n",
      "Val loss: 0.6641490194532607, Val f1: 0.8211855292320251, \n",
      "Val accuracy: 0.8200522661209106, Val precision: 0.8227018713951111, Val recall: 0.8200522661209106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "f1s = []\n",
    "f1s_eval = []\n",
    "accuracies = []\n",
    "accuracies_eval = []\n",
    "precisions = []\n",
    "precisions_eval = []\n",
    "recalls = []\n",
    "recalls_eval = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    print('Training...')\n",
    "    epoch_loss = train(model2, train_iterator, optimizer2, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "    print('\\nEvaluating on train...')\n",
    "    f1_on_train, accuracy_on_train, precision_on_train, recall_on_train,_ = evaluate(model2, train_iterator, criterion)\n",
    "    f1s.append(f1_on_train)\n",
    "    accuracies.append(accuracy_on_train)\n",
    "    precisions.append(precision_on_train)\n",
    "    recalls.append(recall_on_train)\n",
    "    print('\\nEvaluating on test...')\n",
    "    f1_on_test, accuracy_on_test, precision_on_test, recall_on_test, epoch_loss_on_test = evaluate(model2, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)\n",
    "    f1s_eval.append(f1_on_test)\n",
    "    accuracies_eval.append(accuracy_on_test)\n",
    "    precisions_eval.append(precision_on_test)\n",
    "    recalls_eval.append(recall_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6640249578790232, 0.611968916925517, 0.5759799155321988, 0.5426075519485907, 0.5119692693379793, 0.4851822592318058, 0.45944760231809184, 0.4341657002541152, 0.41469747166741977, 0.3945130509409038, 0.3762897849082947, 0.3614892197603529, 0.34448459168726747, 0.3300530602308837, 0.3168646984479644, 0.3042484860528599, 0.2935790148648349, 0.2833469513465058, 0.274687607857314, 0.2636931027201089] \n",
      "\n",
      " [0.6260262072086334, 0.6003160536289215, 0.5799386262893677, 0.559565269947052, 0.5434396684169769, 0.5327178657054901, 0.5241954326629639, 0.518200546503067, 0.5150825619697571, 0.5138055711984635, 0.5152361124753952, 0.5175166338682174, 0.5219608426094056, 0.5316615492105484, 0.5350499004125595, 0.5445555865764617, 0.5468467772006989, 0.5669807732105255, 0.5762003660202026, 0.5977341175079346]\n"
     ]
    }
   ],
   "source": [
    "print(losses, '\\n\\n', losses_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeVhV1f7H8fc5R2ZkUGQUxXkWFRXRrEwUtMxZUsscS9PK/Nng7eZUN29pZoM5lalZDqGZXWfJbBDnHHNGFJNBQGZlOGf//th6kEAFGTbI9/U8+4Gzp/M9dK98WGvttXSKoigIIYQQQlQieq0LEEIIIYQoaxKAhBBCCFHpSAASQgghRKUjAUgIIYQQlY4EICGEEEJUOhKAhBBCCFHpSAASQgghRKUjAUgIIYQQlY4EICGEEEJUOhKAhBDlmo+PD8OHD9e6jFK1bNkydDodkZGRWpciRKUhAUgIYf4FfOfm6upKly5d2LJlS4HX3Lx5k48//hh/f38cHR2xtramYcOGTJgwgbNnz5rPmz59er5737nFxMSU1ccUQgizKloXIIQoP2bOnEmdOnVQFIXY2FiWLVtGz549+emnn3jqqafM58XHxxMcHMyhQ4d46qmnGDJkCPb29pw5c4bVq1ezePFisrKy8tx7wYIF2Nvb53tPJyenUv9cQgjxTxKAhBBmPXr0oG3btubXo0aNws3NjVWrVuUJQMOHD+fPP/8kNDSU/v3757nHu+++y9tvv53v3gMGDMDFxaX0ihdCiCKQLjAhxF05OTlhY2NDlSq5fyvt27ePTZs2MWrUqHzhB8DKyoo5c+aUal0REREMHDiQatWqYWtrS4cOHdi0aVO+8z777DOaNWuGra0tzs7OtG3blu+++858PDU1lYkTJ+Lj44OVlRWurq5069aNw4cP3/W9Q0ND0el07N69O9+xRYsWodPpOHHiBADHjh1j+PDh1K1bF2tra9zd3Rk5ciQJCQn3/Yw6nY7p06fn21/QmKikpCQmTpyIt7c3VlZW1K9fnw8++ACTyXTf9xGispIWICGEWXJyMvHx8SiKQlxcHJ999hlpaWk8++yz5nM2btwIwHPPPVekeycmJubbV6VKlSJ3gcXGxtKxY0cyMjJ45ZVXqF69OsuXL+fpp58mNDSUvn37ArBkyRJeeeUVBgwYwKuvvsrNmzc5duwY+/btY8iQIQCMHTuW0NBQJkyYQNOmTUlISOD333/n1KlTtGnTpsD3f/LJJ7G3t2ft2rU89thjeY6tWbOGZs2a0bx5cwB27NhBREQEI0aMwN3dnZMnT7J48WJOnjzJ3r170el0RfrsBcnIyOCxxx7j77//5sUXX6RWrVrs2bOHKVOmEB0dzbx584r9HkI8lBQhRKX39ddfK0C+zcrKSlm2bFmec/v27asAyvXr1wt172nTphV4b0Bp1KjRfa+vXbu28vzzz5tfT5w4UQGU3377zbwvNTVVqVOnjuLj46MYjUZFURSld+/eSrNmze55b0dHR2X8+PGF+hx3Gjx4sOLq6qrk5OSY90VHRyt6vV6ZOXOmeV9GRka+a1etWqUAyq+//mred/vnf/HiRfM+QJk2bVq+6//583j33XcVOzs75ezZs3nOe+uttxSDwaBcvny5yJ9PiMpAusCEEGbz589nx44d7Nixg5UrV9KlSxdGjx7N+vXrzeekpKQAULVq1SLde926deZ7396+/vrrIte4efNm2rdvzyOPPGLeZ29vzwsvvEBkZCR//fUXoHbfXblyhQMHDtz1Xk5OTuzbt4+rV68WqYaQkBDi4uL45ZdfzPtCQ0MxmUyEhISY99nY2Ji/v3nzJvHx8XTo0AHgnt1sRfH999/TuXNnnJ2diY+PN2+BgYEYjUZ+/fXXEnkfIR420gUmhDBr3759nkHQgwcPpnXr1kyYMIGnnnoKS0tLHBwcAHX8TFG6rx599NESGQR96dIl/P398+1v0qSJ+Xjz5s1588032blzJ+3bt6d+/fp0796dIUOG0KlTJ/M1H374Ic8//zze3t74+fnRs2dPhg0bRt26de9ZQ3BwMI6OjqxZs4auXbsCavdXq1ataNiwofm8xMREZsyYwerVq4mLi8tzj+Tk5Af+Gdzp3LlzHDt2jBo1ahR4/J/vK4RQSQuQEOKu9Ho9Xbp0ITo6mnPnzgHQuHFjAI4fP65laffVpEkT82P5jzzyCOvWreORRx5h2rRp5nMGDRpEREQEn332GZ6ensyePZtmzZrdde6j26ysrOjTpw8//PADOTk5/P333/zxxx95Wn9u33/JkiWMHTuW9evXs337drZu3QrwwAOUjUZjntcmk4lu3brla127vRU0UF0IIS1AQoj7yMnJASAtLQ2AXr16MWvWLFauXEnnzp3LvJ7atWtz5syZfPtPnz5tPn6bnZ0dISEhhISEkJWVRb9+/fjPf/7DlClTsLa2BsDDw4OXXnqJl156ibi4ONq0acN//vMfevTocc86QkJCWL58OWFhYZw6dQpFUfIEoOvXrxMWFsaMGTOYOnWqef/tIHk/zs7OJCUl5dmXlZVFdHR0nn316tUjLS2NwMDAQt1XCKGSFiAhxF1lZ2ezfft2LC0tzV1MAQEBBAcH8+WXX7Jhw4Z812RlZTF58uRSq6lnz57s37+f8PBw87709HQWL16Mj48PTZs2Bcj3qLmlpSVNmzZFURSys7MxGo35uqFcXV3x9PQkMzPzvnUEBgZSrVo11qxZw5o1a2jfvj116tQxHzcYDAAoipLnusI+lVWvXr1843cWL16crwVo0KBBhIeHs23btnz3SEpKMgdYIURe0gIkhDDbsmWLuSUlLi6O7777jnPnzvHWW2+Zx/4ArFixgu7du9OvXz969epF165dsbOz49y5c6xevZro6Oh8cwGFhoYWOBN0t27dcHNzK3SNb731FqtWraJHjx688sorVKtWjeXLl3Px4kXWrVuHXq/+Xde9e3fc3d3p1KkTbm5unDp1is8//5wnn3ySqlWrkpSURM2aNRkwYAC+vr7Y29uzc+dODhw4wEcffXTfOiwsLOjXrx+rV68mPT093+d1cHDg0Ucf5cMPPyQ7OxsvLy+2b9/OxYsXC/U5R48ezdixY+nfvz/dunXj6NGjbNu2Ld84qtdff52NGzfy1FNPMXz4cPz8/EhPT+f48eOEhoYSGRkpE1AKURCNn0ITQpQDBT0Gb21trbRq1UpZsGCBYjKZ8l2TkZGhzJkzR2nXrp1ib2+vWFpaKg0aNFBefvll5fz58+bz7vUYPKDs2rXrnrX987FvRVGUCxcuKAMGDFCcnJwUa2trpX379sr//ve/POcsWrRIefTRR5Xq1asrVlZWSr169ZTXX39dSU5OVhRFUTIzM5XXX39d8fX1VapWrarY2dkpvr6+yhdffFHon9uOHTsUQNHpdEpUVFS+41euXFH69u2rODk5KY6OjsrAgQOVq1ev5nvEvaDH4I1Go/Lmm28qLi4uiq2trRIUFKScP3++wJ9HamqqMmXKFKV+/fqKpaWl4uLionTs2FGZM2eOkpWVVejPI0RlolOUf7TPCiGEEEI85GQMkBBCCCEqHQlAQgghhKh0JAAJIYQQotKRACSEEEKISkcCkBBCCCEqHQlAQgghhKh0ZCLEAphMJq5evUrVqlXR6XRalyOEEEKIQlAUhdTUVDw9Pc2Tot6NBKACXL16FW9vb63LEEIIIcQDiIqKombNmvc8RwJQAapWrQqoP8A7p/8XQgghRPmVkpKCt7e3+ff4vUgAKsDtbi8HBwcJQEIIIUQFU5jhKzIIWgghhBCVjgQgIYQQQlQ6EoCEEEIIUenIGCAhhBCiDJlMJrKysrQuo0KysLDAYDCUyL0kAAkhhBBlJCsri4sXL2IymbQupcJycnLC3d292PP0SQASQgghyoCiKERHR2MwGPD29r7vRH0iL0VRyMjIIC4uDgAPD49i3U8CkBBCCFEGcnJyyMjIwNPTE1tbW63LqZBsbGwAiIuLw9XVtVjdYRI/hRBCiDJgNBoBsLS01LiSiu12eMzOzi7WfSQACSGEEGVI1pgsnpL6+UkAEkIIIUSlIwFICCGEEGXCx8eHefPmaV0GIIOghRBCCHEPjz/+OK1atSqR4HLgwAHs7OxKoKrikxagMnYwMpHkG8UbuCWEEEKUF4qikJOTU6hza9SoUW6egJMAVIb+s+kvBiwMZ8EvF7QuRQghhLiv4cOHs3v3bj755BN0Oh06nY5ly5ah0+nYsmULfn5+WFlZ8fvvv3PhwgV69+6Nm5sb9vb2tGvXjp07d+a53z+7wHQ6HV9++SV9+/bF1taWBg0asHHjxjL5bBKAypB/neoAfP3HRa4m3dC4GiGEEFpSFIWMrBxNNkVRClXjJ598QkBAAGPGjCE6Opro6Gi8vb0BeOutt/jvf//LqVOnaNmyJWlpafTs2ZOwsDD+/PNPgoOD6dWrF5cvX77ne8yYMYNBgwZx7NgxevbsydChQ0lMTCz2z/d+ZAxQGeraxJX2PtXYH5nIxzvOMnugr9YlCSGE0MiNbCNNp27T5L3/mhmEreX9I4CjoyOWlpbY2tri7u4OwOnTpwGYOXMm3bp1M59brVo1fH1zf6+9++67/PDDD2zcuJEJEybc9T2GDx/O4MGDAXj//ff59NNP2b9/P8HBwQ/02QpLWoDKkE6n462ejQFYd/gKZ2JSNa5ICCGEeDBt27bN8zotLY3JkyfTpEkTnJycsLe359SpU/dtAWrZsqX5ezs7OxwcHMzLXZQmaQEqY21qOdOjuTtbTsTwwdbTLB3eTuuShBBCaMDGwsBfM4M0e+/i+ufTXJMnT2bHjh3MmTOH+vXrY2Njw4ABA8jKuvfK9xYWFnle63S6MlksVgKQBl4PasT2v2L5+XQceyMS6FC3utYlCSGEKGM6na5Q3VBas7S0NC/jcS9//PEHw4cPp2/fvoDaIhQZGVnK1T046QLTQN0a9gxurw4im7XldKEHowkhhBBlzcfHh3379hEZGUl8fPxdW2caNGjA+vXrOXLkCEePHmXIkCFl0pLzoCQAaeTVrg2xtTRwNCqJzcdjtC5HCCGEKNDkyZMxGAw0bdqUGjVq3HVMz9y5c3F2dqZjx4706tWLoKAg2rRpU8bVFp5O0bj5Yf78+cyePZuYmBh8fX357LPPaN++/V3PT0pK4u2332b9+vUkJiZSu3Zt5s2bR8+ePQGYPn06M2bMyHNNo0aNzKPWCyMlJQVHR0eSk5NxcHB4sA9WCB/vOMsnYefwqW7LjkmPYWGQPCqEEA+rmzdvcvHiRerUqYO1tbXW5VRY9/o5FuX3t6a/cdesWcOkSZOYNm0ahw8fxtfXl6CgoLuO/s7KyqJbt25ERkYSGhrKmTNnWLJkCV5eXnnOa9asmXm+gujoaH7//fey+DhFNubRurjYWxKZkMGq/fceJS+EEEKIkqNpAJo7dy5jxoxhxIgRNG3alIULF2Jra8vSpUsLPH/p0qUkJiayYcMGOnXqhI+PD4899lieeQcAqlSpgru7u3lzcXEpi49TZPZWVXi1awMAPtl5jrTMwk0lLoQQQoji0SwAZWVlcejQIQIDA3OL0esJDAwkPDy8wGs2btxIQEAA48ePx83NjebNm/P+++/nG51+7tw5PD09qVu3LkOHDr3vHARaeqZ9Leq42JGQnsXiXyO0LkcIIYSoFDQLQPHx8RiNRtzc3PLsd3NzIyam4EHBERERhIaGYjQa2bx5M++88w4fffQR7733nvkcf39/li1bxtatW1mwYAEXL16kc+fOpKbefdLBzMxMUlJS8mxlxcKg5/WgRgAs+TWCuJSbZfbeQgghRGVVoUbdmkwmXF1dWbx4MX5+foSEhPD222+zcOFC8zk9evRg4MCBtGzZkqCgIDZv3kxSUhJr1669631nzZqFo6Ojebu9zklZ6dHcnVbeTtzINjIv7FyZvrcQQghRGWkWgFxcXDAYDMTGxubZHxsba15v5J88PDxo2LAhBkPuDJZNmjQhJibmrjNNOjk50bBhQ86fP3/XWqZMmUJycrJ5i4qKeoBP9OB0Oh1TeqhLZKw5EMWFa2ll+v5CCCFEZaNZALK0tMTPz4+wsDDzPpPJRFhYGAEBAQVe06lTJ86fP59nYqWzZ8/i4eGBpaVlgdekpaVx4cIFPDw87lqLlZUVDg4Oebay5l+3Ol0bu2I0KXy4tfCP7AshhBCi6DTtAps0aRJLlixh+fLlnDp1inHjxpGens6IESMAGDZsGFOmTDGfP27cOBITE3n11Vc5e/YsmzZt4v3332f8+PHmcyZPnszu3buJjIxkz5499O3bF4PBYF5ptjx7s0dj9DrYdjKWQ5cStS5HCCGEeGhpughJSEgI165dY+rUqcTExNCqVSu2bt1qHhh9+fJl9PrcjObt7c22bdt47bXXaNmyJV5eXrz66qu8+eab5nOuXLnC4MGDSUhIoEaNGjzyyCPs3buXGjVqlPnnK6qGblUZ6OfNmoNRzNp8mu/HBqDT6bQuSwghhHjoaD4TdHlUVjNBFyQm+SaPz9nFzWwTi5/zo3uzgsdDCSGEqFgq60zQPj4+TJw4kYkTJ5bI/R6KmaBFfu6O1ozsVAeAD7aeJsdYfheSE0IIISoqCUDl0NjH6+Fsa8GFa+l8f+iK1uUIIYQQDx0JQOWQg7UFE55Ql8j4eMdZMrJkiQwhhBBlb/HixXh6euZ5+hqgd+/ejBw5kgsXLtC7d2/c3Nywt7enXbt27Ny5U6Nqi0YCUDn1bIda1HS2IS41k6W/X9S6HCGEECVNUSArXZutkMN/Bw4cSEJCArt27TLvS0xMZOvWrQwdOpS0tDR69uxJWFgYf/75J8HBwfTq1atcL0F1m6ZPgYm7s6pi4PWgRry6+ggLd0cwuH0tqttbaV2WEEKIkpKdAe97avPe/7oKlnb3Pc3Z2ZkePXrw3Xff0bVrVwBCQ0NxcXGhS5cu6PX6PAuSv/vuu/zwww9s3LiRCRMmlFr5JUFagMqxXi09ae7lQFpmDp/9fPeZrIUQQojSMnToUNatW0dmZiYA3377Lc888wx6vZ60tDQmT55MkyZNcHJywt7enlOnTkkLkCgevV7HW8FNeParfXy77xIjO9WhVnVbrcsSQghREixs1ZYYrd67kHr16oWiKGzatIl27drx22+/8fHHHwPq5MM7duxgzpw51K9fHxsbGwYMGHDX5anKEwlA5dwjDVzo3MCF387FM3v7GT4b3FrrkoQQQpQEna5Q3VBas7a2pl+/fnz77becP3+eRo0a0aZNGwD++OMPhg8fTt++fQF1+anIyEgNqy086QKrAN7q0RidDn46epVjV5K0LkcIIUQlM3ToUDZt2sTSpUsZOnSoeX+DBg1Yv349R44c4ejRowwZMiTfE2PllQSgCqCZpyN9WnkB8N8tp5HJu4UQQpSlJ554gmrVqnHmzBmGDBli3j937lycnZ3p2LEjvXr1IigoyNw6VN5JF1gFMalbQzYdi2bPhQR2n73G441ctS5JCCFEJaHX67l6Nf94JR8fH37++ec8++5coBwot11i0gJUQXhXs2VYQG1AbQUymqQVSAghhHhQEoDKkskEB76EnAcbHT++S32qWlfhdEwqG/78u4SLE0IIISoPCUBlaec02PR/8N1AyEwt8uXOdpaM71IfgI+2n+FmtrGkKxRCCCEqBQlAZanu42BhBxG/wPJekB5f5FsM7+iDh6M1V5NvsnxPZAkXKIQQQlQOEoDKUv2uMPwnsK0OV/+Er7rD9UtFuoW1hYFJ3RoCMH/XeZIyyv9kU0IIIXLJk7zFU1I/PwlAZc3LD0ZuB8dakHhBDUExJ4p0i35tatLYvSopN3P44pcLpVSoEEKIkmQwGAAqxCzJ5VlGRgYAFhYWxbqPTpEomk9KSgqOjo4kJyfj4OBQSm8SDSv7Q9xJsHKEIauhdsdCX77rdBwjlh3AsoqeXZMfx8vJpnTqFEIIUSIUReHy5ctkZ2fj6emJXi9tEEWhKAoZGRnExcXh5OSEh4dHvnOK8vtbAlAByiQAAdxIglXPwOVwMFjBgKXQ5KlCXaooCoOX7GVvRCL92ngxd1Cr0qtTCCFEicjKyuLixYsVZrbk8sjJyQl3d3d0Ol2+YxKAiqnMAhBA9g0IHQlnNoNOD0/NA7/nC3Xp0agkes//A50ONr3cmaaepVyrEEKIYjOZTNIN9oAsLCzMXYkFKcrvb5kJWmsWNjDoG/jfq/DnSvjpFUi/Bp3/T10o7x58vZ14sqUHm45F88HW0ywf2b6MihZCCPGg9Ho91tbWWpdR6UkHZHlgqAJPf66GHoCf34Utb6oTJ97H690bUUWvY/fZa+w5X/TH6oUQQojKSAJQeaHTQdepEPyB+nr/Ilg/+r6zRvu42DHUvxYAs7acxiRLZAghhBD3JQGovOkwFvp/BXoLOLEOvht031mjX+7aADtLA8f/TuZ/x6PLqFAhhBCi4pIAVB61GABD1tyaNXrXfWeNdrG34sXH6gEwZ9sZsnLk6QIhhBDiXiQAlVf1u8LzhZ81enTnOtSoasXlxAzmbD9ThoUKIYQQFY8EoPKsph+M3FaoWaNtLasw8+lmACz+NYJNx6QrTAghhLgbCUDlnUsDGLUNXJtCWgx83RMu7Snw1B4tPHjh0boAvB56lHOxRV9xXgghhKgMJABVBA6eMGIz1AqAzGT4pi+c3lTgqW8ENSKgbnUysoy8+M0hUm9ml3GxQgghRPknAaiisHGG536ARj0h5yaseRYOr8h3WhWDns+GtMbD0ZqI+HQmf39UVh4WQggh/kECUEVye9bo1s+CYoKNL8NvH8E/Ao6LvRVfDG2DpUHPtpOxLNgtK8YLIYQQd9I8AM2fPx8fHx+sra3x9/dn//799zw/KSmJ8ePH4+HhgZWVFQ0bNmTz5s3FumeFcnvW6Ecmqa/DZsLWt/LNGt26ljPTbw2KnrPtDL+fk1mihRBCiNs0DUBr1qxh0qRJTJs2jcOHD+Pr60tQUBBxcXEFnp+VlUW3bt2IjIwkNDSUM2fOsGTJEry8vB74nhWSTgeB0yD4v+rrfQsLnDV6cHtvBrWtiUmBl1cd5sr1DA2KFUIIIcofTVeD9/f3p127dnz++eeAukKut7c3L7/8Mm+99Va+8xcuXMjs2bM5ffo0FhYWJXLPgpTpavDFdex72DAWTDlQtwuEfANWVc2Hb2YbGbgwnON/J9PCy5HvxwZgbXH3lXSFEEKIiqoov781awHKysri0KFDBAYG5haj1xMYGEh4eHiB12zcuJGAgADGjx+Pm5sbzZs35/3338doND7wPSu8lgNhyNq8s0anXDUftrYwsODZNjjbWnD872Sm/nhCBkULIYSo9DQLQPHx8RiNRtzc3PLsd3NzIyYmpsBrIiIiCA0NxWg0snnzZt555x0++ugj3nvvvQe+J0BmZiYpKSl5tgrl9qzRNtXUWaMXdIRT/zMfrulsy6eDW6PXwdqDV1i1P0rDYoUQQgjtaT4IuihMJhOurq4sXrwYPz8/QkJCePvtt1m4cGGx7jtr1iwcHR3Nm7e3dwlVXIZq+sHoneDRCm5chzVD4X+vQZY67qdzgxr8X/dGAEzfeJIjUUlaViuEEKKySo2B74dDmrZjczULQC4uLhgMBmJjY/Psj42Nxd3dvcBrPDw8aNiwIQZD7hiWJk2aEBMTQ1ZW1gPdE2DKlCkkJyebt6ioCtpCUr0ejNoBHV9RXx9cCku6mJfPeOnxegQ1cyPLaGLcykPEp2VqWKwQQohKJ2I3LHwETv6g/pGuIc0CkKWlJX5+foSFhZn3mUwmwsLCCAgIKPCaTp06cf78eUx3PPJ99uxZPDw8sLS0fKB7AlhZWeHg4JBnq7CqWEL3d9VJE+3d4NppWPIE7FuEDpgz0Je6NeyITr7Jy9/9SY5RVo4XQghRykwm2D0bvukD6dfAtRkEztC0JE27wCZNmsSSJUtYvnw5p06dYty4caSnpzNixAgAhg0bxpQpU8znjxs3jsTERF599VXOnj3Lpk2beP/99xk/fnyh71lp1HsCxu2BhsFgzIQtb8B3IVQ1JrPoWT9sLQ2ERyQwe5usHC+EEKIUpSfAdwNh13vqJL6tnlWHbLjU17SsKlq+eUhICNeuXWPq1KnExMTQqlUrtm7dah7EfPnyZfT63Izm7e3Ntm3beO2112jZsiVeXl68+uqrvPnmm4W+Z6Vi5wKDV8P+JbD933BuGyzoSIM+C5g9wJfx3x1m0a8RtKzpxJMtPbSuVgghxMMm6oA63iflClSxhic/UlczKAc0nQeovKpQ8wAVVuxJCB0F106przu+zH+zBrHw9yhsLQ38OL4TDdyq3vseQgghRGEoijpJ7/Z/q/PUVasHg1aAe/NSfdsKMQ+QKGNuzeCFXdButPp6z2e8eWUCfWvdkJXjhRBClJybybB22K1lmnKgaR944ZdSDz9FJQGoMrGwUZsfn/kObJzRxRxlbuLLjLH/g4j4NFk5XgghRPFEH4PFj8OpjaC3gB6zYeAysC5/vSkSgCqjxk+qA6TrPIouJ4O3c+bzheVnhJ+MkJXjhRBCFJ2iwKHl8GUgJEaAozeM3Ab+L6jrV5ZDEoAqKwdPeG4DBE4HfRV66vey2WoKv2z/UVaOF0IIUXhZ6bBhHPz0ivrUcYMgePFXdYLeckwCUGWmN8Ajr8Go7SjOdaipi2eVxbuc+PYtriRUsOVAhBBClL1rZ2FJVzi6CnR66DpNffrYtprWld2XBCABXn7oxv6GscUzGHQKY/melAVB3IyP1LoyIYQQ5dXxUHW1gWun1Il3n/8JOk8CfcWIFhWjSlH6rKpi6L+IhKD5pGJD05y/UL7ohHJivdaVCSGEKE9yMmHT/8G6UZCVBj6d4cXfwOcRrSsrEglAIo/qAc9yqvdmDpkaYGNKQxc6An4cD5lpWpcmhBBCa9cjYWkQHPhSfd15Mgz7EapWvMmGJQCJfNq3bsP+x1fySU5fjIoO/lwJix6Fq39qXZoQQgitnNmS+7vAxhmGhkLXd9TxpBWQBCBRoLFdGvFXowkMzvo3sVSHxAvwZTf441N1UTshhBCVgzEHdk5D+PQAACAASURBVEyFVc+okxx6tVW7vBp007qyYpEAJAqk0+mYM9CXeJe2dL85i33Wj4ApG3a8Ayv7QWqM1iUKIYQobSnRsLwX/PGJ+tp/HIzYAk7e2tZVAiQAibuqam3Bomf9yLZ0JCRpHJt9poCFLUTsggUd4cxWrUsUQghRWiJ+gUWd4fIesKwKA5dDj/9CFUutKysREoDEPTVwq8rsAb6AjpdOt2D346Hg3gIyEmBVCGx+A7Jval2mEEKIkpKRCLvehxV9IP0auDWHF3dDsz5aV1aiJACJ+3qypQcvPloXgHHbUjn15A/QYbx6cP8iWPIExJ3SsEIhhBDFkhYHB76CFb1hdn3Y/QGgQJthMHonVK+ndYUlTqfI6pf5pKSk4OjoSHJyMg4O5W8BNy3kGE0M//oAv5+Px8PRmh/Hd8I19nfYMFb9C6GKNQT9B9qOKrfrvgghhLhDylU49RP89SNc2gPcEQfcWkCnV6DlIM3KexBF+f0tAagAEoAKlpyRTd8FfxBxLZ2WNR1Z80IANlkJsOElOL9DPanRk/D0Z2BXXdtihRBC5Hf9krpS+18b4cr+vMc820DT3tCkV4Vt8ZEAVEwSgO7uUkI6feb/wfWMbHq2cOfzwW3Qo8C+hbBzGhizoKoH9F0EdR/TulwhhBAJF9RWnr9+hOgjeY95d4CmT6uhx6mWNvWVIAlAxSQB6N72X0xk6Jd7yTYqjO9Sj9eDGqsHoo+pU6PHnwV08MhE6PI2GCw0rVcIISqduNNq4Dm1EWJP5O7X6aF2J7Wlp/FT4OChXY2lQAJQMUkAur91h67wf98fBWDOQF8G+NVUD2Slw7Z/waFl6mvPNtD/ywrbnCqEEBWCokDM8dzQE38295i+CtR5FJo8rYYe+xra1VnKJAAVkwSgwpmz7Qyf7zqPhUHHylH++Ne9Y9zPXxth48twMwks7aHnHPB9RgZICyFESVEU+PswnLrVvXU9MveYwRLqPaGGnkY9wLaaZmWWJQlAxSQBqHBMJoUJqw6z+XgMTrYWbHipEz4udrknJF+B9S/Cpd/V1y0GwpMfgbWjNgULIcTDICcTfv9YXacxOSp3fxVrqB8ITftAw+6V8t9aCUDFJAGo8G5kGXlmcThHryRT18WOH17qhKPtHWN+TEb4fS7smgWKUR1k1/8r8G6vXdFCCFFRXTurjrWMOaa+trCDhkHqQOb63cDKXtv6NCYBqJgkABVNXOpN+nz+B1eTb9KxXnWWj2yPheEfc2xGHVD/T5t0CXQGeHwKdJ5UYVcRFkKIMqUocHApbHsbcm6ATTXo8YH69JaFjdbVlRtF+f0tM0GLYnOtas1Xw9thZ2lgz4UE3tlwgny52rsdjP1N7QZTjLDrPXWBveQr2hQthBAVRXo8rBoMmyap4aduF3gpXJ2kUMLPA5MAJEpEEw8HPhvSGr0OVh+IYslvEflPsnZUnwjru0gdGH3pD1jQSR28J4QQIr/zYeri02e3qAObg96HZ9dDVXetK6vwJACJEvNEYzf+/WRTAGZtOc22kzEFn+j7jNoa5OWnPiW2dhhsfEV9hF4IIYS6yPTWKbCyH6TFQo3GMOZnCBgPevnVXRLkpyhK1IhOPjzboRaKAhNXH+HE38kFn1itLozcBo+8Bujg8HJY9Jj6SKcQQlRmcafgy66w9wv1dfsX4IVfwL2FllU9dCQAiRKl0+mY3qsZnRu4cCPbyKjlB4hJvlnwyQYLCJwOw35Ul89IOKeuLL9hPKTepfVICCEeVooC+xbD4sfV2ZttXWDIWug5W8b6lAIJQKLEVTHo+XxIG+q72hObksmo5QfIyMq5+wV1H4Nxe6DFIECBIyvh0zbw6xzIvlFmdQshhGbS4uC7QbDldci5qT7S/lK4+oi7KBUSgESpcLSxYOnz7ahmZ8nJqylMXH0Ek+keMy7YVoP+S2DUTvBqC9np8PO78Hl7OLFe/ctICCEeRme3wRcBcG47GKygx4cw9Huwd9W6soeaBCBRampVt2Xxc35YGvRs/yuWD7aevv9F3u1g9E7o9yU4eEHyZQgdAUuDZXyQEOLhkn0DNr+utvxkxINrM3Wsj/+LsmxQGSgXAWj+/Pn4+PhgbW2Nv78/+/fvv+u5y5YtQ6fT5dmsra3znDN8+PB85wQHB5f2xxAFaOtTjQ8HtARg0a8RrDlw+f4X6XTQciBMOAiP/wssbCFqLyzpAj+Mg5ToUq5aCCFKWcwJdazP/sXq6w4vqU95uTXVtKzKRPMAtGbNGiZNmsS0adM4fPgwvr6+BAUFERcXd9drHBwciI6ONm+XLl3Kd05wcHCec1atWlWaH0PcQ5/WXrzStQEAb/9wgj0X4gt3oaUtPP6mGoRaPqPuO/odfNYGds+W8UFCiIrHZILwL9Q/6K6dBjtXGLoOgmeBhfX9rxclRvMANHfuXMaMGcOIESNo2rQpCxcuxNbWlqVLl971Gp1Oh7u7u3lzc3PLd46VlVWec5ydnUvzY4j7eC2wAb18PckxKYxbeZiIa2mFv9jRC/otgtE/Q832kJ2hziT9eTs4Hirjg4QQFUNqDHzbH7ZNAWMWNOyhDnRuEKh1ZZWSpgEoKyuLQ4cOERiY+x9fr9cTGBhIeHj4Xa9LS0ujdu3aeHt707t3b06ePJnvnF9++QVXV1caNWrEuHHjSEhIKJXPIApHp9Mxe0BLWtdyIvlGNiOXHeB6elbRblLTD0ZtVxdTdaiproK8bhQsDYIrh0qncCGEKAmnN6szOl/4WV21/cmPYPAqsHPRurJKS9MAFB8fj9FozNeC4+bmRkxMwfPANGrUiKVLl/Ljjz+ycuVKTCYTHTt25MqV3DWlgoODWbFiBWFhYXzwwQfs3r2bHj16YDQaC7xnZmYmKSkpeTZR8qwtDCx+ri1eTjZEJmQwduUhsnJMRbuJTgctBsDLB6HLv2+ND9oHXz4B61+ElKulU7wQQjyIrAz432uwejBkJKiTGb74K7QbLQOdNabpavBXr17Fy8uLPXv2EBAQYN7/xhtvsHv3bvbt23ffe2RnZ9OkSRMGDx7Mu+++W+A5ERER1KtXj507d9K1a9d8x6dPn86MGTPy7ZfV4EvHmZhU+i/YQ1pmDgP8ajJ7QEt0D/oPQUo0hM1UxwaBGog6TYSOL6tjiIQQQivRRyF0lDrJK0DABOg6FapYaVvXQ6zCrAbv4uKCwWAgNjY2z/7Y2Fjc3Qu30JuFhQWtW7fm/Pnzdz2nbt26uLi43PWcKVOmkJycbN6ioqIK/yFEkTVyr8rntxZODT10hQW7Lzz4zRw8oO8CGLMLvDuo44N+eR8+bwvHvpfxQUKIkqcocOM6xJ+Hy3vh9CY4tBx++wi2/gvWvwDf9IMlXdXwY+8Oz22AoP9I+ClHqmj55paWlvj5+REWFkafPn0AMJlMhIWFMWHChELdw2g0cvz4cXr27HnXc65cuUJCQgIeHh4FHreyssLKSv5HWZYeb+TKtF7NmLbxJB9uPUOd6nb0aFHwf59C8WoDI7fCyR9gxzR1/qD1o2H/Igiapc4vJIQQBTHmqN1TGfHq1/Q7vxaw70YimO4xu/2dGj8FT3+mTvYqyhVNAxDApEmTeP7552nbti3t27dn3rx5pKenM2LECACGDRuGl5cXs2bNAmDmzJl06NCB+vXrk5SUxOzZs7l06RKjR48G1AHSM2bMoH///ri7u3PhwgXeeOMN6tevT1CQTClenjzf0YeIa2ksD7/Ea2uP4OVsQ8uaTg9+Q50OmveDRj0gfD78NheuHICvAtVlNgKngWPNkvsAQoiKR1HgykH4awOc36k+mXUz6cHuZVlVDTZ2Luq6XXYuYFtd3excwLkO1O4oY33KKc0DUEhICNeuXWPq1KnExMTQqlUrtm7dah4YffnyZfT63J6669evM2bMGGJiYnB2dsbPz489e/bQtKk6eZTBYODYsWMsX76cpKQkPD096d69O++++6608pRD7zzVlEuJGfxy5hqjlh/kx/Gd8HQq5qJ/Fjbw6GRo/SyEvQtHvoXja+HUT+oA6tbPgre//KMkRGWhKHD1sNpCfHKD+gRpPjo1zNhWvxVmbn29HWbM++7YL/P2VGiaDoIur4oyiEoUX+rNbAYsCOdMbCqN3Kqy9sUAHG0tSu4Nrv6p9stf3pO7r3p9aDUEfAeDg2fJvZcQonxQFIg+civ0/ABJd8xCb2mvthQ3eRpcGqoBx8YZ9Abt6hUloii/vyUAFUACUNm7cj2Dvl/s4VpqJn61nflmVHtsLUuwgVJR4NIf8Oe3atN3doa6X6eHek9Aq6HQ+EkZoChERaYoEHMsN/Rcj8w9ZmEHjYKhWV+oH6i2FIuHjgSgYpIApI1T0SmELAon5WYOjzWswZJhbbGsUgoPKmamqs3gR76Fy3dMuGnjDC0GqmHIw1e6yISoCBQFYk/khp7EiNxjFrbQMOhW6OkmU2NUAhKAikkCkHYORiby7Ff7uJlt4mlfT+aFtEKvL8UgknBBDUJHVkHqHZMoujVXg1DLQTJTqxDljaJA3F+5oSfhjilOqlhDg+5q6GkYBJZ22tUpypwEoGKSAKStXWfiGLP8IDkmhecDajP96WYPPlFiYZmMELFL7SI7vQmMmep+fRVoGKwOnK7fDQyaPzcgROUVdyo39MSfzd1vsIIG3W6FnmCwsteuRqEpCUDFJAFIez8e+ZuJa46gKDAxsAETAxuW3ZtnJMKJdfDnSnUQ5W12ruAbAq2eBdfGZVePEJXZtTO5oefa6dz9Bkv1j5JmfdWxPVZVtatRlBsSgIpJAlD5sHxPJNM2qgvdTu/VlOGd6pR9EbEn1VahY2vUCdFu8/JTu8ia9webYsxdJERlZ8xW1/BLjoLkK5AUpU5kmnxFHc9z50BmvYU6gPl26LF21KxsUT5JAComCUDlx7ydZ5m3U11HZ15IK/q09tKmkJwsOLddHS90dhsotxbWrWKtzvTaeijUeRz0mq4uI0T5k5l2R7i5/I+gEwWp0aDcY1FkvYX6pGazvuqj6/IHh7gHCUDFJAGo/FAUhRk//cWyPZFU0etYMqwtXRq7altUWpzaIvTnt3DtVO5+By/1H+iGPaBOZ3mkXjz8FEVdGiL58q1Ac0UNNbfDTXKUumbW/Rgs1f//OHmDYy11xnYnb/Wrh6/6hKYQhSABqJgkAJUvJpPCa2uP8OORq1hb6Fk5yp+2PuVgXZ3bs8v+uRKOr4PM5NxjFnZQ/wk1DDUMkifJxMPj9gSDJ9bBiR8g5cr9r7FyvBVovO8IN7c2J291fJ20nooSIAGomCQAlT/ZRhNjVhzklzPXcLCuwpoXA2jiUY7+22TfgIjdcGaz2kWWFnPHQR3UbKeOWWjUE2o0ljmGRMUT+9et0LMOrl+844AOqrrnhhnHmnnDjWNNGasjyowEoGKSAFQ+3cgy8txX+zh46To1qloROjaA2tXL4RwfJpP6F/LZrXBmizoz7Z2cat/qKguG2p2giqU2dQpxPwkX4MR6NfTc2d1bxUYN9M37y6zKolyRAFRMEoDKr+Qb2YQsCud0TCq1qtkSOjYAV4dyviBh8pVbYWgrXPw1d44hACsHqN9V7Spr0E1djFEILSVdVh85P7EOoo/m7r/92HnzfjLXjii3JAAVkwSg8i0u5SYDFoZzOTGDxu5VWfNCCS+eWpoy0yDiFzi7Re0qS7+We0ynB+8OautQox7g0kCzMkUlkxqrrpF3Yh1E7cvdrzNA3cfVlp7GT8oTWKLckwBUTBKAyr/LCRn0X6guntq2tjPfjPLHxrKCreRsMqmDqM9sVluH4k7mPV6tXm5XWa0AmYValKz0BDi1UQ09kb8Dt38V6MDnEbWlp8nTMoBfVCgSgIpJAlDFcOfiqV0a1WDxsLZYGCrwkyTXL6mtQme3wMXfwJSde8zaEeo8BjXbqpMwerSSLghRdDeT1aVeTqxXl34x5eQeq9leDT1N+4CDh3Y1ClEMEoCKSQJQxXHn4qm9W3ny8aBSXjy1rNxMgQs/q2OHzm6DG4l5j+v0UKMJeLVRA5GXH7g2lVYikV9Wuvq/oxPr1ck8jVm5x9xbqt1bzfqCc23tahSihEgAKiYJQBXLrtNxjFlRxounliWTEa4chMvh8Pch+PtwwXOvVLEBz1a5gcjLD5xqySP3lYXJCEmX4NpZdaHQ+LMQf059CjE7I/c8l0Zq6GneT8aZiYeOBKBikgBU8dy5eOprgQ15NfAh/4c9NeZWGDqUG4oyU/KfZ+uiBqGabdXWIs828qRZRZeVrgab+HO3Qs4Z9fuE83lbd+7k7HMr9PRXWwolFIuHlASgYpIAVDHduXjqjKeb8XxHH20LKksmk/oL0ByIDkLMibzjiG6rVhe82ua2Erm3AItyPpVAZaMo6pIrdwac2y06yVF3v85gpbbquDQAl4bq5tpEQo+oNCQAFZMEoIrrzsVTP3mmFb1babR4anmQfRNiT6iB6MpB9Wvihfzn6S3ArRlUrw+OXuqaTA6etzYvWaagtJhMcDNJnQoh4XxuwLl2K/DcubTKP9lWzw045q2B2uWpr2BPQwpRgiQAFZMEoIpLURSmbzzJ8vBL6uKpz7elSyONF08tTzIS4eqfuS1FVw5CRvy9r9FXgaqed4QiT3V5g9sBycET7N3kF29OFmQkqD/P9Phb3yfc8X28+uj57e8zEkEx3v1+Or06a/jtcFOjkfp99QZgV73sPpcQFYgEoGKSAFSx/XPx1G9H++NXW8a9FEhR1C6Vq3+qMwCnXIWUv299vQqp0aCY7n8fnQGqeuRtOXLwzG1RquoOVlXVRWLL+9IfOVmQlQaZqbe+pqkrmucJN4n5g05BY7AKw8oBqtXJ25Lj0lCdB0q6JoUoEglAxSQBqOL75+Kpa8cG0Nhd/lsWmTEH0mLvCEZ/5w1JyX/fCkn3aMn4J70FWNrlbha2YGkPlrZ37Lt9/PaxAs6zuOMeeoMaVG4HlqzUO17fEWQKPP6P13cbSFwYOoM6yNzWRZ1AMM/31dXN/P2t41WsHvz9hBB5SAAqJglAD4d/Lp66bmxHalW31bqsh4/JqA7YTbmqPp7/z1ak5L8hLaZ4wUILVazVwGVlD9ZOt4LLrfBiV/2O7+8IN9ZOMl5KCA1JAComCUAPj+SMbEIWV7DFUx9WOVmQnQ5ZGeqj3Nnp6tc7t+wMtRXm9jlZabf2/fOc9Nzzbi8uq7dQw4pl1Vtf7XO/3vl9gecU8FomlRSiwpEAVEwSgB4udy6eWsfFjpWj/fFystG6LFFSjDlqF5x0JQlR6RXl97e01YqHnquDNd+O9qemsw0X49MZuGAPF+PTtS5LlBRDFQk/QogikwAkKgXvarZ8PzaAujXsuJp8k4ELwzkd84BP7QghhKjwJACJSsPD0Ya1LwbQxMOB+LRMQhbt5UhUktZlCSGE0IAEIFGpuNhbsXpMB1rXciL5RjZDl+xlb0SC1mUJIYQoYxKARKXjaGvBylH+dKxXnfQsI88v3c+uM3FalyWEEKIMlYsANH/+fHx8fLC2tsbf35/9+/ff9dxly5ah0+nybNbWeR9rVhSFqVOn4uHhgY2NDYGBgZw7d660P4aoQOysqrB0eDsCm7iSmWPihRUH2Xw8WuuyhBBClBHNA9CaNWuYNGkS06ZN4/Dhw/j6+hIUFERc3N3/IndwcCA6Otq8Xbp0Kc/xDz/8kE8//ZSFCxeyb98+7OzsCAoK4ubNm6X9cUQFYm1hYMGzfjzV0oNso8KE7w4TeuiK1mUJIYQoA5oHoLlz5zJmzBhGjBhB06ZNWbhwIba2tixduvSu1+h0Otzd3c2bm5ub+ZiiKMybN49///vf9O7dm5YtW7JixQquXr3Khg0byuIjiQrEwqDnk2daE9LWG5MCk78/yorwSK3LEkIIUco0DUBZWVkcOnSIwMBA8z69Xk9gYCDh4eF3vS4tLY3atWvj7e1N7969OXnypPnYxYsXiYmJyXNPR0dH/P3973lPUXkZ9Dr+278FIzvVAWDqjyeZv+u8xlUJIYQoTZoGoPj4eIxGY54WHAA3NzdiYmIKvKZRo0YsXbqUH3/8kZUrV2IymejYsSNXrqhdF7evK8o9MzMzSUlJybOJykWn0/HOU014pWsDAGZvO8MHW08jE6ULIcTDSfMusKIKCAhg2LBhtGrViscee4z169dTo0YNFi1a9MD3nDVrFo6OjubN29u7BCsWFYVOp2NSt4b8q2djABb8coHpG09iMkkIEkKIh42mAcjFxQWDwUBsbGye/bGxsbi7uxfqHhYWFrRu3Zrz59Uui9vXFeWeU6ZMITk52bxFRUUV9aOIh8gLj9bjP32bo9PB8vBLvLHuGDlGk9ZlCSGEKEFFDkA3btwgIyPD/PrSpUvMmzeP7du3F/nNLS0t8fPzIywszLzPZDIRFhZGQEBAoe5hNBo5fvw4Hh4eANSpUwd3d/c890xJSWHfvn13vaeVlRUODg55NlG5DfWvzdxBvhj0OkIPXeGV1X+SlSMhSAghHhZFDkC9e/dmxYoVACQlJeHv789HH31E7969WbBgQZELmDRpEkuWLGH58uWcOnWKcePGkZ6ezogRIwAYNmwYU6ZMMZ8/c+ZMtm/fTkREBIcPH+bZZ5/l0qVLjB49GlC7MSZOnMh7773Hxo0bOX78OMOGDcPT05M+ffoUuT5RefVtXZMvhrbB0qBn8/EYxqw4yI0so9ZlCSGEKAFFDkCHDx+mc+fOAISGhuLm5salS5dYsWIFn376aZELCAkJYc6cOUydOpVWrVpx5MgRtm7dah7EfPnyZaKjcyeou379OmPGjKFJkyb07NmTlJQU9uzZQ9OmTc3nvPHGG7z88su88MILtGvXjrS0NLZu3ZpvwkQh7ieomTtfDW+LjYWB3Wev8fzX+0m9ma11WUIIIYpJpxTxMRdbW1tOnz5NrVq1GDRoEM2aNWPatGlERUXRqFGjPN1jFVVKSgqOjo4kJydLd5gA4EBkIiO/PkBqZg6+NR1ZPrI9TraWWpclhBDiDkX5/V3kFqD69euzYcMGoqKi2LZtG927dwcgLi5OwoJ4aLXzqcZ3YzrgbGvB0SvJhCzaS1yqzCwuhBAVVZED0NSpU5k8eTI+Pj74+/ubBxZv376d1q1bl3iBQpQXLWo6subFAFyrWnEmNpVBC8O5cr3it3gKIURlVOQuMFAnG4yOjsbX1xe9Xs1Q+/fvx8HBgcaNG5d4kWVNusDEvVxKSGfol/u4cv0Gno7WfDumA3Vc7LQuSwghKr1S7QIDda6d1q1bo9frSUlJYcOGDVStWvWhCD9C3E/t6nZ8PzaAujXsuJp8k4ELwzkVLbOHCyFERVLkADRo0CA+//xzQJ0TqG3btgwaNIiWLVuybt26Ei9QiPLIw9GGtS8G0MTDgfi0TJ5ZvJcjUUlalyWEEKKQihyAfv31V/Nj8D/88AOKopCUlMSnn37Ke++9V+IFClFeudhbsXpMB1rXciL5RjZDl+xlz/l4rcsSQghRCEUOQMnJyVSrVg2ArVu30r9/f2xtbXnyySc5d+5ciRcoRHnmaGvBylH+dKxXnfQsI8O/PsDm49H3v1AIIYSmihyAvL29CQ8PJz09na1bt5ofg79+/bpMNCgqJTurKiwd3o4ezd3JMpoY/91hvtl7SeuyhBBC3EORA9DEiRMZOnQoNWvWxNPTk8cffxxQu8ZatGhR0vUJUSFYWxj4fEgbhvrXQlHgnQ0n+HjHWR7gIUshhBBl4IEegz948CBRUVF069YNe3t7ADZt2oSTkxOdOnUq8SLLmjwGLx6UoijM23mOT8LU7uCh/rWY2bs5Br1O48qEEOLhV5Tf3w8UgG67falO93D94y4BSBTXN3svMfXHEygK9GjuzschrbC2MGhdlhBCPNRKfR6gFStW0KJFC2xsbLCxsaFly5Z88803D1SsEA+j5zrU5vPB6kryW07EMFwWURVCiHKlyAFo7ty5jBs3jp49e7J27VrWrl1LcHAwY8eO5eOPPy6NGoWokJ5s6cGyEe2wt6rC3ohEnlm8l2upmVqXJYQQggfoAqtTpw4zZsxg2LBhefYvX76c6dOnc/HixRItUAvSBSZK0om/kxn+9X7i07KoXd2Wb0b6U6u6rdZlCSHEQ6dUu8Cio6Pp2LFjvv0dO3YkOlrmPxHin5p7ORI6tiPe1Wy4lJBBvwV7OHk1WeuyhBCiUityAKpfvz5r167Nt3/NmjU0aNCgRIoS4mHj42LHurEdzUtnhCzaS/iFBK3LEkKISqvIXWDr1q0jJCSEwMBA8yPvf/zxB2FhYaxdu5a+ffuWSqFlSbrARGlJuZnNmOUH2XcxEUuDnk8HtyK4uYfWZQkhxEOhVLvA+vfvz759+3BxcWHDhg1s2LABFxcX9u/f/1CEHyFKk4O1BctHtieomRtZRhMvfXuYb/fJrNFCCFHWijUP0MNKWoBEaTOaFP694QSr9l8G4LXAhrzStf5DN6eWEEKUpaL8/q5S2BsWlgQGIe7PoNfxft/m1LC35NOfz/PxzrMkpGcyrVczmTVaCCHKQKECkJOT033/MlUUBZ1Oh9FoLJHChHjY6XQ6JnVvRHV7K6b/dJIV4ZdISM9i7iBfrKrIrNFCCFGaChWAdu3aVdp1CFFpPd/Rh2p2lkxae4RNx6JJyshi0XNtsbcq1P89hRBCPAAZA1QAGQMktPD7uXhe/OYg6VlGmns5sGxEe1zsrbQuSwghKoxSXwtMCFHyHmngwqoXOlDdzpITf6cwYMEeohIztC5LCCEeShKAhChHWtZ04vuxAXg52RB5a9bov64W/iEEIYQQhSMBSIhypm4Ne9a/1JHG7lW5lppJyKJw9kXIrNFCCFGSJAAJUQ65OViz5sUA2vtUIzUzh+eW7mfbyRityxJCiIdGoQNQXFzcPY/n5OSwf//+YhckhFA52liwYlR7ujV1IyvHxLiVh2TWaCGE6iwglgAAIABJREFUKCGFDkAeHh55QlCLFi2Iiooyv05ISCAgIKBkqxOikrO2MLBgaBueaeeNSYG3fzjB3O1nkIc3hRCieAodgP75D25kZCTZ2dn3PEcIUXxVDHpm9WvBq10bAPDpz+d5c90xcowmjSsTQoiKq0THAMk6RkKUDp1Ox2vdGvJ+3xbodbD24BVe+OYQGVk5WpcmhBAVUrkYBD1//nx8fHywtrbG39+/0GOJVq9ejU6no0+fPnn2Dx8+HJ1Ol2cLDg4ujdKFKFND/Gux6Lm2WFvo+fl0HIOX7CMhLVPrsoQQosIpdADS6XSkpqaSkpJCcnIyOp2OtLQ0UlJSzNuDWLNmDZMmTWLatGkcPnwYX19fgoKC7jvoOjIyksmTJ9O5c+cCjwcHBxMdHW3eVq1a9UD1CVHedGvqxrejO+Bka8HRqCQGLAzncoJMmCiEEEVR6KUw9Hp9ni6u24uf/vN1URdD9ff3p127dnz++ecAmEwmvL29efnll3nrrbcKvMZoNPLoo48ycuRIfvvtN5KSktiwYYP5+PDhw/PtKwpZCkNUBOfj0nh+6X7+TrqBi70Vy0a0o7mXo9ZlCSGEZory+7vQqy2WxoKoWVlZHDp0iClTppj36fV6AgMDCQ8Pv+t1M2fOxNXVlVGjRvHbb78VeM4vv/yCq6srzs7OPPHEE7z33ntUr169xD+DEFqp76pOmDj86wOcik4hZFE4C57149GGNbQuTQghyr1CB6DHHnusxN88Pj4eo9GIm5tbnv1ubm6cPn26wGt+//13vvrqK44cOXLX+wYHB9OvXz/q1KnDhQsX+Ne//kWPHj0IDw/HYDDkOz8zM5PMzNxxFA/anSdEWXNzsGbtix0Yu/IQf5xPYOSyA8we2JK+rWtqXZoQQpRrhR4DdPXqVSZP/v/27jwuqnr/H/hrhmUGkUVF9kFA3FIWBUXcckHBvC6Vid3KvcXMMjTL+qoV/S7a6jVNzWsuea9LZbZomo7iikoouSEKgoDKgCi7bDPn9wc5NQkIDnBmeT0fj/N4yDmf8+H96TTOy3M+55x5tYaDwsJCvPHGG1CpVE1a3N8VFxfjueeew9q1a+Hk5FRnu4kTJ2LMmDHw9/fHuHHj8PPPPyMhIQFxcXG1to+NjYWDg4N2USgUzTQCoqZnJ7fC+il9MCbQHdUaAa9v+x2rD6XxsRRERPVocAD69NNPUVRUVOs1NQcHBxQXF+PTTz9t1C93cnKChYXFfcFJpVLB1dX1vvZpaWnIyMjA6NGjYWlpCUtLS2zatAk//vgjLC0tkZaWVuvv8fX1hZOTE1JTU2vdvmDBAhQWFmqXvz7gkcgYWFtKsSwqCM8P9AEALPnlEt776SLUGoYgIqLaNDgA7dmzB5MmTapz+6RJk/Dzzz836pdbW1sjODgYSqVSu06j0UCpVNb6VOmuXbvi3LlzSEpK0i5jxozBkCFDkJSUVOeZm+zsbOTn58PNza3W7TKZDPb29joLkbGRSiV4Z9Qj+L9R3QAAG45nYPaW0yivatyNCURE5qDBc4DS09Ph5eVV53ZPT09kZGQ0uoDo6GhMnjwZISEh6NOnD5YtW4bS0lJMnToVQE2w8vDwQGxsLORyOXr06KGzv6OjIwBo15eUlOC9997Dk08+CVdXV6SlpWH+/Pnw8/NDREREo+sjMjYzBvrC2V6OuduTsPtcDvJLTuHLSSFwsLESuzQiIoPR4ABkY2ODjIyMOkNQRkYGbGxsGl1AVFQU8vLysGjRIuTk5CAoKAh79uzRTozOzMyEVNrw5zVaWFjg7Nmz2LhxIwoKCuDu7o4RI0YgJiYGMpms0fURGaMxge5wsrXGC18n4mT6bUxYHY8N03rDzaHxn1EiIlPU4OcAjRo1Cu7u7li7dm2t22fMmIEbN25g9+7dTVqgGPgcIDIVF28UYcr6U8gtroCbgxwbp/VBZxc7scsiImoWjfn+bvCplXnz5mH9+vWYN2+ezqRllUqFuXPnYsOGDZg3b97DV01ETe4Rd3vseLkffNvb4mZhOcavOo6EjNtil0VEJLoGnwECgDVr1uC1115DVVUV7O3tIZFIUFhYCCsrK3z22WeYOXNmc9baYngGiEzNndJKTN+YgNOZBbC2lGL5xCBE9qj9pgAiImPVmO/vRgUgALh+/Tq2b9+O1NRUCIKAzp07Y/z48fD0NJ0HrzEAkSm6W6nG7C1nsD9ZBYkEeH9MdzwX5i12WURETaZZA5A5YAAiU1Wt1mDhDxew5VQmAGDWkI6YN6KLznv9iIiMVbO8C+ye/Px87Tu1srKysHbtWty9exejR4/GoEGDHq5iImoRlhZS/OvxHnBzkOPTfZex8mAaVEUViH3CH1YWDb/bkojI2DX4b7xz587B29sbzs7O6Nq1K5KSktC7d2989tln+PLLLzF06NCHfvs6EbUciUSCV4d1wpIn/GEhleDbxGzM2PgbSiuqxS6NiKjFNDgAzZ8/H/7+/jh8+DAGDx6Mf/zjHxg1ahQKCwtx584dvPjii1iyZElz1kpETWhiHy98+Vww5FZSHLqchzErjuJsdoHYZRERtYgGzwFycnLCgQMHEBAQgJKSEtjb2yMhIQHBwcEAgEuXLqFv374oKDD+v0A5B4jMyZnMO3jh60TkFVfAUirB7KGd8PKQjrwkRkRGp1meA3T79m3tC0pbt24NW1tbtGnTRru9TZs2KC4ufsiSiUgsPb3a4Nc5gzDK3w3VGgGf7b+M8auOIy2vROzSiIiaTaP+iff3O0V45wiRaWhja40V/+yJf08Mgr3cEr9nF+Kxfx/BhmPp0PCN8kRkghp1F9iUKVO079MqLy/HSy+9BFtbWwBARUVF01dHRC1GIpFgbJAH+vi0xfxvz+LIlVt496eL2JeswkfjA+HuyPeIEZHpaPAcoHtvZ3+Q9evX61WQIeAcIDJ3giBg84lr+H+7k1FepYGd3BLvjemOx3t68MwvERksPghRTwxARDWu5pUgevvvSMqqublhZA9X/L/H/dHW1lrkyoiI7tcsk6CJyPz4tm+Nb18Kw7wRnWEpleCX8zkY8dlhKJNVD96ZiMiAMQARUb0sLaR4ZWgn7JzVH52cW+NWSQWmb/wNb313FiV8eCIRGSkGICJqkB4eDvhp9gA8P9AHEgmwNSELkcsO41T6bbFLIyJqNAYgImowuZUF3hn1CLY83xcejjbIvnMXUV/GI3Z3Msqr1GKXR0TUYAxARNRofX3bYc+cgYgKUUAQgDWHr2LsimO4cKNQ7NKIiBqEAYiIHoqd3ApLxwdg7aQQOLW2RoqqGONWHsPKg6moVmvELo+IqF4MQESkl+GPuGDvnEGI6O6CKrWAj/amYMKaeKTfKhW7NCKiOjEAEZHe2rWWYfWzwfh0QiDsZJY4nVmAx/59BF+fuAY+aoyIDBEDEBE1CYlEgid6eWLP64PQr2M73K1SY+HO85i8PgE5heVil0dEpIMBiIialIejDTZPD8Xi0Y9AZinF4ct5iFh2GLvO3hS7NCIiLQYgImpyUqkEU/v7YNerAxHg6YDCu1WY9b/TeOOb3/nwRCIyCAxARNRs/Jxb47uZ/TB7qB8kEuCbxGyMWn5E+24xIiKxMAARUbOyspBi7ogu2PrHwxOv5Zdh/KrjWHkwFWoNJ0gTkTgYgIioRYT6tsPu1wbiHwFuqNbU3C7/9NoTuF5wV+zSiMgMMQARUYtxsLHC50/3xCdPBcLW2gKn0m9j5LLD+PnsDbFLIyIzwwBERC1KIpHgyWBP7H5tIIIUjigqr8Yr/zuDeZwgTUQtiAGIiETRoZ0tvnkpDLOH+kEqAb79Y4L0mcw7YpdGRGaAAYiIRKOdIP1C2J8TpFfHY8WBK5wgTUTNyiAC0MqVK+Ht7Q25XI7Q0FCcOnWqQftt3boVEokE48aN01kvCAIWLVoENzc32NjYIDw8HFeuXGmO0omoCfTxaYvdrw3E6EB3qDUCPv71Mp7+khOkiaj5iB6Atm3bhujoaCxevBinT59GYGAgIiIikJubW+9+GRkZmDdvHgYOHHjftg8//BDLly/H6tWrcfLkSdja2iIiIgLl5XwcP5GhcrCxwvKJQX9OkM64jchlh/HT75wgTURNTyKI/KbC0NBQ9O7dGytWrAAAaDQaKBQKzJ49G2+99Vat+6jVagwaNAjTpk3DkSNHUFBQgJ07dwKoOfvj7u6OuXPnYt68eQCAwsJCuLi4YMOGDZg4ceIDayoqKoKDgwMKCwthb2/fRCMlooa6ll+KOduScCaz5oGJT/byxHtju6O1zFLkyojIkDXm+1vUM0CVlZVITExEeHi4dp1UKkV4eDji4+Pr3O/999+Hs7Mzpk+fft+29PR05OTk6PTp4OCA0NDQevskIsPRoZ0ttr8Yhlf/mCD93elsPPZvTpAmoqYjagC6desW1Go1XFxcdNa7uLggJyen1n2OHj2KdevWYe3atbVuv7dfY/qsqKhAUVGRzkJE4rKykCL6LxOkM2/XTJD+XMkJ0kSkP9HnADVGcXExnnvuOaxduxZOTk5N1m9sbCwcHBy0i0KhaLK+iUg/f58g/cm+y5j4ZTyy75SJXRoRGTFRA5CTkxMsLCygUql01qtUKri6ut7XPi0tDRkZGRg9ejQsLS1haWmJTZs24ccff4SlpSXS0tK0+zW0TwBYsGABCgsLtUtWVlYTjZCImsK9CdKfTghEa5klEjLuYOS/j+BHTpAmoockagCytrZGcHAwlEqldp1Go4FSqURYWNh97bt27Ypz584hKSlJu4wZMwZDhgxBUlISFAoFfHx84OrqqtNnUVERTp48WWufACCTyWBvb6+zEJFhkUgkeKKXJ3a/OhA9vRxRXF6NV7ecQfT2JBSXV4ldHhEZGdFvqYiOjsbkyZMREhKCPn36YNmyZSgtLcXUqVMBAJMmTYKHhwdiY2Mhl8vRo0cPnf0dHR0BQGf9nDlz8MEHH6BTp07w8fHBwoUL4e7uft/zgojI+Hi1a4VvXgzD8gOpWHHgCnacvo6EjNtY+kQA+vk13aVxIjJtogegqKgo5OXlYdGiRcjJyUFQUBD27NmjncScmZkJqbRxJ6rmz5+P0tJSvPDCCygoKMCAAQOwZ88eyOXy5hgCEbUwSwspood3xsBOTpizNQlZt+/in/85iagQBd5+rBscWlmJXSIRGTjRnwNkiPgcICLjUVxehaV7LmHziUwAQHs7GWLGdkdkDzeRKyOilmY0zwEiItKXndwKH4zzx/YXw+DrZIu84gq8tPk0Xvo6EblFfPo7EdWOAYiITMK92+VfGeIHS6kEey7kIPzTQ9iWkAme6Caiv2MAIiKTIbeywLyILvjxlQEI8HRAUXk13vzuHJ75z0lcyy8VuzwiMiAMQERkch5xt8eOmf3wzmPdILeS4nhaPiKWHcaXh9NQrdaIXR4RGQAGICIySZYWUjw/yBd75wxCv47tUF6lwb92X8LjXxzHxRt83Q2RuWMAIiKT1qGdLf47IxRLn/SHndwS564XYsyKo/ho7yWUV6nFLo+IRMIAREQmTyKRIKq3F5TRjyKyuyuqNQJWHkzDY8uP4FT6bbHLIyIRMAARkdlwtpdj9XPBWP1sL7S3k+FqXikmrInH/+08x9dpEJkZBiAiMjuRPdywP/pRTOytAABsPpGJEZ8dhjJZ9YA9ichUMAARkVlysLHCkicD8L8ZofBq2wo3C8sxfeNvmL3lDG6VVIhdHhE1MwYgIjJr/fycsHfOILwwyBdSCfDT7zcQ/ukh7DidzQcoEpkwBiAiMns21hZ4+7Fu2DmrP7q62qGgrArR23/H5PUJyL5TJnZ5RNQMGICIiP4Q4OmIn2YPwBsRXWBtKcXhy3kY8VnNAxR5yzyRaeHb4GvBt8ETUVpeCRZ8dw6nMmpuk3dzkOPVYZ0wPtgTVhb8tyORIWrM9zcDUC0YgIgIADQaAd8mZuOz/Zdxs7DmzfI+TrZ4fXhn/MPfDVKpROQKieivGID0xABERH9VXqXGf09m4ouDqcgvrQQAdHW1wxsRXTC0qzMkEgYhIkPAAKQnBiAiqk1JRTXWH03Hl4evoriiGgDQy8sRb0R0RVjHdiJXR0QMQHpiACKi+hSUVWL1oavYcDwd5VU1b5cf2MkJ80Z0QaDCUeTqiMwXA5CeGICIqCFyi8qx4mAqtpzKRJW65q/SiO4umDuiCzq72IlcHZH5YQDSEwMQETVG1u0yLNt/Bd+fyYZGACQS4PEgD8wJ7wyvdq3ELo/IbDAA6YkBiIgexhVVMT7ddxm/nM8BAFhKJZjYR4HZQzvBxV4ucnVEpo8BSE8MQESkj3PZhfj41xQcupwHAJBZSjG5nzdeerQj2tpai1wdkeliANITAxARNYWTV/Px0d4U/HbtDgCgtcwSMwb6YPoAH9jJrUSujsj0MADpiQGIiJqKIAiIu5yHj/ak4OLNIgBAm1ZWeHmwH54L6wC5lYXIFRKZDgYgPTEAEVFT02gE/HI+B5/sS8HVvFIAgIu9DK8O64QJIQq+XoOoCTAA6YkBiIiaS7Vagx1nruPf+6/gesFdAEAn59Z4f2wPPkyRSE8MQHpiACKi5lZRrcaWk5lYfiAVt/94vcbYIHe8/Vg33jFG9JAYgPTEAERELaWwrAof/5qC/568Bo1QM1F6TngnTO7nzctiRI3EAKQnBiAiamnnrxfi/3aeR1JWAQCgi4sd3h/bHaG+vCxG1FAMQHpiACIiMWg0Ar5JzMKSXy7hTlkVAODxnh5YMLIrnHlZjOiBGvP9zfOrREQGQiqVIKq3Fw7OG4xn+3pBIgG+P3MdQz85hHVH01Gt1ohdIpHJMIgAtHLlSnh7e0MulyM0NBSnTp2qs+2OHTsQEhICR0dH2NraIigoCF9//bVOmylTpkAikegskZGRzT0MIqIm4djKGh+M88cPs/ojUOGIkopqxPx8Ef/4/ChOpd8WuzwikyB6ANq2bRuio6OxePFinD59GoGBgYiIiEBubm6t7du2bYt33nkH8fHxOHv2LKZOnYqpU6di7969Ou0iIyNx8+ZN7bJly5aWGA4RUZMJ8HTE9zP7IfYJf7RpZYVLOcWYsCYe0duSkFtcLnZ5REZN9DlAoaGh6N27N1asWAEA0Gg0UCgUmD17Nt56660G9dGrVy+MGjUKMTExAGrOABUUFGDnzp0PVRPnABGRoblTWomPfk3BllOZEATATmaJ6BGd8VzfDrDk3WJEAIxoDlBlZSUSExMRHh6uXSeVShEeHo74+PgH7i8IApRKJVJSUjBo0CCdbXFxcXB2dkaXLl0wc+ZM5Ofn19lPRUUFioqKdBYiIkPSxtYa/3rcHztf7o8ATwcUV1TjvZ9qLov9lsHLYkSNJWoAunXrFtRqNVxcXHTWu7i4ICcnp879CgsL0bp1a1hbW2PUqFH4/PPPMXz4cO32yMhIbNq0CUqlEkuXLsWhQ4cwcuRIqNXqWvuLjY2Fg4ODdlEoFE0zQCKiJhaocMT3L/fHvx73h+Mfl8XGr47H3O2/I6+4QuzyiIyGqJfAbty4AQ8PDxw/fhxhYWHa9fPnz8ehQ4dw8uTJWvfTaDS4evUqSkpKoFQqERMTg507d2Lw4MG1tr969So6duyI/fv3Y9iwYfdtr6ioQEXFn39xFBUVQaFQ8BIYERm026WV+GjvJWxNyKq5LCa3xLwRXfBMqBcvi5FZMppLYE5OTrCwsIBKpdJZr1Kp4OrqWud+UqkUfn5+CAoKwty5czF+/HjExsbW2d7X1xdOTk5ITU2tdbtMJoO9vb3OQkRk6NraWiP2iQDsmNkP/h4OKC6vxuIfL2DMimNIvMbLYkT1ETUAWVtbIzg4GEqlUrtOo9FAqVTqnBF6EI1Go3MG5++ys7ORn58PNzc3veolIjJEPb3aYOes/vhgXA842Fjh4s0iPLkqHm988ztulfCyGFFtRD9HGh0djbVr12Ljxo1ITk7GzJkzUVpaiqlTpwIAJk2ahAULFmjbx8bGYt++fbh69SqSk5PxySef4Ouvv8azzz4LACgpKcEbb7yBEydOICMjA0qlEmPHjoWfnx8iIiJEGSMRUXOzkErwbN8OODD3UUSF1Mxj/CYxG0M/jsPKg6koragWuUIiw2IpdgFRUVHIy8vDokWLkJOTg6CgIOzZs0c7MTozMxNS6Z85rbS0FC+//DKys7NhY2ODrl27YvPmzYiKigIAWFhY4OzZs9i4cSMKCgrg7u6OESNGICYmBjKZTJQxEhG1lHatZVg6PgBRfRRYuPM8Ltwowkd7U7DuaDpeetQXz/X1ho21hdhlEolO9OcAGSI+B4iITIFaI+Cn32/g38orSL9VCgBwai3Dy4M74p+hXpBbMQiRaeHLUPXEAEREpqRarcH3Z65j+YEryLp9FwDgYi/DK0P8MKG3AjJLBiEyDQxAemIAIiJTVKXW4JvfsrHiwBXcKKx5lYaHow1mD/XDk8GesOKt82TkGID0xABERKasolqNbQlZWHEgFbl/PDzRq20rvDqsE8YFufMZQmS0GID0xABEROagvEqN/57MxKq4VNwqqQQA+DrZ4rXwTvhHgDsspBKRKyRqHAYgPTEAEZE5Kausxqb4a1hzKA13yqoAAJ2cW+P14Z0R2d0VUgYhMhIMQHpiACIic1RSUY0Nx9Lx5eGrKCqveW5QNzd7vB7eCcMfcYFEwiBEho0BSE8MQERkzgrvVmHd0XR8dTQdJX88QNHfwwHRwztjcJf2DEJksBiA9MQAREQEFJRV4svDV7HheAbKKtUAgJ5ejoge3hkD/JwYhMjgMADpiQGIiOhP+SUVWHP4KjbFZ6C8SgMA6OPdFtEjOqOvbztxiyP6CwYgPTEAERHdL7eoHF/EpeF/pzJRWV0ThMJ82+HlIR15RogMAgOQnhiAiIjqdrPwLlYeTMW2hCxUqWu+Qnp42OOlRztiZA833j5PomEA0hMDEBHRg2XfKcN/jqRja0Km9tKYd7tWeH6QL57s5cl3jVGLYwDSEwMQEVHD3S6txIbjGdgUn4GCP54j5NRahmkDvPFs3w6wl1uJWyCZDQYgPTEAERE1XmlFNbYlZOE/R65q3zXWWmaJZ/p6YXp/Hzjby0WukEwdA5CeGICIiB5elVqDH5NuYM3hNFxWlQAArC2keKKXB14Y5Avf9q1FrpBMFQOQnhiAiIj0p9EIOHApF6sPpeG3a3cAABIJENndFS892hGBCkeRKyRTwwCkJwYgIqKmlZBxG6vj0qC8lKtd169jO8wczFvoqekwAOmJAYiIqHmk5BRjzaE0/Pj7DVRrar5+urvX3EL/mD9voSf9MADpiQGIiKh5XS+4i/8cuYqtp7Jwt6rmNRsd2rXC8wN9MT6Yt9DTw2EA0hMDEBFRy7hTWomN8RnYeDwDd/5yC/3U/jW30DvY8BZ6ajgGID0xABERtayyympsT8jC2iPpuF5wF0DNLfRP91FgSn8feDjaiFwhGQMGID0xABERiaNKrcHPZ29gddxVpKiKAQAWUgke83fDjAE+vHOM6sUApCcGICIicQmCgLiUPKw9chXH0/K16/t4t8X0gT4I7+bCCdN0HwYgPTEAEREZjgs3CrHuaDp++v2G9uWrHdq1wrT+PngqxBOtrC1FrpAMBQOQnhiAiIgMj6qoHJviM7D5RCYK79ZMmHawscI/Q70wOcwbrg581Ya5YwDSEwMQEZHhKqusxneJ2Vh3NB0Z+WUAAEupBGMC3TFtgA96eDiIXCGJhQFITwxARESGT60RoExW4T9H03Eq/bZ2fZhvO8wY6IMhXZwh5Twhs8IApCcGICIi43I2uwDrjqbj57M3of7jCdO+7W0xfYAPnujpCRtrPljRHDAA6YkBiIjION0ouIuNxzPwv1OZKC6vBgC0aWWFZ/t2wHNhHeBsx3lCpowBSE8MQERExq2kohrf/JaFr46lI+t2zYMVrS2kGBvkjukDfdDVlX+3myIGID0xABERmQa1RsCvF3Lwn6PpSLx2R7t+YCcnTB/gg0Gd2nOekAlpzPe3tIVqqtfKlSvh7e0NuVyO0NBQnDp1qs62O3bsQEhICBwdHWFra4ugoCB8/fXXOm0EQcCiRYvg5uYGGxsbhIeH48qVK809DCIiMjAWUglG+rvhu5n9sOPlfhgV4AapBDhy5RamrE/Aox8fxLL9l5F1u0zsUqmFiX4GaNu2bZg0aRJWr16N0NBQLFu2DN988w1SUlLg7Ox8X/u4uDjcuXMHXbt2hbW1NX7++WfMnTsXu3btQkREBABg6dKliI2NxcaNG+Hj44OFCxfi3LlzuHjxIuTyB1//5RkgIiLTlXW7DBuOZ2B7QhaKK6q168N82+GpEE9E9nDlwxWNlFFdAgsNDUXv3r2xYsUKAIBGo4FCocDs2bPx1ltvNaiPXr16YdSoUYiJiYEgCHB3d8fcuXMxb948AEBhYSFcXFywYcMGTJw48YH9MQAREZm+u5Vq7L2Qg28Ts3Es7RbufRu2lllilL8bngrxRHCHNpBIeInMWBjNJbDKykokJiYiPDxcu04qlSI8PBzx8fEP3F8QBCiVSqSkpGDQoEEAgPT0dOTk5Oj06eDggNDQ0Dr7rKioQFFRkc5CRESmzcbaAuN6emDzjFAcmT8E0cM7w6ttK5RUVGPbb1kYvzoeQz85hJUHU3HjjzfUk+kQ9RzfrVu3oFar4eLiorPexcUFly5dqnO/wsJCeHh4oKKiAhYWFvjiiy8wfPhwAEBOTo62j7/3eW/b38XGxuK9997TZyhERGTEPNu0wqvDOmH2UD+cSr+NbxOzsevcTaTfKsVHe1Pw8a8pGODnhKdCFBjxiAvkVnyukLEzyoucdnZ2SEpKQklJCZRKJaKjo+Hr64vBgwc/VH8LFixAdHS09ueioiIoFIomqpaIiIyFRCJBqG87hPq2w7tjumP3uZv4NjEbJ9Nv48iVWzhy5Rbs5JYv2w1CAAAXK0lEQVQYE+iO8cGeCFI48hKZkRI1ADk5OcHCwgIqlUpnvUqlgqura537SaVS+Pn5AQCCgoKQnJyM2NhYDB48WLufSqWCm5ubTp9BQUG19ieTySCTyfQdDhERmRBbmSWeClHgqRAFruWX4rvT1/FdYjauF9zFf09m4r8nM+Hn3Brjgz3xRE8PONvzIYvGRNQ5QNbW1ggODoZSqdSu02g0UCqVCAsLa3A/Go0GFRUVAAAfHx+4urrq9FlUVISTJ082qk8iIqJ7OrSzRfTwzjgyfwj+NyMUj/f0gNxKitTcEiz55RLClhzAtA0J2H3uJiqq1WKXSw0g+iWw6OhoTJ48GSEhIejTpw+WLVuG0tJSTJ06FQAwadIkeHh4IDY2FkDNfJ2QkBB07NgRFRUV2L17N77++musWrUKQM3pyzlz5uCDDz5Ap06dtLfBu7u7Y9y4caKNk4iIjJ9UKkE/Pyf083PCe2O7Y/fZm/gmMRuJ1+7gwKVcHLiUC8dWVhgb6I6nQhTo7m7PS2QGSvQAFBUVhby8PCxatAg5OTkICgrCnj17tJOYMzMzIZX+eaKqtLQUL7/8MrKzs2FjY4OuXbti8+bNiIqK0raZP38+SktL8cILL6CgoAADBgzAnj17GvQMICIiooawl1thYh8vTOzjhat5Jfg2MRs7Tl9HTlE5NsZfw8b4a+jk3BqP9/LA2CAPeDjaiF0y/YXozwEyRHwOEBERPQy1RsDR1Fv45rcs/HpRhcpqDQBAIgFCfdriiZ6eiPR3hb3cSuRKTZNRPQjREDEAERGRvorKq/DLuZv4/sx1nLh6W7teZilF+CMueKKnBwZ1bg8rC4N4K5VJYADSEwMQERE1pesFd7HzzHV8f+Y6UnNLtOvb2lpjdIAbxvX04C31TYABSE8MQERE1BwEQcCFG0XYcfo6fvz9Bm6VVGi3+TrZYlxPD4wL8oBXu1YiVmm8GID0xABERETNrVqtwdHUW/j+zHXsvZCD8iqNdltIhzZ4vJcHRvm7wbGVtYhVGhcGID0xABERUUsqqajG3vM52Jl0HcdSb0HzxzeztYUUQ7q2x+M9PTCkqzNklnwFR30YgPTEAERERGJRFZXjx6Qb2HHmOpJv/vlybgcbK4wKcMPjPT0QwrfU14oBSE8MQEREZAgu5RTh+zPX8cOZG8gpKteuV7S1wegAd4zo7ooADwdIpQxDAAOQ3hiAiIjIkKg1Ak5czcf3Z67jl3M3UVr55+s2nO1kGNbNBcMfcUa/jk5m/aZ6BiA9MQAREZGhulupxr5kFfaez8Ghy3koqajWbrOxssCgzk4I7+aCYd1c0NbWvCZQMwDpiQGIiIiMQUW1Giev3sa+iyrsT1bhZuGfl8mkEiC4QxsMf8QF4d1c4Nu+tYiVtgwGID0xABERkbG594yhe2Howo0ine2+7W0x/BEXDO/mgp5ebWBhgvOGGID0xABERETG7nrBXSiTVdh3UYUTV/NRpf7z676drTWGdnVG+CMuGNjJCa2sRX83epNgANITAxAREZmSovIqHL6ch30XVTh4KRdF5X/OG5JZSjHAzwnDH3HB0G7OcLaTi1ipfhiA9MQAREREpqpKrUFC+m3s++PsUPadu9ptEgkQpHBEeDcX/CPADR3a2YpYaeMxAOmJAYiIiMyBIAhIURVj/8WaMPR7dqHO9r6+bTGxtxcie7gaxe31DEB6YgAiIiJzpCoqhzI5F7+cv4mjqbdwLyHYyy0xrqcHJoQo0MPDQdwi68EApCcGICIiMnfXC+7i29+ysf23LFwv+PMyWQ8Pe0T19sKYQHc42FiJWOH9GID0xABERERUQ6MRcCztFrYmZGHfBRUq1TVvrZdZSjHK3w0TeisQ6tPWIN5NxgCkJwYgIiKi+90urcT3Z65je0IWUlTF2vU+TrZ4KsQT43t5wtlevLvIGID0xABERERUN0EQkJRVgO2/ZeHHpBvad5NZSCUY0sUZE3srMLhLe1haSFu0LgYgPTEAERERNUxpRTV2nbuJbQlZSLx2R7ve2U6G8cGemBCigLdTy9xOzwCkJwYgIiKixkvNLca2hCzsOH0d+aWV2vV9fdsiqrcCI3u4Nevt9AxAemIAIiIieniV1Rook1XYmpCFw1fytLfT28ktMS7IA1G9m+d2egYgPTEAERERNY26bqef2FuBJU8GNOnvasz3t2m8/YyIiIgMkoejDV4L74TZQ/1wLO0WtiVk4dcLKoR4txW1LgYgIiIianZSqQQDO7XHwE7tcae0EjbW4r5agwGIiIiIWlQbW2uxS0DL3qBPREREZAAYgIiIiMjsMAARERGR2WEAIiIiIrNjEAFo5cqV8Pb2hlwuR2hoKE6dOlVn27Vr12LgwIFo06YN2rRpg/Dw8PvaT5kyBRKJRGeJjIxs7mEQERGRkRA9AG3btg3R0dFYvHgxTp8+jcDAQERERCA3N7fW9nFxcXj66adx8OBBxMfHQ6FQYMSIEbh+/bpOu8jISNy8eVO7bNmypSWGQ0REREZA9CdBh4aGonfv3lixYgUAQKPRQKFQYPbs2XjrrbceuL9arUabNm2wYsUKTJo0CUDNGaCCggLs3LnzoWrik6CJiIiMT2O+v0U9A1RZWYnExESEh4dr10mlUoSHhyM+Pr5BfZSVlaGqqgpt2+o+UTIuLg7Ozs7o0qULZs6cifz8/Dr7qKioQFFRkc5CREREpkvUAHTr1i2o1Wq4uLjorHdxcUFOTk6D+njzzTfh7u6uE6IiIyOxadMmKJVKLF26FIcOHcLIkSOhVqtr7SM2NhYODg7aRaFQPPygiIiIyOAZ9ZOglyxZgq1btyIuLg5yuVy7fuLEido/+/v7IyAgAB07dkRcXByGDRt2Xz8LFixAdHS09ueioiKGICIiIhMm6hkgJycnWFhYQKVS6axXqVRwdXWtd9+PP/4YS5Yswa+//oqAgPrfJuvr6wsnJyekpqbWul0mk8He3l5nISIiItMlagCytrZGcHAwlEqldp1Go4FSqURYWFid+3344YeIiYnBnj17EBIS8sDfk52djfz8fLi5uTVJ3URERGTcRL8NPjo6GmvXrsXGjRuRnJyMmTNnorS0FFOnTgUATJo0CQsWLNC2X7p0KRYuXIivvvoK3t7eyMnJQU5ODkpKSgAAJSUleOONN3DixAlkZGRAqVRi7Nix8PPzQ0REhChjJCIiIsMi+hygqKgo5OXlYdGiRcjJyUFQUBD27NmjnRidmZkJqfTPnLZq1SpUVlZi/PjxOv0sXrwY7777LiwsLHD27Fls3LgRBQUFcHd3x4gRIxATEwOZTNagmu49GYB3gxERERmPe9/bDXnCj+jPATJE2dnZnARNRERkpLKysuDp6VlvGwagWmg0Gty4cQN2dnaQSCRN2ve9O8yysrJMfrI1x2q6zGm8HKvpMqfxmstYBUFAcXEx3N3dda4e1Ub0S2CGSCqVPjA56suc7jbjWE2XOY2XYzVd5jRecxirg4NDg9qJPgmaiIiIqKUxABEREZHZsXj33XffFbsIc2NhYYHBgwfD0tL0r0ByrKbLnMbLsZoucxqvOY21ITgJmoiIiMwOL4ERERGR2WEAIiIiIrPDAERERERmhwGIiIiIzA4DUDNYuXIlvL29IZfLERoailOnTtXb/ptvvkHXrl0hl8vh7++P3bt3t1ClDy82Nha9e/eGnZ0dnJ2dMW7cOKSkpNS7z4YNGyCRSHQWuVzeQhU/vHffffe+urt27VrvPsZ4TO/x9va+b7wSiQSzZs2qtb0xHdfDhw9j9OjRcHd3h0Qiwc6dO3W2C4KARYsWwc3NDTY2NggPD8eVK1ce2G9jP/Mtob6xVlVV4c0334S/vz9sbW3h7u6OSZMm4caNG/X2+TCfhZbyoGM7ZcqU+2qPjIx8YL/GdmwB1Pr5lUgk+Oijj+rs05CPbXNhAGpi27ZtQ3R0NBYvXozTp08jMDAQERERyM3NrbX98ePH8fTTT2P69Ok4c+YMxo0bh3HjxuH8+fMtXHnjHDp0CLNmzcKJEyewb98+VFVVYcSIESgtLa13P3t7e9y8eVO7XLt2rYUq1k/37t116j569GidbY31mN6TkJCgM9Z9+/YBAJ566qk69zGW41paWorAwECsXLmy1u0ffvghli9fjtWrV+PkyZOwtbVFREQEysvL6+yzsZ/5llLfWMvKynD69GksXLgQp0+fxo4dO5CSkoIxY8Y8sN/GfBZa0oOOLQBERkbq1L5ly5Z6+zTGYwtAZ4w3b97EV199BYlEgieffLLefg312DYbgZpUnz59hFmzZml/VqvVgru7uxAbG1tr+wkTJgijRo3SWRcaGiq8+OKLzVpnU8vNzRUACIcOHaqzzfr16wUHB4cWrKppLF68WAgMDGxwe1M5pve89tprQseOHQWNRlPrdmM9rgCE77//XvuzRqMRXF1dhY8++ki7rqCgQJDJZMKWLVvq7Kexn3kx/H2stTl16pQAQLh27VqdbRr7WRBLbeOdPHmyMHbs2Eb1YyrHduzYscLQoUPrbWMsx7Yp8QxQE6qsrERiYiLCw8O166RSKcLDwxEfH1/rPvHx8TrtASAiIqLO9oaqsLAQANC2bdt625WUlKBDhw5QKBQYO3YsLly40BLl6e3KlStwd3eHr68vnnnmGWRmZtbZ1lSOKVDz//TmzZsxbdq0el8MbKzH9a/S09ORk5Ojc+wcHBwQGhpa57F7mM+8oSosLIREIoGjo2O97RrzWTA0cXFxcHZ2RpcuXTBz5kzk5+fX2dZUjq1KpcKuXbswffr0B7Y15mP7MBiAmtCtW7egVqvh4uKis97FxQU5OTm17pOTk9Oo9oZIo9Fgzpw56N+/P3r06FFnuy5duuCrr77CDz/8gM2bN0Oj0aBfv37Izs5uwWobLzQ0FBs2bMCePXuwatUqpKenY+DAgSguLq61vSkc03t27tyJgoICTJkypc42xnpc/+7e8WnMsXuYz7whKi8vx5tvvomnn3663hdlNvazYEgiIyOxadMmKJVKLF26FIcOHcLIkSOhVqtrbW8qx3bjxo2ws7PDE088UW87Yz62D4vPwya9zZo1C+fPn3/g9eKwsDCEhYVpf+7Xrx+6deuGNWvWICYmprnLfGgjR47U/jkgIAChoaHo0KEDtm/f3qB/VRmzdevWYeTIkXB3d6+zjbEeV6pRVVWFCRMmQBAErFq1qt62xvxZmDhxovbP/v7+CAgIQMeOHREXF4dhw4aJWFnz+uqrr/DMM8888MYEYz62D4tngJqQk5MTLCwsoFKpdNarVCq4urrWuo+rq2uj2huaV155BT///DMOHjwIT0/PRu1rZWWFnj17IjU1tZmqax6Ojo7o3LlznXUb+zG959q1a9i/fz9mzJjRqP2M9bjeOz6NOXYP85k3JPfCz7Vr17Bv3756z/7U5kGfBUPm6+sLJyenOms39mMLAEeOHEFKSkqjP8OAcR/bhmIAakLW1tYIDg6GUqnUrtNoNFAqlTr/Qv6rsLAwnfYAsG/fvjrbGwpBEPDKK6/g+++/x4EDB+Dj49PoPtRqNc6dOwc3N7dmqLD5lJSUIC0trc66jfWY/t369evh7OyMUaNGNWo/Yz2uPj4+cHV11Tl2RUVFOHnyZJ3H7mE+84biXvi5cuUK9u/fj3bt2jW6jwd9FgxZdnY28vPz66zdmI/tPevWrUNwcDACAwMbva8xH9sGE3sWtqnZunWrIJPJhA0bNggXL14UXnjhBcHR0VHIyckRBEEQnnvuOeGtt97Stj927JhgaWkpfPzxx0JycrKwePFiwcrKSjh37pxYQ2iQmTNnCg4ODkJcXJxw8+ZN7VJWVqZt8/exvvfee8LevXuFtLQ0ITExUZg4caIgl8uFCxcuiDGEBps7d64QFxcnpKenC8eOHRPCw8MFJycnITc3VxAE0zmmf6VWqwUvLy/hzTffvG+bMR/X4uJi4cyZM8KZM2cEAMKnn34qnDlzRnvn05IlSwRHR0fhhx9+EM6ePSuMHTtW8PHxEe7evavtY+jQocLnn3+u/flBn3mx1DfWyspKYcyYMYKnp6eQlJSk8xmuqKjQ9vH3sT7osyCm+sZbXFwszJs3T4iPjxfS09OF/fv3C7169RI6deoklJeXa/swhWN7T2FhodCqVSth1apVtfZhTMe2uTAANYPPP/9c8PLyEqytrYU+ffoIJ06c0G579NFHhcmTJ+u03759u9C5c2fB2tpa6N69u7Br164WrrjxANS6rF+/Xtvm72OdM2eO9r+Li4uL8NhjjwmnT59u+eIbKSoqSnBzcxOsra0FDw8PISoqSkhNTdVuN5Vj+ld79+4VAAgpKSn3bTPm43rw4MFa/7+9Nx6NRiMsXLhQcHFxEWQymTBs2LD7/ht06NBBWLx4sc66+j7zYqlvrOnp6XV+hg8ePKjt4+9jfdBnQUz1jbesrEwYMWKE0L59e8HKykro0KGD8Pzzz98XZEzh2N6zZs0awcbGRigoKKi1D2M6ts1FIgiC0KynmIiIiIgMDOcAERERkdlhACIiIiKzwwBEREREZocBiIiIiMwOAxARERGZHQYgIiIiMjsMQERERGR2GICIiBogLi4OEokEBQUFYpdCRE2AAYiIiIjMDgMQERERmR0GICIyChqNBrGxsfDx8YGNjQ0CAwPx7bffAvjz8tSuXbsQEBAAuVyOvn374vz58zp9fPfdd+jevTtkMhm8vb3xySef6GyvqKjAm2++CYVCAZlMBj8/P6xbt06nTWJiIkJCQtCqVSv069cPKSkpzTtwImoWDEBEZBRiY2OxadMmrF69GhcuXMDrr7+OZ599FocOHdK2eeONN/DJJ58gISEB7du3x+jRo1FVVQWgJrhMmDABEydOxLlz5/Duu+9i4cKF2LBhg3b/SZMmYcuWLVi+fDmSk5OxZs0atG7dWqeOd955B5988gl+++03WFpaYtq0aS0yfiJqWnwZKhEZvIqKCrRt2xb79+9HWFiYdv2MGTNQVlaGF154AUOGDMHWrVsRFRUFALh9+zY8PT2xYcMGTJgwAc888wzy8vLw66+/avefP38+du3ahQsXLuDy5cvo0qUL9u3bh/Dw8PtqiIuLw5AhQ7B//34MGzYMALB7926MGjUKd+/ehVwub+b/CkTUlHgGiIgMXmpqKsrKyjB8+HC0bt1au2zatAlpaWnadn8NR23btkWXLl2QnJwMAEhOTkb//v11+u3fvz+uXLkCtVqNpKQkWFhY4NFHH623loCAAO2f3dzcAAC5ubl6j5GIWpal2AUQET1ISUkJAGDXrl3w8PDQ2SaTyXRC0MOysbFpUDsrKyvtnyUSCYCa+UlEZFx4BoiIDN4jjzwCmUyGzMxM+Pn56SwKhULb7sSJE9o/37lzB5cvX0a3bt0AAN26dcOxY8d0+j127Bg6d+4MCwsL+Pv7Q6PR6MwpIiLTxTNARGTw7OzsMG/ePLz++uvQaDQYMGAACgsLcezYMdjb26NDhw4AgPfffx/t2rWDi4sL3nnnHTg5OWHcuHEAgLlz56J3796IiYlBVFQU4uPjsWLFCnzxxRcAAG9vb0yePBnTpk3D8uXLERgYiGvXriE3NxcTJkwQbexE1DwYgIjIKMTExKB9+/aIjY3F1atX4ejoiF69euHtt9/WXoJasmQJXnvtNVy5cgVBQUH46aefYG1tDQDo1asXtm/fjkWLFiEmJgZubm54//33MWXKFO3vWLVqFd5++228/PLLyM/Ph5eXF95++20xhktEzYx3gRGR0bt3h9adO3fg6OgodjlEZAQ4B4iIiIjMDgMQERERmR1eAiMiIiKzwzNAREREZHYYgIiIiMjsMAARERGR2WEAIiIiIrPDAERERERmhwGIiIiIzA4DEBEREZkdBiAiIiIyOwxAREREZHb+P/CgSPUA8Z3wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучается, но как и без предобученных эмбеддингов в какой-то момент происходит переобучение. Loss на тестовой выборке снова начинает расти. Так что по сути, ситуация не меняется, и нет особой разницы, обучать эмбеддинг слой самостоятельно или брать готовые эмбеддинги."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка улучшить модель 1\n",
    "Попробую снова взять первую модель (без предобученных эмбеддингов, но взять маленький размер одного эмбеддинга (до этого я брала 180 - это примерно корень из размера словаря word2id; теперь попробую взять эмбеддинги размером 5). Возможно это спасет от переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = CNN(len(word2id), 5)\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model3 = model3.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting Epoch 0\n",
      "Training...\n",
      "Train loss: 0.7653459385037422\n",
      "Train loss: 0.7301801623720111\n",
      "Train loss: 0.7179129743576049\n",
      "Train loss: 0.711241582436348\n",
      "Train loss: 0.7072939063821521\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.7299639917910099, Val f1: 0.709339439868927, \n",
      "Val accuracy: 0.9680090546607971, Val precision: 0.5599786043167114, Val recall: 0.9680090546607971\n",
      "\n",
      "Val loss: 0.7078279672246991, Val f1: 0.6842839121818542, \n",
      "Val accuracy: 0.9363110661506653, Val precision: 0.5393483638763428, Val recall: 0.9363110661506653\n",
      "\n",
      "Val loss: 0.7005223250389099, Val f1: 0.6787593960762024, \n",
      "Val accuracy: 0.9273651838302612, Val precision: 0.5355235934257507, Val recall: 0.9273651838302612\n",
      "\n",
      "Val loss: 0.6971644839244102, Val f1: 0.6754658818244934, \n",
      "Val accuracy: 0.9228017926216125, Val precision: 0.5329264998435974, Val recall: 0.9228017926216125\n",
      "\n",
      "Val loss: 0.6952692646355856, Val f1: 0.6732805967330933, \n",
      "Val accuracy: 0.9202463030815125, Val precision: 0.5310658812522888, Val recall: 0.9202463030815125\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.3750029802322388, Val f1: 1.3165502548217773, \n",
      "Val accuracy: 1.7996304035186768, Val precision: 1.0382225513458252, Val recall: 1.7996304035186768\n",
      "\n",
      "Val loss: 0.9159784515698751, Val f1: 0.8854934573173523, \n",
      "Val accuracy: 1.2041797637939453, Val precision: 0.7003501057624817, Val recall: 1.2041797637939453\n",
      "\n",
      "Val loss: 0.8252126336097717, Val f1: 0.7929280400276184, \n",
      "Val accuracy: 1.0897313356399536, Val precision: 0.6234213709831238, Val recall: 1.0897313356399536\n",
      "\n",
      "Val loss: 0.7858496478625706, Val f1: 0.7588292360305786, \n",
      "Val accuracy: 1.0384591817855835, Val precision: 0.5980395078659058, Val recall: 1.0384591817855835\n",
      "\n",
      "Val loss: 0.763449596034156, Val f1: 0.738837480545044, \n",
      "Val accuracy: 1.0079773664474487, Val precision: 0.5833460688591003, Val recall: 1.0079773664474487\n",
      "\n",
      "\n",
      "starting Epoch 1\n",
      "Training...\n",
      "Train loss: 0.7313891872763634\n",
      "Train loss: 0.7089817867134557\n",
      "Train loss: 0.7004466593265534\n",
      "Train loss: 0.6964482834090048\n",
      "Train loss: 0.6935563633839289\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.7175055779516697, Val f1: 0.6521758437156677, \n",
      "Val accuracy: 0.6915128827095032, Val precision: 0.6174013018608093, Val recall: 0.6915128827095032\n",
      "\n",
      "Val loss: 0.6958067543578871, Val f1: 0.6353399753570557, \n",
      "Val accuracy: 0.6757693886756897, Val precision: 0.5998145937919617, Val recall: 0.6757693886756897\n",
      "\n",
      "Val loss: 0.6886185324192047, Val f1: 0.6295154690742493, \n",
      "Val accuracy: 0.6676332354545593, Val precision: 0.5959275960922241, Val recall: 0.6676332354545593\n",
      "\n",
      "Val loss: 0.6852616240729147, Val f1: 0.6267884373664856, \n",
      "Val accuracy: 0.6649697422981262, Val precision: 0.5931156873703003, Val recall: 0.6649697422981262\n",
      "\n",
      "Val loss: 0.6833896587292353, Val f1: 0.6245061755180359, \n",
      "Val accuracy: 0.6621739268302917, Val precision: 0.5912547707557678, Val recall: 0.6621739268302917\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.3492879271507263, Val f1: 1.2283679246902466, \n",
      "Val accuracy: 1.2857813835144043, Val precision: 1.1763895750045776, Val recall: 1.2857813835144043\n",
      "\n",
      "Val loss: 0.9003078738848368, Val f1: 0.8229014277458191, \n",
      "Val accuracy: 0.8694985508918762, Val precision: 0.781350314617157, Val recall: 0.8694985508918762\n",
      "\n",
      "Val loss: 0.8105727314949036, Val f1: 0.7385334968566895, \n",
      "Val accuracy: 0.7873288989067078, Val precision: 0.6958199739456177, Val recall: 0.7873288989067078\n",
      "\n",
      "Val loss: 0.7724979775292533, Val f1: 0.7078869938850403, \n",
      "Val accuracy: 0.753024697303772, Val precision: 0.6681469082832336, Val recall: 0.753024697303772\n",
      "\n",
      "Val loss: 0.751170900132921, Val f1: 0.6872100830078125, \n",
      "Val accuracy: 0.7296820878982544, Val precision: 0.6498305797576904, Val recall: 0.7296820878982544\n",
      "\n",
      "\n",
      "starting Epoch 2\n",
      "Training...\n",
      "Train loss: 0.719512902200222\n",
      "Train loss: 0.6949469212329749\n",
      "Train loss: 0.6873110139369965\n",
      "Train loss: 0.6838345127319222\n",
      "Train loss: 0.6814454141117278\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.705443013459444, Val f1: 0.6226338744163513, \n",
      "Val accuracy: 0.5917423963546753, Val precision: 0.6574912667274475, Val recall: 0.5917423963546753\n",
      "\n",
      "Val loss: 0.6835212617209463, Val f1: 0.6078552007675171, \n",
      "Val accuracy: 0.575943112373352, Val precision: 0.6439878940582275, Val recall: 0.575943112373352\n",
      "\n",
      "Val loss: 0.6755251252651214, Val f1: 0.6055787801742554, \n",
      "Val accuracy: 0.5740420818328857, Val precision: 0.6412259936332703, Val recall: 0.5740420818328857\n",
      "\n",
      "Val loss: 0.6723921316773144, Val f1: 0.6014689207077026, \n",
      "Val accuracy: 0.5699977278709412, Val precision: 0.6371200680732727, Val recall: 0.5699977278709412\n",
      "\n",
      "Val loss: 0.6705520614272072, Val f1: 0.5985957384109497, \n",
      "Val accuracy: 0.5673384070396423, Val precision: 0.6339492201805115, Val recall: 0.5673384070396423\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.3212408423423767, Val f1: 1.1796000003814697, \n",
      "Val accuracy: 1.0913996696472168, Val precision: 1.2837529182434082, Val recall: 1.0913996696472168\n",
      "\n",
      "Val loss: 0.8819656769434611, Val f1: 0.7886576056480408, \n",
      "Val accuracy: 0.7405707240104675, Val precision: 0.8441391587257385, Val recall: 0.7405707240104675\n",
      "\n",
      "Val loss: 0.7946933507919312, Val f1: 0.7102729082107544, \n",
      "Val accuracy: 0.6751731634140015, Val precision: 0.750228226184845, Val recall: 0.6751731634140015\n",
      "\n",
      "Val loss: 0.7575500692640033, Val f1: 0.6833950281143188, \n",
      "Val accuracy: 0.6491331458091736, Val precision: 0.7222084403038025, Val recall: 0.6491331458091736\n",
      "\n",
      "Val loss: 0.7373438278834025, Val f1: 0.6622573733329773, \n",
      "Val accuracy: 0.6277544498443604, Val precision: 0.7015842199325562, Val recall: 0.6277544498443604\n",
      "\n",
      "\n",
      "starting Epoch 3\n",
      "Training...\n",
      "Train loss: 0.7061482034623623\n",
      "Train loss: 0.6832412372935902\n",
      "Train loss: 0.6757811725139617\n",
      "Train loss: 0.6710363092707164\n",
      "Train loss: 0.6676175147294998\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6862758062779903, Val f1: 0.6670778393745422, \n",
      "Val accuracy: 0.6480706334114075, Val precision: 0.6879989504814148, Val recall: 0.6480706334114075\n",
      "\n",
      "Val loss: 0.6655266610058871, Val f1: 0.6448326706886292, \n",
      "Val accuracy: 0.6282085180282593, Val precision: 0.6629340052604675, Val recall: 0.6282085180282593\n",
      "\n",
      "Val loss: 0.658846195936203, Val f1: 0.6365476846694946, \n",
      "Val accuracy: 0.6201384663581848, Val precision: 0.6544032096862793, Val recall: 0.6201384663581848\n",
      "\n",
      "Val loss: 0.6563263268613103, Val f1: 0.630846381187439, \n",
      "Val accuracy: 0.6146885752677917, Val precision: 0.6483950614929199, Val recall: 0.6146885752677917\n",
      "\n",
      "Val loss: 0.6541279291822797, Val f1: 0.6294098496437073, \n",
      "Val accuracy: 0.6133973598480225, Val precision: 0.6467900276184082, Val recall: 0.6133973598480225\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.2904533743858337, Val f1: 1.2370257377624512, \n",
      "Val accuracy: 1.1726717948913574, Val precision: 1.3089091777801514, Val recall: 1.1726717948913574\n",
      "\n",
      "Val loss: 0.8602725466092428, Val f1: 0.8282801508903503, \n",
      "Val accuracy: 0.7962255477905273, Val precision: 0.8635156154632568, Val recall: 0.7962255477905273\n",
      "\n",
      "Val loss: 0.775851571559906, Val f1: 0.7431840896606445, \n",
      "Val accuracy: 0.7233446836471558, Val precision: 0.7649710178375244, Val recall: 0.7233446836471558\n",
      "\n",
      "Val loss: 0.7399048038891384, Val f1: 0.7149950265884399, \n",
      "Val accuracy: 0.6966246366500854, Val precision: 0.734961986541748, Val recall: 0.6966246366500854\n",
      "\n",
      "Val loss: 0.7208147181404961, Val f1: 0.692982017993927, \n",
      "Val accuracy: 0.6743180751800537, Val precision: 0.7134847044944763, Val recall: 0.6743180751800537\n",
      "\n",
      "\n",
      "starting Epoch 4\n",
      "Training...\n",
      "Train loss: 0.6932668425142765\n",
      "Train loss: 0.6694938161156394\n",
      "Train loss: 0.6611607050895691\n",
      "Train loss: 0.6562807924711882\n",
      "Train loss: 0.6528184690645763\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6713476032018661, Val f1: 0.6600899696350098, \n",
      "Val accuracy: 0.6158983111381531, Val precision: 0.711813747882843, Val recall: 0.6158983111381531\n",
      "\n",
      "Val loss: 0.6519327886176832, Val f1: 0.6397533416748047, \n",
      "Val accuracy: 0.5967708826065063, Val precision: 0.6902098059654236, Val recall: 0.5967708826065063\n",
      "\n",
      "Val loss: 0.6456631445884704, Val f1: 0.6316186785697937, \n",
      "Val accuracy: 0.5881995558738708, Val precision: 0.6827191710472107, Val recall: 0.5881995558738708\n",
      "\n",
      "Val loss: 0.6424192964141049, Val f1: 0.6298888921737671, \n",
      "Val accuracy: 0.5859126448631287, Val precision: 0.6816893219947815, Val recall: 0.5859126448631287\n",
      "\n",
      "Val loss: 0.6402650986398969, Val f1: 0.6276453733444214, \n",
      "Val accuracy: 0.5840394496917725, Val precision: 0.6789640784263611, Val recall: 0.5840394496917725\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.2672479748725891, Val f1: 1.222292184829712, \n",
      "Val accuracy: 1.1130603551864624, Val precision: 1.3553873300552368, Val recall: 1.1130603551864624\n",
      "\n",
      "Val loss: 0.8445214827855428, Val f1: 0.8192111849784851, \n",
      "Val accuracy: 0.7541384696960449, Val precision: 0.8972411751747131, Val recall: 0.7541384696960449\n",
      "\n",
      "Val loss: 0.7615922808647155, Val f1: 0.7392991185188293, \n",
      "Val accuracy: 0.6884918212890625, Val precision: 0.799118161201477, Val recall: 0.6884918212890625\n",
      "\n",
      "Val loss: 0.7267164077077594, Val f1: 0.7037218809127808, \n",
      "Val accuracy: 0.6546460390090942, Val precision: 0.7614321708679199, Val recall: 0.6546460390090942\n",
      "\n",
      "Val loss: 0.7083522015147738, Val f1: 0.680809736251831, \n",
      "Val accuracy: 0.6324832439422607, Val precision: 0.7377426028251648, Val recall: 0.6324832439422607\n",
      "\n",
      "\n",
      "starting Epoch 5\n",
      "Training...\n",
      "Train loss: 0.6795428209006786\n",
      "Train loss: 0.6539643713922212\n",
      "Train loss: 0.645698823928833\n",
      "Train loss: 0.6412185928714809\n",
      "Train loss: 0.637385449948765\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6583612933754921, Val f1: 0.6763833165168762, \n",
      "Val accuracy: 0.6334673166275024, Val precision: 0.7260341644287109, Val recall: 0.6334673166275024\n",
      "\n",
      "Val loss: 0.6377882794900374, Val f1: 0.6600602865219116, \n",
      "Val accuracy: 0.6186453104019165, Val precision: 0.7078382968902588, Val recall: 0.6186453104019165\n",
      "\n",
      "Val loss: 0.6299571228027344, Val f1: 0.655799925327301, \n",
      "Val accuracy: 0.6154241561889648, Val precision: 0.7023669481277466, Val recall: 0.6154241561889648\n",
      "\n",
      "Val loss: 0.6270635813029845, Val f1: 0.650638222694397, \n",
      "Val accuracy: 0.61092609167099, Val precision: 0.696376383304596, Val recall: 0.61092609167099\n",
      "\n",
      "Val loss: 0.6246991547800246, Val f1: 0.6490314602851868, \n",
      "Val accuracy: 0.6105533838272095, Val precision: 0.6931854486465454, Val recall: 0.6105533838272095\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.2425090074539185, Val f1: 1.2631046772003174, \n",
      "Val accuracy: 1.1658694744110107, Val precision: 1.3786522150039673, Val recall: 1.1658694744110107\n",
      "\n",
      "Val loss: 0.8274549643198649, Val f1: 0.8441645503044128, \n",
      "Val accuracy: 0.7843493819236755, Val precision: 0.9142837524414062, Val recall: 0.7843493819236755\n",
      "\n",
      "Val loss: 0.7470543265342713, Val f1: 0.7577400207519531, \n",
      "Val accuracy: 0.7114250063896179, Val precision: 0.8111809492111206, Val recall: 0.7114250063896179\n",
      "\n",
      "Val loss: 0.7130768639700753, Val f1: 0.7196447253227234, \n",
      "Val accuracy: 0.674757182598114, Val precision: 0.771441638469696, Val recall: 0.674757182598114\n",
      "\n",
      "Val loss: 0.6951336397065057, Val f1: 0.6965451240539551, \n",
      "Val accuracy: 0.6524456739425659, Val precision: 0.7477614879608154, Val recall: 0.6524456739425659\n",
      "\n",
      "\n",
      "starting Epoch 6\n",
      "Training...\n",
      "Train loss: 0.6566190272569656\n",
      "Train loss: 0.6342497612490798\n",
      "Train loss: 0.6282207334041595\n",
      "Train loss: 0.6245814944381145\n",
      "Train loss: 0.6224188265346345\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6439054757356644, Val f1: 0.7054969072341919, \n",
      "Val accuracy: 0.691594660282135, Val precision: 0.7204641103744507, Val recall: 0.691594660282135\n",
      "\n",
      "Val loss: 0.624595071330215, Val f1: 0.6861398220062256, \n",
      "Val accuracy: 0.6729176640510559, Val precision: 0.7003127336502075, Val recall: 0.6729176640510559\n",
      "\n",
      "Val loss: 0.6184824776649475, Val f1: 0.680528461933136, \n",
      "Val accuracy: 0.6661977171897888, Val precision: 0.6958776712417603, Val recall: 0.6661977171897888\n",
      "\n",
      "Val loss: 0.6149906249188665, Val f1: 0.6790637969970703, \n",
      "Val accuracy: 0.6646621227264404, Val precision: 0.6944836974143982, Val recall: 0.6646621227264404\n",
      "\n",
      "Val loss: 0.6127344206685111, Val f1: 0.6771578788757324, \n",
      "Val accuracy: 0.6611291170120239, Val precision: 0.6943987011909485, Val recall: 0.6611291170120239\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.2242704033851624, Val f1: 1.314821720123291, \n",
      "Val accuracy: 1.2530310153961182, Val precision: 1.383376121520996, Val recall: 1.2530310153961182\n",
      "\n",
      "Val loss: 0.8141451279322306, Val f1: 0.8802763819694519, \n",
      "Val accuracy: 0.847217321395874, Val precision: 0.9167446494102478, Val recall: 0.847217321395874\n",
      "\n",
      "Val loss: 0.735575532913208, Val f1: 0.7924425601959229, \n",
      "Val accuracy: 0.7727377414703369, Val precision: 0.8141931295394897, Val recall: 0.7727377414703369\n",
      "\n",
      "Val loss: 0.7020535724503654, Val f1: 0.7525266408920288, \n",
      "Val accuracy: 0.7335115075111389, Val precision: 0.773322582244873, Val recall: 0.7335115075111389\n",
      "\n",
      "Val loss: 0.6845469143655565, Val f1: 0.727554440498352, \n",
      "Val accuracy: 0.7092214226722717, Val precision: 0.7476276755332947, Val recall: 0.7092214226722717\n",
      "\n",
      "\n",
      "starting Epoch 7\n",
      "Training...\n",
      "Train loss: 0.6428611874580383\n",
      "Train loss: 0.6221108508832527\n",
      "Train loss: 0.6156479728221893\n",
      "Train loss: 0.6121615055781692\n",
      "Train loss: 0.6103747011650176\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6327388621866703, Val f1: 0.7240949273109436, \n",
      "Val accuracy: 0.7162721753120422, Val precision: 0.7324621677398682, Val recall: 0.7162721753120422\n",
      "\n",
      "Val loss: 0.6125941908720768, Val f1: 0.7023154497146606, \n",
      "Val accuracy: 0.6930999159812927, Val precision: 0.712295413017273, Val recall: 0.6930999159812927\n",
      "\n",
      "Val loss: 0.6067314970493317, Val f1: 0.6954822540283203, \n",
      "Val accuracy: 0.6853882670402527, Val precision: 0.7062806487083435, Val recall: 0.6853882670402527\n",
      "\n",
      "Val loss: 0.6030251561705746, Val f1: 0.6940079927444458, \n",
      "Val accuracy: 0.6836519241333008, Val precision: 0.7050697803497314, Val recall: 0.6836519241333008\n",
      "\n",
      "Val loss: 0.6008111089468002, Val f1: 0.6924626231193542, \n",
      "Val accuracy: 0.6813505291938782, Val precision: 0.7043406367301941, Val recall: 0.6813505291938782\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.207650065422058, Val f1: 1.3231637477874756, \n",
      "Val accuracy: 1.270896553993225, Val precision: 1.381195068359375, Val recall: 1.270896553993225\n",
      "\n",
      "Val loss: 0.8026275237401327, Val f1: 0.8896241784095764, \n",
      "Val accuracy: 0.862021267414093, Val precision: 0.9199986457824707, Val recall: 0.862021267414093\n",
      "\n",
      "Val loss: 0.7251485347747803, Val f1: 0.800322413444519, \n",
      "Val accuracy: 0.7856267690658569, Val precision: 0.8167068362236023, Val recall: 0.7856267690658569\n",
      "\n",
      "Val loss: 0.6922637309346881, Val f1: 0.7602075338363647, \n",
      "Val accuracy: 0.7469944357872009, Val precision: 0.7747554779052734, Val recall: 0.7469944357872009\n",
      "\n",
      "Val loss: 0.6754492455058627, Val f1: 0.735389232635498, \n",
      "Val accuracy: 0.7223296165466309, Val precision: 0.7497403621673584, Val recall: 0.7223296165466309\n",
      "\n",
      "\n",
      "starting Epoch 8\n",
      "Training...\n",
      "Train loss: 0.6395321525633335\n",
      "Train loss: 0.6156365167010914\n",
      "Train loss: 0.6062474691867829\n",
      "Train loss: 0.6016675002539336\n",
      "Train loss: 0.5979923989091601\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6175287030637264, Val f1: 0.7320334911346436, \n",
      "Val accuracy: 0.7098322510719299, Val precision: 0.7560842633247375, Val recall: 0.7098322510719299\n",
      "\n",
      "Val loss: 0.5972776774204138, Val f1: 0.7120806574821472, \n",
      "Val accuracy: 0.6908968687057495, Val precision: 0.7350253462791443, Val recall: 0.6908968687057495\n",
      "\n",
      "Val loss: 0.5919050574302673, Val f1: 0.7037081718444824, \n",
      "Val accuracy: 0.6821972131729126, Val precision: 0.7269970178604126, Val recall: 0.6821972131729126\n",
      "\n",
      "Val loss: 0.5885036561026502, Val f1: 0.7006496787071228, \n",
      "Val accuracy: 0.6794062256813049, Val precision: 0.7236359119415283, Val recall: 0.6794062256813049\n",
      "\n",
      "Val loss: 0.5872433696474347, Val f1: 0.6970550417900085, \n",
      "Val accuracy: 0.6762393116950989, Val precision: 0.7195574641227722, Val recall: 0.6762393116950989\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1861274242401123, Val f1: 1.3332538604736328, \n",
      "Val accuracy: 1.2571213245391846, Val precision: 1.4201931953430176, Val recall: 1.2571213245391846\n",
      "\n",
      "Val loss: 0.7891851862271627, Val f1: 0.8988866806030273, \n",
      "Val accuracy: 0.8581604361534119, Val precision: 0.9448971748352051, Val recall: 0.8581604361534119\n",
      "\n",
      "Val loss: 0.7131227016448974, Val f1: 0.8051904439926147, \n",
      "Val accuracy: 0.7777290344238281, Val precision: 0.8359241485595703, Val recall: 0.7777290344238281\n",
      "\n",
      "Val loss: 0.6808009488242013, Val f1: 0.7666773200035095, \n",
      "Val accuracy: 0.740817129611969, Val precision: 0.7953446507453918, Val recall: 0.740817129611969\n",
      "\n",
      "Val loss: 0.6649970743391249, Val f1: 0.7403182983398438, \n",
      "Val accuracy: 0.715914785861969, Val precision: 0.767330527305603, Val recall: 0.715914785861969\n",
      "\n",
      "\n",
      "starting Epoch 9\n",
      "Training...\n",
      "Train loss: 0.6223526857793331\n",
      "Train loss: 0.5985529404697996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5923423099517823\n",
      "Train loss: 0.5872749659552503\n",
      "Train loss: 0.5854785300436474\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.610469002276659, Val f1: 0.7237602472305298, \n",
      "Val accuracy: 0.6640839576721191, Val precision: 0.7958225011825562, Val recall: 0.6640839576721191\n",
      "\n",
      "Val loss: 0.5911363489700087, Val f1: 0.7001261711120605, \n",
      "Val accuracy: 0.6433091163635254, Val precision: 0.7686737179756165, Val recall: 0.6433091163635254\n",
      "\n",
      "Val loss: 0.5841828203201294, Val f1: 0.6936816573143005, \n",
      "Val accuracy: 0.6373755931854248, Val precision: 0.7615124583244324, Val recall: 0.6373755931854248\n",
      "\n",
      "Val loss: 0.5808115912907159, Val f1: 0.6902576684951782, \n",
      "Val accuracy: 0.6342372894287109, Val precision: 0.7576820254325867, Val recall: 0.6342372894287109\n",
      "\n",
      "Val loss: 0.5793313611121405, Val f1: 0.6879891753196716, \n",
      "Val accuracy: 0.6320376992225647, Val precision: 0.755416214466095, Val recall: 0.6320376992225647\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1780751943588257, Val f1: 1.314399242401123, \n",
      "Val accuracy: 1.173557996749878, Val precision: 1.495091199874878, Val recall: 1.173557996749878\n",
      "\n",
      "Val loss: 0.7839872439702352, Val f1: 0.8814167976379395, \n",
      "Val accuracy: 0.7946341633796692, Val precision: 0.9903702139854431, Val recall: 0.7946341633796692\n",
      "\n",
      "Val loss: 0.7068281769752502, Val f1: 0.7913768887519836, \n",
      "Val accuracy: 0.7220058441162109, Val precision: 0.8767218589782715, Val recall: 0.7220058441162109\n",
      "\n",
      "Val loss: 0.6753696969577244, Val f1: 0.7522441744804382, \n",
      "Val accuracy: 0.6857873201370239, Val precision: 0.8339070677757263, Val recall: 0.6857873201370239\n",
      "\n",
      "Val loss: 0.6595059633255005, Val f1: 0.7261502146720886, \n",
      "Val accuracy: 0.6619951725006104, Val precision: 0.8048978447914124, Val recall: 0.6619951725006104\n",
      "\n",
      "\n",
      "starting Epoch 10\n",
      "Training...\n",
      "Train loss: 0.6078545153141022\n",
      "Train loss: 0.5877471746820392\n",
      "Train loss: 0.5808075964450836\n",
      "Train loss: 0.5766361747215043\n",
      "Train loss: 0.5738450239102045\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5953032039105892, Val f1: 0.7578062415122986, \n",
      "Val accuracy: 0.7451932430267334, Val precision: 0.7710988521575928, Val recall: 0.7451932430267334\n",
      "\n",
      "Val loss: 0.5774714820312731, Val f1: 0.7352412939071655, \n",
      "Val accuracy: 0.7246927618980408, Val precision: 0.7463809847831726, Val recall: 0.7246927618980408\n",
      "\n",
      "Val loss: 0.5712276840209961, Val f1: 0.7279212474822998, \n",
      "Val accuracy: 0.7176693081855774, Val precision: 0.7388209700584412, Val recall: 0.7176693081855774\n",
      "\n",
      "Val loss: 0.5686384430572168, Val f1: 0.7244991660118103, \n",
      "Val accuracy: 0.7139685750007629, Val precision: 0.7357119917869568, Val recall: 0.7139685750007629\n",
      "\n",
      "Val loss: 0.5666231392394929, Val f1: 0.7225486040115356, \n",
      "Val accuracy: 0.7119978666305542, Val precision: 0.7337711453437805, Val recall: 0.7119978666305542\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1602295637130737, Val f1: 1.3791701793670654, \n",
      "Val accuracy: 1.3404879570007324, Val precision: 1.4206185340881348, Val recall: 1.3404879570007324\n",
      "\n",
      "Val loss: 0.7715372244517008, Val f1: 0.9230306148529053, \n",
      "Val accuracy: 0.8998586535453796, Val precision: 0.9478569030761719, Val recall: 0.8998586535453796\n",
      "\n",
      "Val loss: 0.6966926217079162, Val f1: 0.8268639445304871, \n",
      "Val accuracy: 0.8139359354972839, Val precision: 0.8408142328262329, Val recall: 0.8139359354972839\n",
      "\n",
      "Val loss: 0.6658495238849095, Val f1: 0.7880730032920837, \n",
      "Val accuracy: 0.7746939659118652, Val precision: 0.8023688197135925, Val recall: 0.7746939659118652\n",
      "\n",
      "Val loss: 0.6503042976061503, Val f1: 0.7617228627204895, \n",
      "Val accuracy: 0.7494809627532959, Val precision: 0.7749694585800171, Val recall: 0.7494809627532959\n",
      "\n",
      "\n",
      "starting Epoch 11\n",
      "Training...\n",
      "Train loss: 0.5921845659613609\n",
      "Train loss: 0.5738830891522494\n",
      "Train loss: 0.5681989514827728\n",
      "Train loss: 0.5651139777098129\n",
      "Train loss: 0.5631914124602363\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5831154547631741, Val f1: 0.7593858242034912, \n",
      "Val accuracy: 0.7269147634506226, Val precision: 0.795205295085907, Val recall: 0.7269147634506226\n",
      "\n",
      "Val loss: 0.5657694159132062, Val f1: 0.7363650798797607, \n",
      "Val accuracy: 0.7036207914352417, Val precision: 0.7726554870605469, Val recall: 0.7036207914352417\n",
      "\n",
      "Val loss: 0.5602169299125671, Val f1: 0.7283921241760254, \n",
      "Val accuracy: 0.6965864300727844, Val precision: 0.7636638879776001, Val recall: 0.6965864300727844\n",
      "\n",
      "Val loss: 0.5570842152211204, Val f1: 0.7240206003189087, \n",
      "Val accuracy: 0.6921898722648621, Val precision: 0.7593826055526733, Val recall: 0.6921898722648621\n",
      "\n",
      "Val loss: 0.5549155544667017, Val f1: 0.7217692136764526, \n",
      "Val accuracy: 0.6892104744911194, Val precision: 0.758031964302063, Val recall: 0.6892104744911194\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1442959308624268, Val f1: 1.3598674535751343, \n",
      "Val accuracy: 1.2610149383544922, Val precision: 1.4761415719985962, Val recall: 1.2610149383544922\n",
      "\n",
      "Val loss: 0.7617207368214926, Val f1: 0.9121005535125732, \n",
      "Val accuracy: 0.8535647988319397, Val precision: 0.9797282218933105, Val recall: 0.8535647988319397\n",
      "\n",
      "Val loss: 0.6875434875488281, Val f1: 0.8174983263015747, \n",
      "Val accuracy: 0.7745621204376221, Val precision: 0.8663991093635559, Val recall: 0.7745621204376221\n",
      "\n",
      "Val loss: 0.6572125468935285, Val f1: 0.7795283198356628, \n",
      "Val accuracy: 0.7388230562210083, Val precision: 0.8256736993789673, Val recall: 0.7388230562210083\n",
      "\n",
      "Val loss: 0.642597410413954, Val f1: 0.7540009021759033, \n",
      "Val accuracy: 0.715919017791748, Val precision: 0.7970083355903625, Val recall: 0.715919017791748\n",
      "\n",
      "\n",
      "starting Epoch 12\n",
      "Training...\n",
      "Train loss: 0.5867112129926682\n",
      "Train loss: 0.5662163297335306\n",
      "Train loss: 0.559640451669693\n",
      "Train loss: 0.5563291026585138\n",
      "Train loss: 0.5540530958345958\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5744064711034298, Val f1: 0.7718259692192078, \n",
      "Val accuracy: 0.7554612159729004, Val precision: 0.7893804311752319, Val recall: 0.7554612159729004\n",
      "\n",
      "Val loss: 0.5572316700761969, Val f1: 0.7485604286193848, \n",
      "Val accuracy: 0.7328924536705017, Val precision: 0.7653911709785461, Val recall: 0.7328924536705017\n",
      "\n",
      "Val loss: 0.5516691076755523, Val f1: 0.7419283986091614, \n",
      "Val accuracy: 0.7263186573982239, Val precision: 0.7586547136306763, Val recall: 0.7263186573982239\n",
      "\n",
      "Val loss: 0.548587280422894, Val f1: 0.740251362323761, \n",
      "Val accuracy: 0.7250721454620361, Val precision: 0.7564765214920044, Val recall: 0.7250721454620361\n",
      "\n",
      "Val loss: 0.5464873860279719, Val f1: 0.7379528880119324, \n",
      "Val accuracy: 0.7229769825935364, Val precision: 0.753945529460907, Val recall: 0.7229769825935364\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1337090730667114, Val f1: 1.4067457914352417, \n",
      "Val accuracy: 1.3522670269012451, Val precision: 1.4661372900009155, Val recall: 1.3522670269012451\n",
      "\n",
      "Val loss: 0.7544137636820475, Val f1: 0.9352535605430603, \n",
      "Val accuracy: 0.9024251103401184, Val precision: 0.9708437323570251, Val recall: 0.9024251103401184\n",
      "\n",
      "Val loss: 0.6814321398735046, Val f1: 0.8368788957595825, \n",
      "Val accuracy: 0.8174727559089661, Val precision: 0.8579564094543457, Val recall: 0.8174727559089661\n",
      "\n",
      "Val loss: 0.6516365834644863, Val f1: 0.7969452738761902, \n",
      "Val accuracy: 0.7774982452392578, Val precision: 0.8179215788841248, Val recall: 0.7774982452392578\n",
      "\n",
      "Val loss: 0.6366754306687249, Val f1: 0.7713563442230225, \n",
      "Val accuracy: 0.7543458938598633, Val precision: 0.7896706461906433, Val recall: 0.7543458938598633\n",
      "\n",
      "\n",
      "starting Epoch 13\n",
      "Training...\n",
      "Train loss: 0.5663943402469158\n",
      "Train loss: 0.5547103647029761\n",
      "Train loss: 0.5495891690254211\n",
      "Train loss: 0.5466166120856556\n",
      "Train loss: 0.5443621114605949\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5644766725599766, Val f1: 0.7887710332870483, \n",
      "Val accuracy: 0.7878507971763611, Val precision: 0.7901217937469482, Val recall: 0.7878507971763611\n",
      "\n",
      "Val loss: 0.5456421772638956, Val f1: 0.76331627368927, \n",
      "Val accuracy: 0.7556720972061157, Val precision: 0.7717069983482361, Val recall: 0.7556720972061157\n",
      "\n",
      "Val loss: 0.5406611168384552, Val f1: 0.7556131482124329, \n",
      "Val accuracy: 0.7484667897224426, Val precision: 0.7634247541427612, Val recall: 0.7484667897224426\n",
      "\n",
      "Val loss: 0.5386386664945688, Val f1: 0.7513073086738586, \n",
      "Val accuracy: 0.7435009479522705, Val precision: 0.7597362995147705, Val recall: 0.7435009479522705\n",
      "\n",
      "Val loss: 0.5372692552350816, Val f1: 0.7483883500099182, \n",
      "Val accuracy: 0.7407233715057373, Val precision: 0.7566615343093872, Val recall: 0.7407233715057373\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.123540461063385, Val f1: 1.4086527824401855, \n",
      "Val accuracy: 1.3656482696533203, Val precision: 1.454698085784912, Val recall: 1.3656482696533203\n",
      "\n",
      "Val loss: 0.747500479221344, Val f1: 0.9422257542610168, \n",
      "Val accuracy: 0.9202534556388855, Val precision: 0.9655405879020691, Val recall: 0.9202534556388855\n",
      "\n",
      "Val loss: 0.675134253501892, Val f1: 0.8426998257637024, \n",
      "Val accuracy: 0.832182765007019, Val precision: 0.8541110754013062, Val recall: 0.832182765007019\n",
      "\n",
      "Val loss: 0.6455116868019104, Val f1: 0.8055800199508667, \n",
      "Val accuracy: 0.7952121496200562, Val precision: 0.8166693449020386, Val recall: 0.7952121496200562\n",
      "\n",
      "Val loss: 0.6305619478225708, Val f1: 0.7796370983123779, \n",
      "Val accuracy: 0.7711235284805298, Val precision: 0.7887488603591919, Val recall: 0.7711235284805298\n",
      "\n",
      "\n",
      "starting Epoch 14\n",
      "Training...\n",
      "Train loss: 0.5617231391370296\n",
      "Train loss: 0.545724711634896\n",
      "Train loss: 0.5399043345451355\n",
      "Train loss: 0.5368075157279399\n",
      "Train loss: 0.5354034886473701\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5585211999714375, Val f1: 0.7967261075973511, \n",
      "Val accuracy: 0.806515097618103, Val precision: 0.7875385284423828, Val recall: 0.806515097618103\n",
      "\n",
      "Val loss: 0.5402169805584531, Val f1: 0.7739210724830627, \n",
      "Val accuracy: 0.7801288366317749, Val precision: 0.7683464884757996, Val recall: 0.7801288366317749\n",
      "\n",
      "Val loss: 0.5335299742221832, Val f1: 0.7664787769317627, \n",
      "Val accuracy: 0.7727364897727966, Val precision: 0.7607707977294922, Val recall: 0.7727364897727966\n",
      "\n",
      "Val loss: 0.5311221320237687, Val f1: 0.7628651857376099, \n",
      "Val accuracy: 0.7676994204521179, Val precision: 0.7585223317146301, Val recall: 0.7676994204521179\n",
      "\n",
      "Val loss: 0.5303840488195419, Val f1: 0.759893536567688, \n",
      "Val accuracy: 0.7650073170661926, Val precision: 0.7552210688591003, Val recall: 0.7650073170661926\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1154704689979553, Val f1: 1.426581621170044, \n",
      "Val accuracy: 1.4188511371612549, Val precision: 1.435612440109253, Val recall: 1.4188511371612549\n",
      "\n",
      "Val loss: 0.7417467633883158, Val f1: 0.9548459053039551, \n",
      "Val accuracy: 0.9531839489936829, Val precision: 0.9569525718688965, Val recall: 0.9531839489936829\n",
      "\n",
      "Val loss: 0.6702405452728272, Val f1: 0.8529486656188965, \n",
      "Val accuracy: 0.8595447540283203, Val precision: 0.8470348119735718, Val recall: 0.8595447540283203\n",
      "\n",
      "Val loss: 0.6408361877713885, Val f1: 0.814224123954773, \n",
      "Val accuracy: 0.8190308213233948, Val precision: 0.8099055290222168, Val recall: 0.8190308213233948\n",
      "\n",
      "Val loss: 0.6264855530526903, Val f1: 0.7879346609115601, \n",
      "Val accuracy: 0.7940870523452759, Val precision: 0.7822763919830322, Val recall: 0.7940870523452759\n",
      "\n",
      "\n",
      "starting Epoch 15\n",
      "Training...\n",
      "Train loss: 0.5519786216318607\n",
      "Train loss: 0.5351665462508346\n",
      "Train loss: 0.5293400365114213\n",
      "Train loss: 0.5272158606728511\n",
      "Train loss: 0.5246964473099935\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5445208456367254, Val f1: 0.8006781339645386, \n",
      "Val accuracy: 0.7872151732444763, Val precision: 0.8149436712265015, Val recall: 0.7872151732444763\n",
      "\n",
      "Val loss: 0.5303890136155215, Val f1: 0.7746695876121521, \n",
      "Val accuracy: 0.7629756927490234, Val precision: 0.7869625091552734, Val recall: 0.7629756927490234\n",
      "\n",
      "Val loss: 0.5251321959495544, Val f1: 0.7670400738716125, \n",
      "Val accuracy: 0.7556154131889343, Val precision: 0.7790957093238831, Val recall: 0.7556154131889343\n",
      "\n",
      "Val loss: 0.5218482217681941, Val f1: 0.7642566561698914, \n",
      "Val accuracy: 0.7534545063972473, Val precision: 0.7756361365318298, Val recall: 0.7534545063972473\n",
      "\n",
      "Val loss: 0.5199812615201587, Val f1: 0.7619001269340515, \n",
      "Val accuracy: 0.7500826716423035, Val precision: 0.7743743658065796, Val recall: 0.7500826716423035\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1038863062858582, Val f1: 1.4157764911651611, \n",
      "Val accuracy: 1.3702311515808105, Val precision: 1.46547532081604, Val recall: 1.3702311515808105\n",
      "\n",
      "Val loss: 0.7349705696105957, Val f1: 0.9477879405021667, \n",
      "Val accuracy: 0.9217081069946289, Val precision: 0.9757826328277588, Val recall: 0.9217081069946289\n",
      "\n",
      "Val loss: 0.6634374499320984, Val f1: 0.8474335670471191, \n",
      "Val accuracy: 0.8326587677001953, Val precision: 0.8634178042411804, Val recall: 0.8326587677001953\n",
      "\n",
      "Val loss: 0.6346003753798348, Val f1: 0.8096596598625183, \n",
      "Val accuracy: 0.7952861189842224, Val precision: 0.8250457644462585, Val recall: 0.7952861189842224\n",
      "\n",
      "Val loss: 0.6205883158577813, Val f1: 0.7843899130821228, \n",
      "Val accuracy: 0.7714493870735168, Val precision: 0.7981693744659424, Val recall: 0.7714493870735168\n",
      "\n",
      "\n",
      "starting Epoch 16\n",
      "Training...\n",
      "Train loss: 0.5379434656351805\n",
      "Train loss: 0.5203912438768329\n",
      "Train loss: 0.5187114995718002\n",
      "Train loss: 0.5180544524050471\n",
      "Train loss: 0.5168901465478397\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5389854572713375, Val f1: 0.7998765707015991, \n",
      "Val accuracy: 0.7765929102897644, Val precision: 0.8248547911643982, Val recall: 0.7765929102897644\n",
      "\n",
      "Val loss: 0.5210221969720089, Val f1: 0.775156557559967, \n",
      "Val accuracy: 0.7510870695114136, Val precision: 0.8010846376419067, Val recall: 0.7510870695114136\n",
      "\n",
      "Val loss: 0.5146769332885742, Val f1: 0.7699601054191589, \n",
      "Val accuracy: 0.7467318773269653, Val precision: 0.7949565052986145, Val recall: 0.7467318773269653\n",
      "\n",
      "Val loss: 0.5131274621878097, Val f1: 0.7655378580093384, \n",
      "Val accuracy: 0.7423954010009766, Val precision: 0.7904794216156006, Val recall: 0.7423954010009766\n",
      "\n",
      "Val loss: 0.5111126058868, Val f1: 0.7641473412513733, \n",
      "Val accuracy: 0.7420811057090759, Val precision: 0.7879056334495544, Val recall: 0.7420811057090759\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.095502495765686, Val f1: 1.4080532789230347, \n",
      "Val accuracy: 1.3449723720550537, Val precision: 1.478405237197876, Val recall: 1.3449723720550537\n",
      "\n",
      "Val loss: 0.7292709549268087, Val f1: 0.9421062469482422, \n",
      "Val accuracy: 0.9037088751792908, Val precision: 0.9843061566352844, Val recall: 0.9037088751792908\n",
      "\n",
      "Val loss: 0.6580540418624878, Val f1: 0.8437632322311401, \n",
      "Val accuracy: 0.818646252155304, Val precision: 0.8711966276168823, Val recall: 0.818646252155304\n",
      "\n",
      "Val loss: 0.6299032143184117, Val f1: 0.8055506944656372, \n",
      "Val accuracy: 0.7815388441085815, Val precision: 0.8316100835800171, Val recall: 0.7815388441085815\n",
      "\n",
      "Val loss: 0.6159207688437568, Val f1: 0.7811936140060425, \n",
      "Val accuracy: 0.7588232755661011, Val precision: 0.805396556854248, Val recall: 0.7588232755661011\n",
      "\n",
      "\n",
      "starting Epoch 17\n",
      "Training...\n",
      "Train loss: 0.5347619950771332\n",
      "Train loss: 0.5171590908007189\n",
      "Train loss: 0.5107576608657837\n",
      "Train loss: 0.509172299459799\n",
      "Train loss: 0.5083044778023448\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5299338959157467, Val f1: 0.8150309920310974, \n",
      "Val accuracy: 0.8146675825119019, Val precision: 0.8156335353851318, Val recall: 0.8146675825119019\n",
      "\n",
      "Val loss: 0.5151732816840663, Val f1: 0.7917785048484802, \n",
      "Val accuracy: 0.7906550168991089, Val precision: 0.7932148575782776, Val recall: 0.7906550168991089\n",
      "\n",
      "Val loss: 0.5097625857591629, Val f1: 0.7837559580802917, \n",
      "Val accuracy: 0.7847734093666077, Val precision: 0.7830519676208496, Val recall: 0.7847734093666077\n",
      "\n",
      "Val loss: 0.505942751222582, Val f1: 0.7812467217445374, \n",
      "Val accuracy: 0.782576858997345, Val precision: 0.7801960110664368, Val recall: 0.782576858997345\n",
      "\n",
      "Val loss: 0.5049341140048844, Val f1: 0.7774916291236877, \n",
      "Val accuracy: 0.7782665491104126, Val precision: 0.7770082354545593, Val recall: 0.7782665491104126\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0893837213516235, Val f1: 1.4268732070922852, \n",
      "Val accuracy: 1.4053714275360107, Val precision: 1.4503026008605957, Val recall: 1.4053714275360107\n",
      "\n",
      "Val loss: 0.7248878280321757, Val f1: 0.9569306373596191, \n",
      "Val accuracy: 0.9492905139923096, Val precision: 0.9652280807495117, Val recall: 0.9492905139923096\n",
      "\n",
      "Val loss: 0.6548666834831238, Val f1: 0.8584998846054077, \n",
      "Val accuracy: 0.8591992259025574, Val precision: 0.8584067225456238, Val recall: 0.8591992259025574\n",
      "\n",
      "Val loss: 0.6265832952090672, Val f1: 0.8191760182380676, \n",
      "Val accuracy: 0.8185219764709473, Val precision: 0.8202852606773376, Val recall: 0.8185219764709473\n",
      "\n",
      "Val loss: 0.6124130023850335, Val f1: 0.7936994433403015, \n",
      "Val accuracy: 0.7937463521957397, Val precision: 0.7940215468406677, Val recall: 0.7937463521957397\n",
      "\n",
      "\n",
      "starting Epoch 18\n",
      "Training...\n",
      "Train loss: 0.5272649172693491\n",
      "Train loss: 0.5114592458262588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5066952258348465\n",
      "Train loss: 0.5013955835975817\n",
      "Train loss: 0.5000615425053097\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5213297586888075, Val f1: 0.8231984972953796, \n",
      "Val accuracy: 0.8239181041717529, Val precision: 0.8229566216468811, Val recall: 0.8239181041717529\n",
      "\n",
      "Val loss: 0.5054884074312268, Val f1: 0.7989593148231506, \n",
      "Val accuracy: 0.8002527952194214, Val precision: 0.7980203628540039, Val recall: 0.8002527952194214\n",
      "\n",
      "Val loss: 0.5009949862957, Val f1: 0.7888731956481934, \n",
      "Val accuracy: 0.7924644947052002, Val precision: 0.7856183648109436, Val recall: 0.7924644947052002\n",
      "\n",
      "Val loss: 0.4989710432379993, Val f1: 0.7848669290542603, \n",
      "Val accuracy: 0.7873162627220154, Val precision: 0.7827048897743225, Val recall: 0.7873162627220154\n",
      "\n",
      "Val loss: 0.49721906050330117, Val f1: 0.7831443548202515, \n",
      "Val accuracy: 0.7867869138717651, Val precision: 0.7798193693161011, Val recall: 0.7867869138717651\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0814744234085083, Val f1: 1.4307876825332642, \n",
      "Val accuracy: 1.4188511371612549, Val precision: 1.4439328908920288, Val recall: 1.4188511371612549\n",
      "\n",
      "Val loss: 0.720190187295278, Val f1: 0.9569811820983887, \n",
      "Val accuracy: 0.9525258541107178, Val precision: 0.9618718028068542, Val recall: 0.9525258541107178\n",
      "\n",
      "Val loss: 0.6512490749359131, Val f1: 0.8557203412055969, \n",
      "Val accuracy: 0.8595339059829712, Val precision: 0.852458655834198, Val recall: 0.8595339059829712\n",
      "\n",
      "Val loss: 0.6226904562541417, Val f1: 0.818021297454834, \n",
      "Val accuracy: 0.8203532099723816, Val precision: 0.8160883784294128, Val recall: 0.8203532099723816\n",
      "\n",
      "Val loss: 0.6089721918106079, Val f1: 0.7938247919082642, \n",
      "Val accuracy: 0.7962369918823242, Val precision: 0.7917505502700806, Val recall: 0.7962369918823242\n",
      "\n",
      "\n",
      "starting Epoch 19\n",
      "Training...\n",
      "Train loss: 0.5242204032838345\n",
      "Train loss: 0.5029114999554374\n",
      "Train loss: 0.4981778734922409\n",
      "Train loss: 0.49637991456843134\n",
      "Train loss: 0.4934105777314731\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5099997352808714, Val f1: 0.8259238004684448, \n",
      "Val accuracy: 0.8093600869178772, Val precision: 0.8435247540473938, Val recall: 0.8093600869178772\n",
      "\n",
      "Val loss: 0.4960506296519077, Val f1: 0.7984480857849121, \n",
      "Val accuracy: 0.783954918384552, Val precision: 0.8138083815574646, Val recall: 0.783954918384552\n",
      "\n",
      "Val loss: 0.49200029134750367, Val f1: 0.7891194224357605, \n",
      "Val accuracy: 0.7763462662696838, Val precision: 0.8026880025863647, Val recall: 0.7763462662696838\n",
      "\n",
      "Val loss: 0.48856382583504293, Val f1: 0.786551833152771, \n",
      "Val accuracy: 0.7737248539924622, Val precision: 0.8002002239227295, Val recall: 0.7737248539924622\n",
      "\n",
      "Val loss: 0.4860141585980143, Val f1: 0.7848363518714905, \n",
      "Val accuracy: 0.7718908190727234, Val precision: 0.7986054420471191, Val recall: 0.7718908190727234\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0731052160263062, Val f1: 1.4269635677337646, \n",
      "Val accuracy: 1.383809208869934, Val precision: 1.4740381240844727, Val recall: 1.383809208869934\n",
      "\n",
      "Val loss: 0.7149683634440104, Val f1: 0.9566351771354675, \n",
      "Val accuracy: 0.9319090843200684, Val precision: 0.9831430912017822, Val recall: 0.9319090843200684\n",
      "\n",
      "Val loss: 0.6452970504760742, Val f1: 0.8573890924453735, \n",
      "Val accuracy: 0.8435667753219604, Val precision: 0.8723279237747192, Val recall: 0.8435667753219604\n",
      "\n",
      "Val loss: 0.6175150445529393, Val f1: 0.8183771371841431, \n",
      "Val accuracy: 0.8038796186447144, Val precision: 0.8338996171951294, Val recall: 0.8038796186447144\n",
      "\n",
      "Val loss: 0.6037838326560127, Val f1: 0.7948403358459473, \n",
      "Val accuracy: 0.781821072101593, Val precision: 0.8087132573127747, Val recall: 0.781821072101593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "f1s = []\n",
    "f1s_eval = []\n",
    "accuracies = []\n",
    "accuracies_eval = []\n",
    "precisions = []\n",
    "precisions_eval = []\n",
    "recalls = []\n",
    "recalls_eval = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    print('Training...')\n",
    "    epoch_loss = train(model3, train_iterator, optimizer3, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "    print('\\nEvaluating on train...')\n",
    "    f1_on_train, accuracy_on_train, precision_on_train, recall_on_train,_ = evaluate(model3, train_iterator, criterion)\n",
    "    f1s.append(f1_on_train)\n",
    "    accuracies.append(accuracy_on_train)\n",
    "    precisions.append(precision_on_train)\n",
    "    recalls.append(recall_on_train)\n",
    "    print('\\nEvaluating on test...')\n",
    "    f1_on_test, accuracy_on_test, precision_on_test, recall_on_test, epoch_loss_on_test = evaluate(model3, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)\n",
    "    f1s_eval.append(f1_on_test)\n",
    "    accuracies_eval.append(accuracy_on_test)\n",
    "    precisions_eval.append(precision_on_test)\n",
    "    recalls_eval.append(recall_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6987037177790295, 0.6851330426606265, 0.6731990975412455, 0.6595241921869192, 0.6447184925729578, 0.6294144872914661, 0.6151657239957289, 0.6029240908947858, 0.5905862504785712, 0.5786392383954742, 0.5673167461698706, 0.5564839839935303, 0.5470268699255857, 0.5376644615422596, 0.5288660079240799, 0.5184444961222735, 0.5110819227993488, 0.5018269815905527, 0.4947109215638854, 0.4876943257721988] \n",
      "\n",
      " [0.6871046364307404, 0.676053810119629, 0.6636094450950623, 0.6487332463264466, 0.6375169813632965, 0.6256202757358551, 0.6160922229290009, 0.6079043209552765, 0.5984973669052124, 0.5935553669929504, 0.5852738678455353, 0.5783376693725586, 0.5730078876018524, 0.5675057530403137, 0.5638369977474212, 0.5585294842720032, 0.5543286919593811, 0.5511717021465301, 0.5480749726295471, 0.5434054493904114]\n"
     ]
    }
   ],
   "source": [
    "print(losses, '\\n\\n', losses_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, уменьшение размера эмбеддинга помогло избежать переобучения. Понятно, что losses у обучающей и тестовой выборки по-любому будут разными. Однако в данном случае, нет такого сильного различия, как у первых 2 моделей. На 20 эпохе loss обучающей выборки примерно 0.499, а тестовой - примерно 0.54. Поэтому можно сказать, что качество модели можно улучшить, работая с гиперпараметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказания \n",
    "\n",
    "Попытаемся по лучшей из имеющихся моделей сделать предсказания на тестовой выборке и посмотрим на false positive и false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, iterator):\n",
    "    model.eval()\n",
    "    fp = []\n",
    "    fn = []\n",
    "    tp = [] \n",
    "    tn = []\n",
    "    with torch.no_grad():\n",
    "        for i, (texts, ys) in enumerate(iterator):   \n",
    "            preds = model(texts)  # делаем предсказания на тесте \n",
    "            for pred, gold, text in zip(preds, ys, texts):\n",
    "                text = ' '.join([id2word[int(word)] for word in text if word !=0])\n",
    "                if round(pred.item()) > gold:\n",
    "                    fp.append(text)\n",
    "                elif round(pred.item()) < gold:\n",
    "                    fn.append(text)\n",
    "                elif round(pred.item()) == gold == 1:\n",
    "                    tp.append(text)\n",
    "                elif round(pred.item()) == gold == 0:\n",
    "                    tn.append(text)\n",
    "    return fp, fn, tp, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: \n",
      " ['5559116951342 на ребус и', 'rt и не не бумажки с меня на спину одноклассникам d', 'это анна то есть она тип но уже редко', 'хах если в следующий раз будет такой тебе все возможно', 'ван — ути знать кто бы это', 'космос 10 до дома скучаю по всем пишите звоните отвечу по возможности всем', 'прочитав этот статус вы лето на 5 секунд', 'hell__silence в лс напишу только насчёт др не забыть бы', 'сегодня я села на автобус и поняла что совсем не знаю города d', 'katerinanews хотя я в его возрасте не был от старшеклассников такое своего рода', 'у вас замечательные ночи', 'rt tukvasociopat коммунальные службы киева отлично работают без участия а.попова євромайдан http://t.co/vivqjkz6hv', 'rt по н.в это пипец ааааааааааа лучшее резюме из тех что я виде http://t.c…', 'я тут есть смотри видосы', 'ооооо спасибо большое так приятно ты первый 3 люблю', 'если бы я записывала все свои и косяки в книгу например то она уже была бы вот такой d', 'rt happybirthdaytrecool мужику стукнул год мама все нормально d', 'rt kate_clapp новое видео d ретвит http://t.co/vxt6clfpdd', 'вспомнила как на пляже в баре в котором я проводила весь аркаша дал мне это со словами кушай лялька', 'вы никогда не пробовали комара'] \n",
      "\n",
      "\n",
      "True negative: \n",
      " ['ленты всю она и чистые', 'просто дико хочется креветок а зарплаты пока не видно', 'то есть не увидимся на блин', 'шумахер получил очень травму головы на лыжах и теперь при смерти ирония судьбы блин life', 'хочу отдыха уже что-то я устала нереально от всего', 'хочется взять его и но нет', 'тоже и ита все дни', 'там запись на шесть', 'rt бля первая геометрия', 'ifuckingunicorn жизненно бля пиздец просто сука', 'rt domanep то не ловкое чувство когда у твоей подруги появляется парень а ты как будто бывший парень у которого увели ее', 'сегодня твой день сказать даже нечего да и не ведь больше нет', 'да уже а ссора за блять', 'mariko_olesya бы говорил', 'ааа так не хочу не', 'совсем не айс и времени мало', 'неужели у всех этих людей и правда мегафон о_о', 'че делать я не могу больше это слушать пока буду надеется что она всего лишь хочет в туалет и таким образом просит хозяина', 'про меня', 'из-за какой-то мелочи же достало это'] \n",
      "\n",
      "\n",
      "False positive: \n",
      " ['иди ты', 'да что кино даже настолки лучше наших такое ощущение что их вообще не перед выходом', 'энэ маань ийн 3 4 өгөөч минь дуу нь', 'я прикола не понял вроде читаю она не удалилась случаем', 'аха прочитала как заебал', 'rt bad_tomat олень какашками', 'кстати из нас тоже не получится янык так не умеет', 'говорят что завтра будет 33 кто там хотел зимы получайте мля', 'rt говорит мне учебника по', 'nektonekto женщины перед мужчиной и своей какая тут демократия', 'что тебя обычно расстраивает — отсутствие вкусняшек в доме', 'так светлана уютного и вам с рб не вас там аж с лета не были', 'rt крепкий орешек вообще впервые с трудом техника', 'пока вообще не радует', 'плоховато себя чувствую да еще и в столовой дежурю', 'я люблю дарить подарки мне нравится их радость искренняя улыбка это же я не умею их дарить', 'всё в', 'в четыре вены елки ебаные', 'ходим по', 'зенит начал игру надеюсь все таки хотя шансов мало'] \n",
      "\n",
      "\n",
      "False negative: \n",
      " ['gataguk espera_espera эти нет траст ми', 'ну что ж маргарита m_simonyan мы наконец новости о нового нтв все ж уже готово', 'чувак совести проходит спустя', 'rt я как иду в гости к', 'утром здесь делать нечего внутри почти всё закрыто', 'в этом вообще поступления в университет', 'zaxarborisych так он вроде нечаянно на фоне пьянки отстань от дедушки', 'и ни чем а с кем', 'сейчас поняла,что я кажись в ок', 'завтра будет насыщенный и даже трудный день не много волнуюсь спать осталось так что снов', 'rt euphoriaxd ладно,я пошла за и с у меня того что кто кто хочет от меня', 'evanescence my всегда действует', 'это радует а то тоже скучает по', 'webelarus дел по горло но все какие то', 'сегодня утром меня дворник таджик встретил були я до сих пор отойти не могу', 'rt задолбал этот майдан и устал отвечать на уже и', 'доброе утро ххх в полдня последнего выходного грусть печаль тоска', 'просто кажется не', 'omon_moscow vrsoloviev в профиль так ваня ургант после съемки очередного урганта прощения за стёб у человека горе', 'опять накрыло пережить бы еще и этот день без'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fp, fn, tp, tn = predict(model3, val_iterator)\n",
    "\n",
    "print('True positive: \\n', tp[:20], '\\n\\n')\n",
    "print('True negative: \\n', tn[:20], '\\n\\n')\n",
    "print('False positive: \\n', fp[:20], '\\n\\n')\n",
    "print('False negative: \\n', fn[:20], '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Немножко анализа \n",
    "Наверное, это довольно очевидный факт, но твиты могут определяться моделью как негативные (ошибочно определяться), если в них есть частица \"не\". Видимо, \"не\" - является одним из основных признаков негативного твита, хотя в реальности \"не\" может употребляться где угодно.\n",
    "\n",
    "Честно говоря, с false positive труднее. Возможно, влиет появление слов с положительной оценкой, таких как: \"люблю\", \"радость\", \"классно\" и тд. Или такие штуки, которые выражают какую-то положительную реакцию... типа \"ахахахаха\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектура II\n",
    "\n",
    "Каждый текст препроцессим, склеиваем все тексты в одну строку, а дальше делаем словарь из уникальных символов и словарь уникальных символов, встретившихся больше 5 раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего уникальных символов: 295\n"
     ]
    }
   ],
   "source": [
    "vocab_sym = Counter()\n",
    "tweets_data_for_sym = tweets_data.text.apply(lambda x: ' '.join(preprocess(x)))\n",
    "for symbol in tweets_data_for_sym:\n",
    "    vocab_sym.update(list(symbol))\n",
    "print('всего уникальных символов:', len(vocab_sym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "уникальных символов, втретившихся больше 5 раз: 141\n"
     ]
    }
   ],
   "source": [
    "filtered_vocab_sym = set()\n",
    "\n",
    "for symbol in vocab_sym:\n",
    "    if vocab_sym[symbol] > 5:\n",
    "        filtered_vocab_sym.add(symbol)\n",
    "print('уникальных символов, втретившихся больше 5 раз:', len(filtered_vocab_sym))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь symbol2id и обратный ему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем словарь с индексами symbol2id, для спецсимвола паддинга дефолтный индекс - 0\n",
    "symbol2id = {'PAD':0}\n",
    "\n",
    "for symbol in filtered_vocab_sym:\n",
    "    symbol2id[symbol] = len(symbol2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обратный словарь для того, чтобы раскодировать последовательность\n",
    "id2symbol = {i:symbol for symbol, i in symbol2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "print(len(symbol2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Приводим данные в тот вид, в котором их можно будет подать в модель\n",
    "Создаем класс, наследующий у Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data['sym_texts'] = tweets_data_for_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences = train_test_split(tweets_data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sym_Word_TweetsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, word2id, symbol2id, DEVICE):\n",
    "        self.dataset = dataset['sym_texts'].values\n",
    "        self.word2id = word2id\n",
    "        self.symbol2id = symbol2id\n",
    "        self.length = dataset.shape[0]\n",
    "        self.target = dataset['tone'].values\n",
    "        self.device = DEVICE\n",
    "\n",
    "    def __len__(self): #это обязательный метод, он должен уметь считать длину датасета\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index): #еще один обязательный метод. По индексу возвращает элемент выборки\n",
    "        symbols = list(self.dataset[index])\n",
    "        sym_ids = torch.LongTensor([self.symbol2id[symbol] for symbol in symbols if symbol in self.symbol2id])\n",
    "        \n",
    "        tokens = self.preprocess(self.dataset[index]) # токенизируем\n",
    "        word_ids = torch.LongTensor([self.word2id[token] for token in tokens if token in self.word2id])\n",
    "        y = [self.target[index]]\n",
    "        return sym_ids, word_ids, y\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        tokens = text.lower().split()\n",
    "        tokens = [token.strip(punctuation) for token in tokens]\n",
    "        tokens = [token for token in tokens if token]\n",
    "        return tokens\n",
    "\n",
    "    def collate_fn(self, batch): #этот метод можно реализовывать и отдельно,\n",
    "    # он понадобится для DataLoader во время итерации по батчам\n",
    "        sym_ids, word_ids, y = list(zip(*batch))\n",
    "        padded_sym_ids = pad_sequence(sym_ids, batch_first=True).to(self.device)\n",
    "        padded_word_ids = pad_sequence(word_ids, batch_first=True).to(self.device)\n",
    "        #мы хотим применять BCELoss, он будет брать на вход predicted размера batch_size x 1 (так как для каждого семпла модель будет отдавать одно число), target размера batch_size x 1\n",
    "        y = torch.Tensor(y).to(self.device) # tuple ([1], [0], [1])  -> Tensor [[1.], [0.], [1.]] \n",
    "        return padded_sym_ids, padded_word_ids, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучающей и для тестовой выборки создаем экземпляры Dataset (точнее того, класса, который наследует от него) и DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Sym_Word_TweetsDataset(train_sentences, word2id, symbol2id, DEVICE)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_iterator = DataLoader(train_dataset, collate_fn = train_dataset.collate_fn, sampler=train_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Sym_Word_TweetsDataset(val_sentences, word2id, symbol2id, DEVICE)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_iterator = DataLoader(val_dataset, collate_fn = val_dataset.collate_fn, sampler=val_sampler, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем саму модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sym_Word_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, sym_vocab_size, word_vocab_size, sym_embedding_dim, word_embedding_dim):\n",
    "        \n",
    "        super().__init__()          \n",
    "        # указываем в атрибутах класса, какие слои и активации нам понадобятся\n",
    "        self.embedding_word = nn.Embedding(word_vocab_size, word_embedding_dim)\n",
    "        self.linear_words = nn.Linear(in_features=word_embedding_dim, out_features=100)\n",
    "        \n",
    "        self.embedding_sym = nn.Embedding(sym_vocab_size, sym_embedding_dim)\n",
    "        self.bigrams = nn.Conv1d(in_channels=sym_embedding_dim, out_channels=100, kernel_size=2, padding='same')\n",
    "        self.trigrams = nn.Conv1d(in_channels=sym_embedding_dim, out_channels=80, kernel_size=3, padding='same')\n",
    "        self.linear_sym = nn.Linear(in_features=180, out_features=100)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden = nn.Linear(in_features=200, out_features=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, sym_texts, word_texts): #необходимый метод,  в нем указываем, как именно связываются слои/активации между собой\n",
    "        embedded_words = self.embedding_word(word_texts)   \n",
    "        mean_embedded_words = torch.mean(embedded_words, dim=1)\n",
    "        vec_words = self.dropout(self.relu(self.linear_words(mean_embedded_words)))\n",
    "        \n",
    "        embedded_sym = self.embedding_sym(sym_texts)\n",
    "        embedded_sym = embedded_sym.transpose(1,2)\n",
    "        feature_map_bigrams = self.dropout(self.relu(self.bigrams(embedded_sym)))\n",
    "        feature_map_trigrams = self.dropout(self.relu(self.trigrams(embedded_sym)))\n",
    "        pooling_bi = feature_map_bigrams.max(2)[0]\n",
    "        pooling_tri = feature_map_trigrams.max(2)[0]\n",
    "        concat_sym = torch.cat((pooling_bi, pooling_tri), 1)\n",
    "        vec_sym = self.linear_sym(concat_sym)\n",
    "        \n",
    "        concat = torch.cat((vec_words, vec_sym), 1)\n",
    "        logits = self.hidden(concat) \n",
    "        logits = self.out(logits)      \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модифицируем функции обучения и эвалюации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_II(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0 # для подсчета среднего лосса на всех батчах\n",
    "\n",
    "    model.train()  # ставим модель в обучение, явно указываем, что сейчас надо будет хранить градиенты у всех весов\n",
    "\n",
    "    for i, (sym_texts, words_texts, ys) in enumerate(iterator): #итерируемся по батчам\n",
    "        optimizer.zero_grad()  #обнуляем градиенты\n",
    "        preds = model(sym_texts, words_texts)  #прогоняем данные через модель\n",
    "        loss = criterion(preds, ys) #считаем значение функции потерь  \n",
    "        loss.backward() #считаем градиенты  \n",
    "        optimizer.step() #обновляем веса \n",
    "        epoch_loss += loss.item() #сохраняем значение функции потерь\n",
    "        if not (i + 1) % int(len(iterator)/5):\n",
    "            print(f'Train loss: {epoch_loss/i}')      \n",
    "    return  epoch_loss / len(iterator) # возвращаем среднее значение лосса по всей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_II(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_metric_f1 = 0\n",
    "    epoch_metric_precision = 0\n",
    "    epoch_metric_recall = 0\n",
    "    epoch_metric_accuracy = 0\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for i, (sym_texts, words_texts, ys) in enumerate(iterator):   \n",
    "            preds = model(sym_texts, words_texts)  # делаем предсказания на тесте\n",
    "            loss = criterion(preds, ys)   # считаем значения функции ошибки для статистики  \n",
    "            epoch_loss += loss.item()\n",
    "            batch_metric_f1 = f1(preds.round().long(), ys.long(), ignore_index=0)\n",
    "            epoch_metric_f1 += batch_metric_f1\n",
    "            batch_metric_precision = precision(preds.round().long(), ys.long(), ignore_index=0)\n",
    "            epoch_metric_precision += batch_metric_precision\n",
    "            batch_metric_recall = recall(preds.round().long(), ys.long(), ignore_index=0)\n",
    "            epoch_metric_recall += batch_metric_recall\n",
    "            batch_metric_accuracy = accuracy(preds.round().long(), ys.long(), ignore_index=0)\n",
    "            epoch_metric_accuracy += batch_metric_accuracy\n",
    "\n",
    "            if not (i + 1) % int(len(iterator)/5):\n",
    "                print(f'Val loss: {epoch_loss/i}, Val f1: {epoch_metric_f1/i}, \\nVal accuracy: {epoch_metric_accuracy/i}, Val precision: {epoch_metric_precision/i}, Val recall: {epoch_metric_recall/i}\\n')\n",
    "        \n",
    "    return epoch_metric_f1 / len(iterator), epoch_metric_accuracy / len(iterator), epoch_metric_precision / len(iterator), epoch_metric_recall / len(iterator), epoch_loss / len(iterator) # возвращаем среднее значение по всей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем экземпляр модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_II = Sym_Word_CNN(len(symbol2id), len(word2id), 5, 100)\n",
    "optimizer_II = optim.Adam(model_II.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model_II = model_II.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение и эвалюацию модели (на 10 эпохах)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting Epoch 0\n",
      "Training...\n",
      "Train loss: 0.7853158675134182\n",
      "Train loss: 0.7363376490997545\n",
      "Train loss: 0.7164020836353302\n",
      "Train loss: 0.7034204646722594\n",
      "Train loss: 0.6944403449694315\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.7005071006715298, Val f1: 0.5977252125740051, \n",
      "Val accuracy: 0.5158455967903137, Val precision: 0.7117050886154175, Val recall: 0.5158455967903137\n",
      "\n",
      "Val loss: 0.6788859547990741, Val f1: 0.574823796749115, \n",
      "Val accuracy: 0.49596261978149414, Val precision: 0.6849884986877441, Val recall: 0.49596261978149414\n",
      "\n",
      "Val loss: 0.6717440032958985, Val f1: 0.5672608017921448, \n",
      "Val accuracy: 0.4882849454879761, Val precision: 0.6779254078865051, Val recall: 0.4882849454879761\n",
      "\n",
      "Val loss: 0.6688944368220088, Val f1: 0.5629779696464539, \n",
      "Val accuracy: 0.4850606918334961, Val precision: 0.6718699336051941, Val recall: 0.4850606918334961\n",
      "\n",
      "Val loss: 0.6672593241646176, Val f1: 0.5601361989974976, \n",
      "Val accuracy: 0.48295673727989197, Val precision: 0.6677235960960388, Val recall: 0.48295673727989197\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.327286958694458, Val f1: 1.1101369857788086, \n",
      "Val accuracy: 0.9785464406013489, Val precision: 1.2832684516906738, Val recall: 0.9785464406013489\n",
      "\n",
      "Val loss: 0.8846137921015421, Val f1: 0.7245857119560242, \n",
      "Val accuracy: 0.6316565275192261, Val precision: 0.8512623310089111, Val recall: 0.6316565275192261\n",
      "\n",
      "Val loss: 0.7959357261657715, Val f1: 0.6515595316886902, \n",
      "Val accuracy: 0.5613729357719421, Val precision: 0.7780237197875977, Val recall: 0.5613729357719421\n",
      "\n",
      "Val loss: 0.7564108712332589, Val f1: 0.6236644983291626, \n",
      "Val accuracy: 0.5364267230033875, Val precision: 0.7460702657699585, Val recall: 0.5364267230033875\n",
      "\n",
      "Val loss: 0.7349619468053182, Val f1: 0.6055795550346375, \n",
      "Val accuracy: 0.5229372978210449, Val precision: 0.7204267978668213, Val recall: 0.5229372978210449\n",
      "\n",
      "\n",
      "starting Epoch 1\n",
      "Training...\n",
      "Train loss: 0.6856976300477982\n",
      "Train loss: 0.6654840635530876\n",
      "Train loss: 0.6560127055644989\n",
      "Train loss: 0.6485600311364701\n",
      "Train loss: 0.6433256020148596\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6643876060843468, Val f1: 0.6294195055961609, \n",
      "Val accuracy: 0.5198469161987305, Val precision: 0.7990437150001526, Val recall: 0.5198469161987305\n",
      "\n",
      "Val loss: 0.642798201604323, Val f1: 0.6105881333351135, \n",
      "Val accuracy: 0.504220724105835, Val precision: 0.7750305533409119, Val recall: 0.504220724105835\n",
      "\n",
      "Val loss: 0.6357862794399262, Val f1: 0.6044297218322754, \n",
      "Val accuracy: 0.49927857518196106, Val precision: 0.7669717669487, Val recall: 0.49927857518196106\n",
      "\n",
      "Val loss: 0.6314914751408706, Val f1: 0.6049000024795532, \n",
      "Val accuracy: 0.5013993382453918, Val precision: 0.7634665369987488, Val recall: 0.5013993382453918\n",
      "\n",
      "Val loss: 0.6294559978303456, Val f1: 0.6031073331832886, \n",
      "Val accuracy: 0.4990595877170563, Val precision: 0.7631556391716003, Val recall: 0.4990595877170563\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.2558758854866028, Val f1: 1.1903671026229858, \n",
      "Val accuracy: 0.998009204864502, Val precision: 1.474637746810913, Val recall: 0.998009204864502\n",
      "\n",
      "Val loss: 0.8395033081372579, Val f1: 0.7727028727531433, \n",
      "Val accuracy: 0.6416501402854919, Val precision: 0.9714420437812805, Val recall: 0.6416501402854919\n",
      "\n",
      "Val loss: 0.7563150882720947, Val f1: 0.6909869313240051, \n",
      "Val accuracy: 0.5686950087547302, Val precision: 0.8813924789428711, Val recall: 0.5686950087547302\n",
      "\n",
      "Val loss: 0.7188428214618138, Val f1: 0.6602956652641296, \n",
      "Val accuracy: 0.5440477132797241, Val precision: 0.8405801057815552, Val recall: 0.5440477132797241\n",
      "\n",
      "Val loss: 0.697835836145613, Val f1: 0.6430163979530334, \n",
      "Val accuracy: 0.5310025811195374, Val precision: 0.8157408833503723, Val recall: 0.5310025811195374\n",
      "\n",
      "\n",
      "starting Epoch 2\n",
      "Training...\n",
      "Train loss: 0.6401703245937824\n",
      "Train loss: 0.6189891352797999\n",
      "Train loss: 0.6088874804973602\n",
      "Train loss: 0.6026078382534767\n",
      "Train loss: 0.5951409197988964\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.6108350902795792, Val f1: 0.6945770978927612, \n",
      "Val accuracy: 0.5848202705383301, Val precision: 0.8559940457344055, Val recall: 0.5848202705383301\n",
      "\n",
      "Val loss: 0.5917679252046527, Val f1: 0.6766055822372437, \n",
      "Val accuracy: 0.5699754953384399, Val precision: 0.8332103490829468, Val recall: 0.5699754953384399\n",
      "\n",
      "Val loss: 0.5856603240966797, Val f1: 0.6672679781913757, \n",
      "Val accuracy: 0.5612607002258301, Val precision: 0.8234811425209045, Val recall: 0.5612607002258301\n",
      "\n",
      "Val loss: 0.5816212358759411, Val f1: 0.6658164858818054, \n",
      "Val accuracy: 0.5605326294898987, Val precision: 0.8206859827041626, Val recall: 0.5605326294898987\n",
      "\n",
      "Val loss: 0.5790631948482423, Val f1: 0.664435863494873, \n",
      "Val accuracy: 0.5592337846755981, Val precision: 0.8192620873451233, Val recall: 0.5592337846755981\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.1682799458503723, Val f1: 1.2821931838989258, \n",
      "Val accuracy: 1.0873676538467407, Val precision: 1.5620827674865723, Val recall: 1.0873676538467407\n",
      "\n",
      "Val loss: 0.7829361955324808, Val f1: 0.8455871939659119, \n",
      "Val accuracy: 0.7182003855705261, Val precision: 1.0279581546783447, Val recall: 0.7182003855705261\n",
      "\n",
      "Val loss: 0.7072802066802979, Val f1: 0.7535454630851746, \n",
      "Val accuracy: 0.6351334452629089, Val precision: 0.9267585873603821, Val recall: 0.6351334452629089\n",
      "\n",
      "Val loss: 0.6734481198447091, Val f1: 0.7161555290222168, \n",
      "Val accuracy: 0.601744532585144, Val precision: 0.8850377202033997, Val recall: 0.601744532585144\n",
      "\n",
      "Val loss: 0.6529624727037218, Val f1: 0.6986117959022522, \n",
      "Val accuracy: 0.5871854424476624, Val precision: 0.8628173470497131, Val recall: 0.5871854424476624\n",
      "\n",
      "\n",
      "starting Epoch 3\n",
      "Training...\n",
      "Train loss: 0.5862977504730225\n",
      "Train loss: 0.5670793164860118\n",
      "Train loss: 0.5587098348140717\n",
      "Train loss: 0.5522392463328233\n",
      "Train loss: 0.546487440665563\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5465015470981598, Val f1: 0.7732571959495544, \n",
      "Val accuracy: 0.7013794183731079, Val precision: 0.861939013004303, Val recall: 0.7013794183731079\n",
      "\n",
      "Val loss: 0.531663634560325, Val f1: 0.7494070529937744, \n",
      "Val accuracy: 0.6794421672821045, Val precision: 0.8358933329582214, Val recall: 0.6794421672821045\n",
      "\n",
      "Val loss: 0.5266351664066314, Val f1: 0.7434020042419434, \n",
      "Val accuracy: 0.6728112101554871, Val precision: 0.8310969471931458, Val recall: 0.6728112101554871\n",
      "\n",
      "Val loss: 0.5248491577248076, Val f1: 0.7398463487625122, \n",
      "Val accuracy: 0.6690017580986023, Val precision: 0.8280749320983887, Val recall: 0.6690017580986023\n",
      "\n",
      "Val loss: 0.5234885077391352, Val f1: 0.7385758757591248, \n",
      "Val accuracy: 0.6679084300994873, Val precision: 0.8265554308891296, Val recall: 0.6679084300994873\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0818764567375183, Val f1: 1.413438081741333, \n",
      "Val accuracy: 1.289362907409668, Val precision: 1.5643486976623535, Val recall: 1.289362907409668\n",
      "\n",
      "Val loss: 0.7254305680592855, Val f1: 0.9353271126747131, \n",
      "Val accuracy: 0.8578709959983826, Val precision: 1.0284671783447266, Val recall: 0.8578709959983826\n",
      "\n",
      "Val loss: 0.6561827421188354, Val f1: 0.8332325220108032, \n",
      "Val accuracy: 0.758051335811615, Val precision: 0.9256660342216492, Val recall: 0.758051335811615\n",
      "\n",
      "Val loss: 0.6263289451599121, Val f1: 0.7908679246902466, \n",
      "Val accuracy: 0.7179052233695984, Val precision: 0.8809701800346375, Val recall: 0.7179052233695984\n",
      "\n",
      "Val loss: 0.6071988807784187, Val f1: 0.7697479724884033, \n",
      "Val accuracy: 0.698138415813446, Val precision: 0.8582474589347839, Val recall: 0.698138415813446\n",
      "\n",
      "\n",
      "starting Epoch 4\n",
      "Training...\n",
      "Train loss: 0.5442882850766182\n",
      "Train loss: 0.5263059825608225\n",
      "Train loss: 0.5158516144752503\n",
      "Train loss: 0.5085794107237859\n",
      "Train loss: 0.5033290421678907\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.5027511194348335, Val f1: 0.8104302287101746, \n",
      "Val accuracy: 0.742800772190094, Val precision: 0.8919445872306824, Val recall: 0.742800772190094\n",
      "\n",
      "Val loss: 0.48866852034221997, Val f1: 0.7853581309318542, \n",
      "Val accuracy: 0.7175770401954651, Val precision: 0.8677301406860352, Val recall: 0.7175770401954651\n",
      "\n",
      "Val loss: 0.48515432357788085, Val f1: 0.7748516798019409, \n",
      "Val accuracy: 0.7079173922538757, Val precision: 0.8562637567520142, Val recall: 0.7079173922538757\n",
      "\n",
      "Val loss: 0.48440184922360663, Val f1: 0.7711161971092224, \n",
      "Val accuracy: 0.7043819427490234, Val precision: 0.852327287197113, Val recall: 0.7043819427490234\n",
      "\n",
      "Val loss: 0.4832687626282374, Val f1: 0.768722653388977, \n",
      "Val accuracy: 0.702477753162384, Val precision: 0.8492525219917297, Val recall: 0.702477753162384\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test...\n",
      "Val loss: 1.0324949026107788, Val f1: 1.4444901943206787, \n",
      "Val accuracy: 1.3340647220611572, Val precision: 1.5754756927490234, Val recall: 1.3340647220611572\n",
      "\n",
      "Val loss: 0.6912742654482523, Val f1: 0.9540538787841797, \n",
      "Val accuracy: 0.8865298628807068, Val precision: 1.0331329107284546, Val recall: 0.8865298628807068\n",
      "\n",
      "Val loss: 0.6255768775939942, Val f1: 0.8552337884902954, \n",
      "Val accuracy: 0.7898663282394409, Val precision: 0.9329781532287598, Val recall: 0.7898663282394409\n",
      "\n",
      "Val loss: 0.598441583769662, Val f1: 0.81400066614151, \n",
      "Val accuracy: 0.749912679195404, Val precision: 0.8905627131462097, Val recall: 0.749912679195404\n",
      "\n",
      "Val loss: 0.5799742672178481, Val f1: 0.7922370433807373, \n",
      "Val accuracy: 0.7288650870323181, Val precision: 0.8680815696716309, Val recall: 0.7288650870323181\n",
      "\n",
      "\n",
      "starting Epoch 5\n",
      "Training...\n",
      "Train loss: 0.49773837625980377\n",
      "Train loss: 0.48586268858476117\n",
      "Train loss: 0.4770907199382782\n",
      "Train loss: 0.47292525243403305\n",
      "Train loss: 0.4696323357167698\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.47000136971473694, Val f1: 0.8393364548683167, \n",
      "Val accuracy: 0.7802067995071411, Val precision: 0.908409595489502, Val recall: 0.7802067995071411\n",
      "\n",
      "Val loss: 0.4552142782644792, Val f1: 0.8119157552719116, \n",
      "Val accuracy: 0.7547556757926941, Val precision: 0.8787428140640259, Val recall: 0.7547556757926941\n",
      "\n",
      "Val loss: 0.45172938048839567, Val f1: 0.8032333850860596, \n",
      "Val accuracy: 0.7457828521728516, Val precision: 0.8707077503204346, Val recall: 0.7457828521728516\n",
      "\n",
      "Val loss: 0.44911493872528646, Val f1: 0.7987858653068542, \n",
      "Val accuracy: 0.7418665289878845, Val precision: 0.8655457496643066, Val recall: 0.7418665289878845\n",
      "\n",
      "Val loss: 0.447720338900884, Val f1: 0.7964968681335449, \n",
      "Val accuracy: 0.7408397197723389, Val precision: 0.8615654706954956, Val recall: 0.7408397197723389\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 0.995307445526123, Val f1: 1.4871070384979248, \n",
      "Val accuracy: 1.401984691619873, Val precision: 1.5832675695419312, Val recall: 1.401984691619873\n",
      "\n",
      "Val loss: 0.6667754749457041, Val f1: 0.9802484512329102, \n",
      "Val accuracy: 0.9283135533332825, Val precision: 1.0385218858718872, Val recall: 0.9283135533332825\n",
      "\n",
      "Val loss: 0.6032468855381012, Val f1: 0.8778467178344727, \n",
      "Val accuracy: 0.8265713453292847, Val precision: 0.9364058375358582, Val recall: 0.8265713453292847\n",
      "\n",
      "Val loss: 0.5776716428143638, Val f1: 0.8335614800453186, \n",
      "Val accuracy: 0.7816452980041504, Val precision: 0.8933983445167542, Val recall: 0.7816452980041504\n",
      "\n",
      "Val loss: 0.5594781405395932, Val f1: 0.8097872734069824, \n",
      "Val accuracy: 0.7580496072769165, Val precision: 0.8695641756057739, Val recall: 0.7580496072769165\n",
      "\n",
      "\n",
      "starting Epoch 6\n",
      "Training...\n",
      "Train loss: 0.4710047598928213\n",
      "Train loss: 0.4534251373825651\n",
      "Train loss: 0.447127001285553\n",
      "Train loss: 0.4419333183053714\n",
      "Train loss: 0.4405743522303445\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.454473827034235, Val f1: 0.835339367389679, \n",
      "Val accuracy: 0.7546305656433105, Val precision: 0.9357649683952332, Val recall: 0.7546305656433105\n",
      "\n",
      "Val loss: 0.4417043635339448, Val f1: 0.8090373873710632, \n",
      "Val accuracy: 0.7274640798568726, Val precision: 0.9117064476013184, Val recall: 0.7274640798568726\n",
      "\n",
      "Val loss: 0.4386182129383087, Val f1: 0.800097644329071, \n",
      "Val accuracy: 0.7190985083580017, Val precision: 0.9021878838539124, Val recall: 0.7190985083580017\n",
      "\n",
      "Val loss: 0.43612728056622974, Val f1: 0.796046793460846, \n",
      "Val accuracy: 0.7155611515045166, Val precision: 0.8974378108978271, Val recall: 0.7155611515045166\n",
      "\n",
      "Val loss: 0.43577314842314946, Val f1: 0.7933492064476013, \n",
      "Val accuracy: 0.7127467393875122, Val precision: 0.894995927810669, Val recall: 0.7127467393875122\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 0.9958091676235199, Val f1: 1.4484798908233643, \n",
      "Val accuracy: 1.3029741048812866, Val precision: 1.630577802658081, Val recall: 1.3029741048812866\n",
      "\n",
      "Val loss: 0.6670446296532949, Val f1: 0.9612548351287842, \n",
      "Val accuracy: 0.8714695572853088, Val precision: 1.071891188621521, Val recall: 0.8714695572853088\n",
      "\n",
      "Val loss: 0.6043144047260285, Val f1: 0.8633896112442017, \n",
      "Val accuracy: 0.7804499268531799, Val precision: 0.9664462208747864, Val recall: 0.7804499268531799\n",
      "\n",
      "Val loss: 0.5802581608295441, Val f1: 0.8177626729011536, \n",
      "Val accuracy: 0.7359404563903809, Val precision: 0.9205031991004944, Val recall: 0.7359404563903809\n",
      "\n",
      "Val loss: 0.5612063904603323, Val f1: 0.7960419058799744, \n",
      "Val accuracy: 0.7156974673271179, Val precision: 0.8971282243728638, Val recall: 0.7156974673271179\n",
      "\n",
      "\n",
      "starting Epoch 7\n",
      "Training...\n",
      "Train loss: 0.445153484120965\n",
      "Train loss: 0.43037262920177344\n",
      "Train loss: 0.4257913362979889\n",
      "Train loss: 0.421653441083965\n",
      "Train loss: 0.41998967670259024\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.42660428397357464, Val f1: 0.8602722883224487, \n",
      "Val accuracy: 0.7951005697250366, Val precision: 0.9378040432929993, Val recall: 0.7951005697250366\n",
      "\n",
      "Val loss: 0.41430991436495923, Val f1: 0.8329377174377441, \n",
      "Val accuracy: 0.7698855996131897, Val precision: 0.9078088402748108, Val recall: 0.7698855996131897\n",
      "\n",
      "Val loss: 0.41241403698921203, Val f1: 0.8230503797531128, \n",
      "Val accuracy: 0.7602376341819763, Val precision: 0.8977612853050232, Val recall: 0.7602376341819763\n",
      "\n",
      "Val loss: 0.4093860521245359, Val f1: 0.8204460144042969, \n",
      "Val accuracy: 0.7574074864387512, Val precision: 0.8954546451568604, Val recall: 0.7574074864387512\n",
      "\n",
      "Val loss: 0.40889184425274533, Val f1: 0.8184469938278198, \n",
      "Val accuracy: 0.7557772397994995, Val precision: 0.8929315209388733, Val recall: 0.7557772397994995\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 0.9811824858188629, Val f1: 1.4956061840057373, \n",
      "Val accuracy: 1.3961330652236938, Val precision: 1.610343098640442, Val recall: 1.3961330652236938\n",
      "\n",
      "Val loss: 0.6573703785737356, Val f1: 0.9881179928779602, \n",
      "Val accuracy: 0.9262593388557434, Val precision: 1.0589195489883423, Val recall: 0.9262593388557434\n",
      "\n",
      "Val loss: 0.5945792019367218, Val f1: 0.8840475082397461, \n",
      "Val accuracy: 0.8226202130317688, Val precision: 0.9559537768363953, Val recall: 0.8226202130317688\n",
      "\n",
      "Val loss: 0.570318592446191, Val f1: 0.8395980596542358, \n",
      "Val accuracy: 0.7781636118888855, Val precision: 0.9120837450027466, Val recall: 0.7781636118888855\n",
      "\n",
      "Val loss: 0.5510802434550391, Val f1: 0.814114511013031, \n",
      "Val accuracy: 0.7529764175415039, Val precision: 0.8865288496017456, Val recall: 0.7529764175415039\n",
      "\n",
      "\n",
      "starting Epoch 8\n",
      "Training...\n",
      "Train loss: 0.4205775763839483\n",
      "Train loss: 0.4084186111435746\n",
      "Train loss: 0.40220018088817594\n",
      "Train loss: 0.3996815890518587\n",
      "Train loss: 0.3969523282278152\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.4051610566675663, Val f1: 0.8746210932731628, \n",
      "Val accuracy: 0.8137800693511963, Val precision: 0.9456436038017273, Val recall: 0.8137800693511963\n",
      "\n",
      "Val loss: 0.39314508167180146, Val f1: 0.8483714461326599, \n",
      "Val accuracy: 0.7893238663673401, Val precision: 0.9173885583877563, Val recall: 0.7893238663673401\n",
      "\n",
      "Val loss: 0.3892514407634735, Val f1: 0.8398284912109375, \n",
      "Val accuracy: 0.7821308970451355, Val precision: 0.9071268439292908, Val recall: 0.7821308970451355\n",
      "\n",
      "Val loss: 0.3872382943309955, Val f1: 0.8356550335884094, \n",
      "Val accuracy: 0.7775834798812866, Val precision: 0.9034743309020996, Val recall: 0.7775834798812866\n",
      "\n",
      "Val loss: 0.3864272226180349, Val f1: 0.8325965404510498, \n",
      "Val accuracy: 0.7745869159698486, Val precision: 0.9003387689590454, Val recall: 0.7745869159698486\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 0.9728050231933594, Val f1: 1.497452735900879, \n",
      "Val accuracy: 1.4116746187210083, Val precision: 1.5943299531936646, Val recall: 1.4116746187210083\n",
      "\n",
      "Val loss: 0.6523724297682444, Val f1: 0.9983434677124023, \n",
      "Val accuracy: 0.945135772228241, Val precision: 1.0579439401626587, Val recall: 0.945135772228241\n",
      "\n",
      "Val loss: 0.5896761417388916, Val f1: 0.8916851282119751, \n",
      "Val accuracy: 0.838537335395813, Val precision: 0.9524314999580383, Val recall: 0.838537335395813\n",
      "\n",
      "Val loss: 0.5650449820927211, Val f1: 0.8455145955085754, \n",
      "Val accuracy: 0.7911565899848938, Val precision: 0.9083585739135742, Val recall: 0.7911565899848938\n",
      "\n",
      "Val loss: 0.5453412897057004, Val f1: 0.8186435103416443, \n",
      "Val accuracy: 0.7647342681884766, Val precision: 0.8811314702033997, Val recall: 0.7647342681884766\n",
      "\n",
      "\n",
      "starting Epoch 9\n",
      "Training...\n",
      "Train loss: 0.39661405235528946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.38611936207973596\n",
      "Train loss: 0.38230785727500916\n",
      "Train loss: 0.38120602404893333\n",
      "Train loss: 0.3812904453703335\n",
      "\n",
      "Evaluating on train...\n",
      "Val loss: 0.4007279071956873, Val f1: 0.873281717300415, \n",
      "Val accuracy: 0.7981586456298828, Val precision: 0.9644042253494263, Val recall: 0.7981586456298828\n",
      "\n",
      "Val loss: 0.3876509892218041, Val f1: 0.8478496670722961, \n",
      "Val accuracy: 0.7738270163536072, Val precision: 0.9378848671913147, Val recall: 0.7738270163536072\n",
      "\n",
      "Val loss: 0.3848141783475876, Val f1: 0.8387451171875, \n",
      "Val accuracy: 0.7663498520851135, Val precision: 0.9266040921211243, Val recall: 0.7663498520851135\n",
      "\n",
      "Val loss: 0.3828718737879796, Val f1: 0.8340103626251221, \n",
      "Val accuracy: 0.7609024047851562, Val precision: 0.9230526685714722, Val recall: 0.7609024047851562\n",
      "\n",
      "Val loss: 0.38313186913728714, Val f1: 0.8312374949455261, \n",
      "Val accuracy: 0.7580516934394836, Val precision: 0.920468270778656, Val recall: 0.7580516934394836\n",
      "\n",
      "\n",
      "Evaluating on test...\n",
      "Val loss: 0.9977782964706421, Val f1: 1.483473777770996, \n",
      "Val accuracy: 1.3631421327590942, Val precision: 1.6271402835845947, Val recall: 1.3631421327590942\n",
      "\n",
      "Val loss: 0.6675569315751394, Val f1: 0.9850379824638367, \n",
      "Val accuracy: 0.9098560810089111, Val precision: 1.073853850364685, Val recall: 0.9098560810089111\n",
      "\n",
      "Val loss: 0.6028535187244415, Val f1: 0.8793327212333679, \n",
      "Val accuracy: 0.807369589805603, Val precision: 0.9658133387565613, Val recall: 0.807369589805603\n",
      "\n",
      "Val loss: 0.5788129951272692, Val f1: 0.8339676856994629, \n",
      "Val accuracy: 0.7623224854469299, Val precision: 0.9209451079368591, Val recall: 0.7623224854469299\n",
      "\n",
      "Val loss: 0.558658136261834, Val f1: 0.8088382482528687, \n",
      "Val accuracy: 0.7374804019927979, Val precision: 0.8959248661994934, Val recall: 0.7374804019927979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "f1s = []\n",
    "f1s_eval = []\n",
    "accuracies = []\n",
    "accuracies_eval = []\n",
    "precisions = []\n",
    "precisions_eval = []\n",
    "recalls = []\n",
    "recalls_eval = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    print('Training...')\n",
    "    epoch_loss = train_II(model_II, train_iterator, optimizer_II, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "    print('\\nEvaluating on train...')\n",
    "    f1_on_train, accuracy_on_train, precision_on_train, recall_on_train,_ = evaluate_II(model_II, train_iterator, criterion)\n",
    "    f1s.append(f1_on_train)\n",
    "    accuracies.append(accuracy_on_train)\n",
    "    precisions.append(precision_on_train)\n",
    "    recalls.append(recall_on_train)\n",
    "    print('\\nEvaluating on test...')\n",
    "    f1_on_test, accuracy_on_test, precision_on_test, recall_on_test, epoch_loss_on_test = evaluate_II(model_II, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)\n",
    "    f1s_eval.append(f1_on_test)\n",
    "    accuracies_eval.append(accuracy_on_test)\n",
    "    precisions_eval.append(precision_on_test)\n",
    "    recalls_eval.append(recall_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6852426407012072, 0.6346949501471086, 0.5873468897559426, 0.5395162559368394, 0.4966728057373654, 0.4637072055854581, 0.43528044426983054, 0.4147061597217213, 0.3924485556781292, 0.3765388571403243] \n",
      "\n",
      " [0.6614657521247864, 0.6280522525310517, 0.5876662254333496, 0.5464789927005768, 0.5219768404960632, 0.5035303264856339, 0.505085751414299, 0.4959722191095352, 0.4908071607351303, 0.5027923226356507]\n"
     ]
    }
   ],
   "source": [
    "print(losses, '\\n\\n', losses_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3RU1d7G8e9MeiEJEEgChl6kd0KzIB3h0kF6VxBULmLh+koRlasoVq5Ib1KDAkonKiotSBGR0Ak1EAIkIQmpc94/5jreGEoCSSYhz2etWcvZs88+v5n1vjcP5+yzt8kwDAMRERGRAsRs7wJEREREcpsCkIiIiBQ4CkAiIiJS4CgAiYiISIGjACQiIiIFjgKQiIiIFDgKQCIiIlLgKACJiIhIgaMAJCIiIgWOApCI5GllypRh0KBB9i4jRy1YsACTyUR4eLi9SxEpMBSARMT2B/h/X8WLF6d58+Zs3LjxtsckJiby0UcfERQUhLe3N66urlSqVInRo0dz/PhxW79JkyZlGPt/X5cvX86trykiYuNo7wJEJO946623KFu2LIZhcOXKFRYsWED79u359ttv6dChg61fVFQUbdu2Zd++fXTo0IE+ffrg6enJsWPHWL58ObNmzSI5OTnd2F988QWenp4Zzunj45Pj30tE5O8UgETEpl27dtSvX9/2fujQofj5+bFs2bJ0AWjQoEEcOHCA4OBgunXrlm6MKVOm8MYbb2QYu3v37vj6+uZc8SIiWaBbYCJyRz4+Pri5ueHo+Ne/lfbs2cP69esZOnRohvAD4OLiwgcffJCjdZ0+fZoePXpQpEgR3N3dadSoEevXr8/Q77PPPqNatWq4u7tTuHBh6tevz9KlS22f37x5kzFjxlCmTBlcXFwoXrw4rVq1Yv/+/Xc8d3BwMCaTie3bt2f47Msvv8RkMnH48GEADh06xKBBgyhXrhyurq74+/szZMgQrl27ds/vaDKZmDRpUob2282Jio6OZsyYMQQGBuLi4kKFChV47733sFgs9zyPSEGlK0AiYhMTE0NUVBSGYRAZGclnn31GXFwc/fr1s/VZt24dAP3798/S2NevX8/Q5ujomOVbYFeuXKFJkyYkJCTw4osvUrRoURYuXMg//vEPgoOD6dKlCwCzZ8/mxRdfpHv37rz00kskJiZy6NAh9uzZQ58+fQAYMWIEwcHBjB49mqpVq3Lt2jV++eUXwsLCqFu37m3P//TTT+Pp6cnKlSt54okn0n22YsUKqlWrRvXq1QHYunUrp0+fZvDgwfj7+/PHH38wa9Ys/vjjD3bv3o3JZMrSd7+dhIQEnnjiCS5evMhzzz1HqVKl2LlzJ+PHjyciIoKPP/74gc8h8lAyRKTAmz9/vgFkeLm4uBgLFixI17dLly4GYNy4cSNTY0+cOPG2YwNG5cqV73l86dKljYEDB9rejxkzxgCMn3/+2dZ28+ZNo2zZskaZMmWMtLQ0wzAMo1OnTka1atXuOra3t7cxatSoTH2P/9W7d2+jePHiRmpqqq0tIiLCMJvNxltvvWVrS0hIyHDssmXLDMD46aefbG1//v5nzpyxtQHGxIkTMxz/999jypQphoeHh3H8+PF0/V5//XXDwcHBOHfuXJa/n0hBoFtgImIzY8YMtm7dytatW1myZAnNmzdn2LBhfP3117Y+sbGxABQqVChLY69evdo29p+v+fPnZ7nGDRs20LBhQ5o1a2Zr8/T05NlnnyU8PJwjR44A1tt3Fy5cYO/evXccy8fHhz179nDp0qUs1dCrVy8iIyP58ccfbW3BwcFYLBZ69epla3Nzc7P9d2JiIlFRUTRq1AjgrrfZsmLVqlU89thjFC5cmKioKNurZcuWpKWl8dNPP2XLeUQeNroFJiI2DRs2TDcJunfv3tSpU4fRo0fToUMHnJ2d8fLyAqzzZ7Jy++rxxx/PlknQZ8+eJSgoKEN7lSpVbJ9Xr16d1157jW3bttGwYUMqVKhA69at6dOnD02bNrUd8/777zNw4EACAwOpV68e7du3Z8CAAZQrV+6uNbRt2xZvb29WrFhBixYtAOvtr9q1a1OpUiVbv+vXrzN58mSWL19OZGRkujFiYmLu+zf4XydOnODQoUMUK1bstp///bwiYqUrQCJyR2azmebNmxMREcGJEycAePTRRwH4/fff7VnaPVWpUsX2WH6zZs1YvXo1zZo1Y+LEibY+PXv25PTp03z22WeUKFGCadOmUa1atTuuffQnFxcXOnfuzDfffENqaioXL15kx44d6a7+/Dn+7NmzGTFiBF9//TVbtmxh06ZNAPc9QTktLS3de4vFQqtWrTJcXfvzdbuJ6iKiK0Aicg+pqakAxMXFAdCxY0emTp3KkiVLeOyxx3K9ntKlS3Ps2LEM7UePHrV9/icPDw969epFr169SE5OpmvXrrzzzjuMHz8eV1dXAAICAnj++ed5/vnniYyMpG7durzzzju0a9furnX06tWLhQsXEhISQlhYGIZhpAtAN27cICQkhMmTJzNhwgRb+59B8l4KFy5MdHR0urbk5GQiIiLStZUvX564uDhatmyZqXFFxEpXgETkjlJSUtiyZQvOzs62W0yNGzembdu2zJkzhzVr1mQ4Jjk5mXHjxuVYTe3btyc0NJRdu3bZ2uLj45k1axZlypShatWqABkeNXd2dqZq1aoYhkFKSgppaWkZbkMVL16cEiVKkJSUdM86WrZsSZEiRVixYgUrVqygYcOGlC1b1va5g4MDAIZhpDsus09llS9fPsP8nVmzZmW4AtSzZ0927drF5s2bM4wRHR1tC7Aikp6uAImIzcaNG21XUiIjI1m6dCknTpzg9ddft839AVi0aBGtW7ema9eudOzYkRYtWuDh4cGJEydYvnw5ERERGdYCCg4Ovu1K0K1atcLPzy/TNb7++ussW7aMdu3a8eKLL1KkSBEWLlzImTNnWL16NWaz9d91rVu3xt/fn6ZNm+Ln50dYWBiff/45Tz/9NIUKFSI6OppHHnmE7t27U6tWLTw9Pdm2bRt79+7lww8/vGcdTk5OdO3aleXLlxMfH5/h+3p5efH444/z/vvvk5KSQsmSJdmyZQtnzpzJ1PccNmwYI0aMoFu3brRq1YrffvuNzZs3Z5hH9corr7Bu3To6dOjAoEGDqFevHvHx8fz+++8EBwcTHh6uBShFbsfOT6GJSB5wu8fgXV1djdq1axtffPGFYbFYMhyTkJBgfPDBB0aDBg0MT09Pw9nZ2ahYsaLxwgsvGCdPnrT1u9tj8IDxww8/3LW2vz/2bRiGcerUKaN79+6Gj4+P4erqajRs2ND47rvv0vX58ssvjccff9woWrSo4eLiYpQvX9545ZVXjJiYGMMwDCMpKcl45ZVXjFq1ahmFChUyPDw8jFq1ahn/+c9/Mv27bd261QAMk8lknD9/PsPnFy5cMLp06WL4+PgY3t7eRo8ePYxLly5leMT9do/Bp6WlGa+99prh6+truLu7G23atDFOnjx529/j5s2bxvjx440KFSoYzs7Ohq+vr9GkSRPjgw8+MJKTkzP9fUQKEpNh/O36rIiIiMhDTnOAREREpMBRABIREZECRwFIREREChwFIBERESlw8kQAmjFjBmXKlMHV1ZWgoCBCQ0Pv2PfJJ5/EZDJleD399NO2PoZhMGHCBAICAnBzc6Nly5aZXnxMREREHn52D0ArVqxg7NixTJw4kf3791OrVi3atGlzx/1rvv76ayIiImyvw4cP4+DgQI8ePWx93n//fT799FNmzpzJnj178PDwoE2bNiQmJubW1xIREZE8zO6PwQcFBdGgQQM+//xzwLqvTWBgIC+88AKvv/76PY//+OOPmTBhAhEREXh4eGAYBiVKlODll1+2rUYbExODn58fCxYs4JlnnrnnmBaLhUuXLlGoUCFMJtODfUERERHJFYZhcPPmTUqUKGFbFPVO7LoSdHJyMvv27WP8+PG2NrPZTMuWLdMtc383c+fO5ZlnnsHDwwOAM2fOcPny5XT74nh7exMUFMSuXbtuG4CSkpLSLX1/8eJF23L6IiIikr+cP3+eRx555K597BqAoqKiSEtLy7AMvp+fn205/rsJDQ3l8OHDzJ0719Z2+fJl2xh/H/PPz/5u6tSpTJ48OUP7+fPn0y3/LyIiInlXbGwsgYGBFCpU6J598/VeYHPnzqVGjRo0bNjwgcYZP348Y8eOtb3/8wf08vJSABIREclnMjN9xa6ToH19fXFwcODKlSvp2q9cuYK/v/9dj42Pj2f58uUMHTo0Xfufx2VlTBcXF1vYUegRERF5+Nk1ADk7O1OvXj1CQkJsbRaLhZCQEBo3bnzXY1etWkVSUhL9+vVL1162bFn8/f3TjRkbG8uePXvuOaaIiIgUDHa/BTZ27FgGDhxI/fr1adiwIR9//DHx8fEMHjwYgAEDBlCyZEmmTp2a7ri5c+fSuXNnihYtmq7dZDIxZswY3n77bSpWrEjZsmV58803KVGiBJ07d8617yUiIiJ5l90DUK9evbh69SoTJkzg8uXL1K5dm02bNtkmMZ87dy7Do2zHjh3jl19+YcuWLbcd89VXXyU+Pp5nn32W6OhomjVrxqZNm3B1dc3x7yMiInI3FouF5ORke5eRLzk5OeHg4JAtY9l9HaC8KDY2Fm9vb2JiYjQfSEREsk1ycjJnzpzBYrHYu5R8y8fHB39//9tOdM7K32+7XwESEREpCAzDICIiAgcHBwIDA++5UJ+kZxgGCQkJtp0iAgICHmg8BSAREZFckJqaSkJCAiVKlMDd3d3e5eRLbm5uAERGRlK8ePEHuh2m+CkiIpIL0tLSAOsT0HL//gyPKSkpDzSOApCIiEgu0h6TDya7fj8FIBERESlwFIBEREQkV5QpU4aPP/7Y3mUAmgQtIiIid/Hkk09Su3btbAkue/fuxcPDIxuqenC6ApTLQsKukGbR0ksiIvJwMAyD1NTUTPUtVqxYnnkCTgEoF32y7QRDF/7K/605jNafFBGRvG7QoEFs376dTz75BJPJhMlkYsGCBZhMJjZu3Ei9evVwcXHhl19+4dSpU3Tq1Ak/Pz88PT1p0KAB27ZtSzfe32+BmUwm5syZQ5cuXXB3d6dixYqsW7cuV76bAlAuquTnickEy0LP8dHW4/YuR0RE7MgwDBKSU+3yyuw/wj/55BMaN27M8OHDiYiIICIigsDAQABef/11/v3vfxMWFkbNmjWJi4ujffv2hISEcODAAdq2bUvHjh05d+7cXc8xefJkevbsyaFDh2jfvj19+/bl+vXrD/z73ovmAOWidjUCeLtzdd745jCffn+Sop4uDGxSxt5liYiIHdxKSaPqhM12OfeRt9rg7nzvCODt7Y2zszPu7u74+/sDcPToUQDeeustWrVqZetbpEgRatWqZXs/ZcoUvvnmG9atW8fo0aPveI5BgwbRu3dvAN59910+/fRTQkNDadu27X19t8zSFaBc1jeoNP9sWQmASd/+wXeHLtm5IhERkayrX79+uvdxcXGMGzeOKlWq4OPjg6enJ2FhYfe8AlSzZk3bf3t4eODl5WXb7iIn6QqQHbzYogLX4pNYtOss/1xxEB83Z5pV9LV3WSIikovcnBw48lYbu537Qf39aa5x48axdetWPvjgAypUqICbmxvdu3cnOTn5ruM4OTmle28ymXJls1gFIDswmUxM7FiNa/HJrD8UwbOLf2X5s42o+YiPvUsTEZFcYjKZMnUbyt6cnZ1t23jczY4dOxg0aBBdunQBrFeEwsPDc7i6+6dbYHbiYDYxvWctmlYoSkJyGoPm7+X01Th7lyUiIpJOmTJl2LNnD+Hh4URFRd3x6kzFihX5+uuvOXjwIL/99ht9+vTJlSs590sByI5cHB34sn99apT05np8Mv3nhnIlNtHeZYmIiNiMGzcOBwcHqlatSrFixe44p2f69OkULlyYJk2a0LFjR9q0aUPdunVzudrMMxlakCaD2NhYvL29iYmJwcvLK8fPFxWXRI+ZuzgTFc+j/oVY8VxjvN2c7n2giIjkG4mJiZw5c4ayZcvi6upq73Lyrbv9jln5+60rQHmAr6cLi4Y0pFghF45evsmwhXtJTLn3/VYRERG5PwpAeURgEXcWDWlIIVdH9obfYPTSA6Sm5d17pyIiIvmZAlAeUiXAizkD6uPsaGZb2BX+9c3v2jJDREQkBygA5TFB5Yryee86mE2w8tcLTNt8zN4liYiIPHQUgPKg1tX8mdq1BgD/+fEUc385Y+eKREREHi4KQHlUrwaleKVNZQCmfHeENQcu2rkiERGRh4cCUB72/JPlGdy0DADjVv3Gj8dyfm8UERGRgkABKA8zmUy8+XRVOtUuQarFYOSS/Rw4d8PeZYmIiOR7CkB5nNlsYlr3WjxeqRi3UtIYsmAvJyO1ZYaIiMiDUADKB5wdzXzRty61An24kZDCgLl7iIi5Ze+yRERE7qlMmTJ8/PHH9i4jAwWgfMLDxZH5gxpQrpgHl2ISGTA3lOiEZHuXJSIiki8pAOUjRTycWTSkIf5erpyIjGPowl+5lawtM0RERLJKASifeaSwO4uGNsTbzYl9Z28waul+UrRlhoiI5IBZs2ZRokQJLJb0f2c6derEkCFDOHXqFJ06dcLPzw9PT08aNGjAtm3b7FRt1igA5UOV/Aoxb1B9XJ3MfH80ktdWH8Ji0ZYZIiL5imFAcrx9XpncZqlHjx5cu3aNH374wdZ2/fp1Nm3aRN++fYmLi6N9+/aEhIRw4MAB2rZtS8eOHTl37lxO/WrZxtHeBcj9qVe6CP/pW5fhi/bx9f6L+Hq68K/2VexdloiIZFZKArxbwj7n/tclcPa4Z7fChQvTrl07li5dSosWLQAIDg7G19eX5s2bYzabqVWrlq3/lClT+Oabb1i3bh2jR4/OsfKzg64A5WNPPerHe91qAjDrp9PM+umUnSsSEZGHTd++fVm9ejVJSUkAfPXVVzzzzDOYzWbi4uIYN24cVapUwcfHB09PT8LCwnQFSP4mLRX2zYe6A8HROVuG7F7vEa7FJTF141He3XCUoh4udKv3SLaMLSIiOcjJ3Xolxl7nzqSOHTtiGAbr16+nQYMG/Pzzz3z00UcAjBs3jq1bt/LBBx9QoUIF3Nzc6N69O8nJef8pZQWg3PTTNNj+bzj4FXSbC0XLZ8uwzz1Rnqi4JGb/fIZXVx+isIcTTz3qly1ji4hIDjGZMnUbyt5cXV3p2rUrX331FSdPnqRy5crUrVsXgB07djBo0CC6dOkCQFxcHOHh4XasNvN0Cyw3+dcAVx+4dAC+fBx+W55tQ49vV4WudUqSZjF4/qv97Dt7PdvGFhGRgq1v376sX7+eefPm0bdvX1t7xYoV+frrrzl48CC//fYbffr0yfDEWF6lAJSbqnSAkTugdFNIjoNvnoOvn4Wkmw88tNls4r3uNWleuRiJKRaGLPiV41cefFwREZGnnnqKIkWKcOzYMfr06WNrnz59OoULF6ZJkyZ07NiRNm3a2K4O5XUmw8jks3AFSGxsLN7e3sTExODl5ZX9J7Ckwc8fwo9TwbBA4bLQfS6UrPfAQyckp9J3zh4OnIvG38uV1c83oaSPWzYULSIiDyIxMZEzZ85QtmxZXF1d7V1OvnW33zErf791BcgezA7wxKsweCN4B8KNMzC3Nez4BB7w0qG7s3XLjIrFPbkcm0j/uXu4Hp/3J6OJiIjkJgUgeyrVCEb8DFU7gyUVtk6AJV3h5pUHGtbH3ZlFQxtSwtuV01fjGbxgL/FJqdlUtIiISP6nAGRvboWhxwLo+Ck4usHpH+CLJnBi6wMNG+DtxqKhDfFxd+K389GM/Go/yan5Y2KaiIhITlMAygtMJqg3EJ7bDn7VISEKvuoOm/4FqUn3PWyF4oWYP6gBbk4O/HT8Kq8E/6YtM0RERFAAyluKVYZhIRA0wvp+9wyY0xKiTt73kHVKFeaLfnVxNJtYe/ASb68PQ/PeRUTsR/8b/GCy6/ezewCaMWMGZcqUwdXVlaCgIEJDQ+/aPzo6mlGjRhEQEICLiwuVKlViw4YNts8nTZqEyWRK93r00Udz+mtkHydXaPce9F4ObkXg8iHrmkEHvsr05nV/92Tl4nzQw7pXy7wdZ/hiu7bMEBHJbQ4ODgD5YpXkvCwhIQEAJyenBxrHritBr1ixgrFjxzJz5kyCgoL4+OOPadOmDceOHaN48eIZ+icnJ9OqVSuKFy9OcHAwJUuW5OzZs/j4+KTrV61aNbZt22Z77+iYDxe8rtzOumbQ189C+M+w9nk4FQIdPgJX7ywP17lOSaLiknh7fRjvbzqGr4cLPRsE5kDhIiJyO46Ojri7u3P16lWcnJwwm+1+DSJfMQyDhIQEIiMj8fHxsQXK+2XXdYCCgoJo0KABn3/+OQAWi4XAwEBeeOEFXn/99Qz9Z86cybRp0zh69Ogdk9+kSZNYs2YNBw8evO+6cnwdoKywpMGOj+H7d8BIA59S0G0eBDa4r+H+vfEoM7efwmyCL/vXp1VVbZkhIpJbkpOTOXPmTL5ZLTkv8vHxwd/fH5PJlOGzrPz9tlsASk5Oxt3dneDgYDp37mxrHzhwINHR0axduzbDMe3bt6dIkSK4u7uzdu1aihUrRp8+fXjttddsSXDSpElMmzYNb29vXF1dady4MVOnTqVUqVJ3rCUpKcm2yy1Yf8DAwMC8EYD+dH4vrB4C0efA5ABPvQFNx1jXFMoCwzB4NfgQq/ZdwMXRzOKhQTQsWySHihYRkb+zWCy6DXafnJyc7nrlJysByG73hqKiokhLS8PPL/0VCD8/P44ePXrbY06fPs33339P37592bBhAydPnuT5558nJSWFiRMnAtarSgsWLKBy5cpEREQwefJkHnvsMQ4fPkyhQoVuO+7UqVOZPHly9n7B7BbYAEb8At/9Ew6vhpC34PSP0GUWeAVkehiTycTUrjW4kZDCtrArDF24l5XPNaZKQB4JeiIiDzmz2ayVoPMAu10BunTpEiVLlmTnzp00btzY1v7qq6+yfft29uzZk+GYSpUq2ZbA/jMBTp8+nWnTphEREXHb80RHR1O6dGmmT5/O0KFDb9snX1wB+pNhwMGlsOEVSIm3TpTu/AVUbpulYRJT0ug/dw97w29QvJALq0c2IbCIew4VLSIikvPyxVYYvr6+ODg4cOVK+lWPr1y5gr+//22PCQgIoFKlSukuf1WpUoXLly/f8XKij48PlSpV4uTJOz9K7uLigpeXV7pXnmUyQZ2+1jWD/GvCreuwrBdseBVSEjM9jKuTA3MGNKCyXyEibyYxYF4oUXH3v+aQiIhIfmK3AOTs7Ey9evUICQmxtVksFkJCQtJdEfpfTZs25eTJk+kmjx0/fpyAgACcnZ1ve0xcXBynTp0iICDzt4nyBd+KMGwbNBplfR/6JcxpAVePZXoIb3cnFg1tSEkfN85ExTN4/l7itGWGiIgUAHZ9Bm/s2LHMnj2bhQsXEhYWxsiRI4mPj2fw4MEADBgwgPHjx9v6jxw5kuvXr/PSSy9x/Phx1q9fz7vvvsuoUaNsfcaNG8f27dsJDw9n586ddOnSBQcHB3r37p3r3y/HObpA23ehbzC4+8KVw/DlE7BvYabXDPLzcmXx0IYU8XDm94sxjFi8j6TUtBwuXERExL7sGoB69erFBx98wIQJE6hduzYHDx5k06ZNtonR586dSze3JzAwkM2bN7N3715q1qzJiy++yEsvvZTukfkLFy7Qu3dvKleuTM+ePSlatCi7d++mWLFiuf79ck3FVjByJ5RrDqm34NsXYdUguBWdqcPLFfNk/qAGuDs78MvJKF5eqS0zRETk4WbXdYDyqjy1DlBWWCyw6zPrE2KWVPAOhG5zoVRQpg7/+cRVhizYS0qawcDGpZn0j2q3XWdBREQkL8oXk6AlB5jN0PQlGLoFCpeFmPMwvx1sf9+6oOI9PFaxGB/2rI3JBAt3neWz7+9/DzIREZG8TAHoYVSyHoz4GWr2sq4e/cM7sPAfEHPxnof+o1YJJnaoCsD0rcf5as/ZnK5WREQk1ykAPaxcCkHXWdDlS3D2hLO/wMymEPbdPQ8d1LQsLzxVAYA31xxm0+Hbr7EkIiKSXykAPexqPQPP/QQl6sCtG7CiL6x/GVJu3fWwsa0q0bthKSwGvLjsILtOXculgkVERHKeAlBBULQ8DNkCTV60vt87B2Y/BVeO3PEQk8nE252r06aaH8lpFp5d9Ct/XIrJpYJFRERylgJQQeHoDK2nQL+vwaM4RB6B2c1h79w7rhnkYDbxyTN1CCpbhJtJqQyct5ez1+JzuXAREZHspwBU0FRoYV0zqEJLSE2E9WNhRT9IuH7b7q5ODsweWJ8qAV5ExVm3zLh6U1tmiIhI/qYAVBB5FoM+q6DNu2B2gqPfwcxmEL7jtt29XJ1YOLgBgUXcOHstgYHzQolNTMnlokVERLKPAlBBZTZD41HW/cSKlIfYi7CwA/zwLqRl3A+suJcri4cE4evpzJGIWJ5d9CuJKdoyQ0RE8icFoIKuRG3rU2K1+4Fhge3vwYKnIfpchq5lfD1YMLghni6O7D59nReXHSAlzXKbQUVERPI2BSABF0/oPMO6bYZzITi/23pL7I81GbpWL+nNrP71cHY0s+XIFcasOEiqQpCIiOQzCkDylxrdrStIl6wPiTGwaiB8+xIkJ6Tr1qSCL1/2q4eTg4n1hyJ4JfgQado8VURE8hEFIEmvSFkYsgmajQVMsG8BzHoSLh9O1635o8X5vE9dHM0mvjlwkfFfH9IO8iIikm8oAElGDk7QciIMWAOe/hB1zLpwYujsdGsGtanmzyfP1MFsgpW/XmDCusMYd1hTSEREJC9RAJI7K/ckjNwBFdtAWhJsGAfL+0D8X9tiPF0zgOn/3UF+ye5zTPkuTCFIRETyPAUguTsPX+izAtq9Dw7OcGyDdVPVMz/ZunSuU5L3utYEYN6OM7y36ZhCkIiI5GkKQHJvJhMEPQfDvwffSnAzAhb+A7ZPs90S69kgkCmdqwMwc/spPtp2wp4Vi4iI3JUCkGSefw149keoOwAw4Ie3Yd0LkGZdFbp/o9JM6FAVgE9DTjDjh5N2KzMLZP0AACAASURBVFVERORuFIAka5w94B+fwdPTwWSGA4thaS9IugnAkGZleb3dowBM23yM2T+dtme1IiIit6UAJPenwVB4Zhk4ucOpEJjfDmIjABjxRHnGtqoEwDsbwliw44w9KxUREclAAUjuX+W2MGg9eBSDy7/DnJYQGQbAiy0qMrp5BQAmfXuEpXsybq0hIiJiLwpA8mBK1rVuqFq0IsRegLltbE+Ivdy6Es8+Xg6Af33zO6t+PW/PSkVERGwUgOTBFS4DQ7dAqcaQFAOLu8KhVZhMJsa3e5RBTcoA8OrqQ6w9eNGupYqIiIACkGQX9yLQfw1U6wKWFPh6GPz8ISZgYseq9AkqhWHA2JW/sfH3CHtXKyIiBZwCkGQfJ1foNg+avGB9H/IWfPdPTJY03u5Une71HiHNYvDCsgNsPXLFvrWKiEiBpgAk2ctshtZvQ7tpWDdTnQ/L+2BOiee9bjXpVLsEqRaDUV/t58djkfauVkRECigFIMkZQc9CryXg6AonNsOCp3GIj+TDHrVoX8Of5DQLzy7ex46TUfauVERECiAFIMk5VTrAwO/AvShEHIS5LXG8fpJPnqlDyyp+JKdaGLpwL3tOX7v3WCIiItlIAUhyVmADGLoVipSD6HMwtxVOF3Yzo28dnqxcjMQUC0MW7GXf2Rv2rlRERAoQBSDJeUXLw9Bt8EhDSIyGRZ1wObqGmf3q0ayCL/HJaQyaF8pv56PtXamIiBQQCkCSOzyKwsB18GgHSEuG4CG4hs5gdv96NCxbhJtJqQyYF8ofl2LsXamIiBQACkCSe5zcoOciCBphfb/1TdxCxjNvQF3qlvIh5lYK/eeGcuzyTfvWKSIiDz0FIMldZgdo9x60eRcwQegsPNcMZkH/6tR8xJvr8cn0nbOHU1fj7F2piIg8xBSAxD4aj4IeC8DBBY6tx2t5Fxb3KkvVAC+i4pLoM3s34VHx9q5SREQeUgpAYj/VOlvnBbkVhov78F7anqVdfank58mVWGsIOn89wd5ViojIQ0gBSOyrVCPrY/I+peFGOD5L27OinZlyxTy4FJNInzm7uRR9y95ViojIQ0YBSOzPtyIM2wYl6sKt6xQO7s7qJ65Ruqg756/fou+cPUTGJtq7ShEReYgoAEne4FkcBn0HldpBaiKFvxvK2vq/80hhN85ExdNnzh6i4pLsXaWIiDwkFIAk73D2gGe+ggbDAAOf7W+ysfIGSng5czIyjn5z9nAjPtneVYqIyENAAUjyFrMDtP8AWk4GoNDB2WwNnE+gJxy9fJP+8/YQcyvFzkWKiEh+pwAkeY/JBM3GQLe54OCMx6n1bPGdTnn3RA5fjGXAvFBuJioEiYjI/VMAkryrRnfo/w24euN2+Vc2FJpCdbdr/HY+msHz9xKflGrvCkVEJJ9SAJK8rUwz62Py3qVwiTnDGpdJNHEN59ezNxi6cC+3ktPsXaGIiORDdg9AM2bMoEyZMri6uhIUFERoaOhd+0dHRzNq1CgCAgJwcXGhUqVKbNiw4YHGlDyuWGUYthUCauGYeI0lDm/RweUgu09f59nFv5KYohAkIiJZY9cAtGLFCsaOHcvEiRPZv38/tWrVok2bNkRGRt62f3JyMq1atSI8PJzg4GCOHTvG7NmzKVmy5H2PKflEIX8YtAEqtMKclshn5g8Y6ryNn09E8fxX+0lOtdi7QhERyUdMhmEY9jp5UFAQDRo04PPPPwfAYrEQGBjICy+8wOuvv56h/8yZM5k2bRpHjx7FyckpW8a8ndjYWLy9vYmJicHLy+s+v53kiLRUWP9P2L8IgNmWjryb3ItWVQOY0bcuTg52v6gpIiJ2kpW/33b7a5GcnMy+ffto2bLlX8WYzbRs2ZJdu3bd9ph169bRuHFjRo0ahZ+fH9WrV+fdd98lLS3tvseUfMbBETp+Ck+9CcBw87d87jyD7UfOM2bFQVLTdCVIRETuzW4BKCoqirS0NPz8/NK1+/n5cfny5dsec/r0aYKDg0lLS2PDhg28+eabfPjhh7z99tv3PSZAUlISsbGx6V6Sh5lM8Pg46DILzE48bd7FYud/88uhE7wafIg0i90uaoqISD6Rr+4XWCwWihcvzqxZs6hXrx69evXijTfeYObMmQ807tSpU/H29ra9AgMDs6liyVG1ekG/1eDiRUPzUVa7TCL04EH+9fXvWBSCRETkLuwWgHx9fXFwcODKlSvp2q9cuYK/v/9tjwkICKBSpUo4ODjY2qpUqcLly5dJTk6+rzEBxo8fT0xMjO11/vz5B/hmkqvKPQFDNoNXSSqYLvG180T+2LedCesOY8fpbSIiksfZLQA5OztTr149QkJCbG0Wi4WQkBAaN25822OaNm3KyZMnsVj+mudx/PhxAgICcHZ2vq8xAVxcXPDy8kr3knzEr6p1N3m/6hQ3RbPCeQoXQtcy5bswhSAREbktu94CGzt2LLNnz2bhwoWEhYUxcuRI4uPjGTx4MAADBgxg/Pjxtv4jR47k+vXrvPTSSxw/fpz169fz7rvvMmrUqEyPKQ8prxIweCOUa46HKYk5Th9ya/cc3tt0TCFIREQycLTnyXv16sXVq1eZMGECly9fpnbt2mzatMk2ifncuXOYzX9ltMDAQDZv3sw///lPatasScmSJXnppZd47bXXMj2mPMRcvaDvKvh2DI4HlzDVaS6f74jiI4c3GNu6sr2rExGRPMSu6wDlVVoHKJ8zDNj+Hvw4FYBv0ppy+ckPGdmiip0LExGRnJQv1gESyTEmEzz5OnSaQZrJkS4OO6j14xAWhvxm78pERCSPUACSh1edfjj0XUmygztNHI7QaHsfVn2/295ViYhIHqAAJA+3Ci1wHraZm07FqGy+wGPbn2HD1i32rkpEROxMAUgefgE18Rz1A5Fu5fE33eDxX/rz88YV9q5KRETsSAFICgSTTyDFXgzhjGddPE2JNNo9kgNrP7N3WSIiYicKQFJgmNwKU2bMJg74tMHJlEadA//HiRX/sj41JiIiBYoCkBQoJkcXar2wnG2+/QGoGDaDiwuHQlqKnSsTEZHcpAAkBY7ZwUzz5z9juf84Ug0zJcNXc31ON0iOt3dpIiKSSxSApEByMJvoPvwNviwxhVuGM0UithP3ZVuIj7J3aSIikgsUgKTAcnQwM3zo83xY4kOuG554XjtE4swWcP20vUsTEZEcpgAkBZqzo5lxQ/ryrv+nnLcUw/VmOKmzW8GlA/YuTUREcpACkBR4rk4OvDW0E2/5fcJhSxkcb0VhmdceTm6zd2kiIpJDFIBEAHdnR6YPbc3bxT7g57TqmFMTMJb2gt+W27s0ERHJAQpAIv9VyNWJL4c+ybSiU1iT1gSTJRW+eQ5++UhrBYmIPGQUgET+h7e7E/OHNeU/Pq/yZerT1sZtk2Dja2BJs2ttIiKSfRSARP6mqKcLS4Y3Zpn3cN5KsS6YSOiXEDwYUhLtW5yIiGQLBSCR2yju5cpXwxuxuVBXRie/QDKOcGQtLOkGt6LtXZ6IiDwgBSCROyjp48ay4Y3Y6/kkA5NfIx53OPsLzG8HMRftXZ6IiDwABSCRuyhV1J2vhjXihHsduiVN4Lq5CEQegbmtIDLM3uWJiMh9UgASuYcKxT1ZMiyIy27l6ZgwkQsOgRB7Eea1gbO77F2eiIjcBwUgkUx41N+LxUOCiHUJoEP8/3HcuSokxsCiTnBknb3LExGRLFIAEsmkGo94s2BIA5KdfegY+yoH3JpAWhKsHAChs+1dnoiIZIECkEgW1CtdhLkDG4CjK91vjORnr46AARvGQchbWjBRRCSfUAASyaLG5Ysya0B9HByc6B/5DBt8h1g/+PlDWDsa0lLsW6CIiNyTApDIfXiiUjE+71MHR7OZ5y+0ZHXJVzFMDnBwCSzrDcnx9i5RRETuQgFI5D61rubPR71qYzbBy6dqs6zcvzEc3eDkVljQAeKu2rtEERG5AwUgkQfQsVYJ3u9eC4B//VGSRZU/x3ArApf2w7zWcP20nSsUEZHbUQASeUDd6z3C252rAzBxnxuLqs4Gn1LW8DO3NVw6YOcKRUTk7xSARLJBv0alebNDVQAm7khiUdU54F8T4q/C/Kfh5DY7VygiIv9LAUgkmwxtVpZX2lQGYML3USyr9gWUexJS4mFpL/htuV3rExGRvygAiWSjUc0rMLp5BQDGrz/LqsrToUYPsKTCN8/BLx9prSARkTxAAUgkm73cuhLDmpUF4NU1R1lbbiI0ecH64bZJsPE1sKTZr0AREVEAEsluJpOJN56uQt+gUhgGjF31O5tKjII2U60dQr+E4MGQkmjfQkVECjAFIJEcYDKZmNKpOt3rPUKaxeCFZQf4oXB36D4PHJzhyFpY0g1uRdu7VBGRAkkBSCSHmM0m3utWkw41A0hJM3huyT52uD4B/VaDixec/QXmt4OYi/YuVUSkwFEAEslBDmYTH/WqTeuqfiSnWhi28Ff2mqrD4I3g6Q+RR2BuK4gMs3epIiIFigKQSA5zcjDzWZ86PFGpGLdS0hg8fy8HUx6BYVvBtxLEXoR5beDsLnuXKiJSYCgAieQCF0cHvuxfj8blihKXlMqAuXv4I8EbhmyGwCBIjIFFneDIOnuXKiJSICgAieQSVycH5gysT73ShYlNTKX/3FBO3HSCAWuh8tOQlgQrB0DobHuXKiLy0FMAEslFHi6OzB/cgBolvbken0zfOXsIj7FAz0VQbzBgwIZxEPKWFkwUEclBCkAiuczL1YlFQxryqH8hIm8m0Wf2bi7EJkOHj6D5G9ZOP38Ia0dDWop9ixUReUhlOQDdunWLhIQE2/uzZ8/y8ccfs2XLlmwtTORhVtjDmcVDgyhfzINLMYn0mb2Hy7FJ8MSr0PFTMDnAwSWwrDckxdm7XBGRh06WA1CnTp1YtGgRANHR0QQFBfHhhx/SqVMnvvjii2wvUORhVayQC18Na0SpIu6cu55A3zm7iYpLgnoD4Zml4OgGJ7fCwg4Qd9Xe5YqIPFSyHID279/PY489BkBwcDB+fn6cPXuWRYsW8emnn2Z7gSIPM39vV74aFkQJb1dOXY2n35w9RCckQ+W2MOg7cCsClw7AvNZw/bS9yxUReWhkOQAlJCRQqFAhALZs2ULXrl0xm800atSIs2fP3lcRM2bMoEyZMri6uhIUFERoaOgd+y5YsACTyZTu5erqmq7PoEGDMvRp27btfdUmktMCi7jz1fBGFC/kwtHLN+k/N5TYxBR4pD4M3Qo+pazhZ25raxgSEZEHluUAVKFCBdasWcP58+fZvHkzrVu3BiAyMhIvL68sF7BixQrGjh3LxIkT2b9/P7Vq1aJNmzZERkbe8RgvLy8iIiJsr9sFr7Zt26brs2zZsizXJpJbyvp68NWwIIp4OPP7xRgGz99LfFIq+FaAodvAvybEX4X5T8PJbfYuV0Qk38tyAJowYQLjxo2jTJkyBAUF0bhxY8B6NahOnTpZLmD69OkMHz6cwYMHU7VqVWbOnIm7uzvz5s274zEmkwl/f3/by8/PL0MfFxeXdH0KFy6c5dpEclNFv0IsHtoQL1dH9p29wbCFv5KYkgaF/GDQeij3JKTEw9Je8Ntye5crIpKvZTkAde/enXPnzvHrr7+yadMmW3uLFi346KOPsjRWcnIy+/bto2XLln8VZDbTsmVLdu2687YAcXFxlC5dmsDAQDp16sQff/yRoc+PP/5I8eLFqVy5MiNHjuTatWt3HC8pKYnY2Nh0LxF7qFbCm0VDg/B0cWTX6Ws8t3gfSalp4OoFfVZBjR5gSYVvnoNfPtJaQSIi9+m+1gHy9/enTp06mM1mYmNjWbNmDYUKFeLRRx/N0jhRUVGkpaVluILj5+fH5cuXb3tM5cqVmTdvHmvXrmXJkiVYLBaaNGnChQsXbH3atm3LokWLCAkJ4b333mP79u20a9eOtLS02445depUvL29ba/AwMAsfQ+R7FQ70If5gxvg5uTA9uNXeWHpAVLSLODoDF1mQZMXrB23TYKNr4Hl9v93LSIid2YyjKz9E7Jnz548/vjjjB49mlu3blGrVi3Cw8MxDIPly5fTrVu3TI916dIlSpYsyc6dO2230gBeffVVtm/fzp49e+45RkpKClWqVKF3795MmTLltn1Onz5N+fLl2bZtGy1atMjweVJSEklJSbb3sbGxBAYGEhMTc1/zmkSyw46TUQxesJfkVAsda5Xg4161cTCbrB/u+g9sHm/976qdrMHIyfXOg4mIFACxsbF4e3tn6u93lq8A/fTTT7bH4L/55hsMwyA6OppPP/2Ut99+O0tj+fr64uDgwJUrV9K1X7lyBX9//0yN4eTkRJ06dTh58uQd+5QrVw5fX9879nFxccHLyyvdS8Temlbw5ct+9XByMPHtb5d4bfUhLJb//nul8fPQfR44OMORtbCkK9yKtm/BIiL5SJYDUExMDEWKFAFg06ZNdOvWDXd3d55++mlOnDiRpbGcnZ2pV68eISEhtjaLxUJISEi6K0J3k5aWxu+//05AQMAd+1y4cIFr167dtY9IXtT80eJ8+kwdHMwmgvddYMK6w9gu2lbvBv1Wg4sXnN0BMx+zTo7WLTERkXvKcgAKDAxk165dxMfHs2nTJttj8Ddu3MiwHk9mjB07ltmzZ7Nw4ULCwsIYOXIk8fHxDB48GIABAwYwfvx4W/+33nqLLVu2cPr0afbv30+/fv04e/Ysw4YNA6wTpF955RV2795NeHg4ISEhdOrUiQoVKtCmTZss1ydib+1qBDC9Zy1MJliy+xzvrA/7KwSVfRwGbwSvRyDmnHVy9MzH4NgmTZAWEbkLx6weMGbMGPr27YunpyelS5fmySefBKy3xmrUqJHlAnr16sXVq1eZMGECly9fpnbt2mzatMk2MfrcuXOYzX/ltBs3bjB8+HAuX75M4cKFqVevHjt37qRq1aoAODg4cOjQIRYuXEh0dDQlSpSgdevWTJkyBRcXlyzXJ5IXdKpdkqQUC6+uPsScX87g5uzAy60rWz/0rw6j90Lol9YnwyL/gGW9ILARtJwEpTN3NVVEpCDJ8iRogF9//ZXz58/TqlUrPD09AVi/fj0+Pj40bdo024vMbVmZRCWSmxbuDGfiOuuyD6+0qcyo5hXSd7h1A375GPbMhNREa1ultvDUm9agJCLyEMvK3+/7CkB/+vNQk8l0v0PkSQpAkpd9uf0UUzceBeDNDlUZ2qxsxk6xl2D7e7B/MRhpgAlq9oTm/4LCZXK1XhGR3JKjT4EBLFq0iBo1auDm5oabmxs1a9Zk8eLF91WsiGTNc0+U558tKwEw5bsjfLXnNnvweZWAjp/AqFCo1gUw4NAK+Kw+bHgV4u681YyISEGQ5QA0ffp0Ro4cSfv27Vm5ciUrV66kbdu2jBgxIssrQYvI/XmxRQVGPFEegDe+OUzwvgu37+hbAXosgOE/QLnmYEmxzhX6pDZ8/w4katVzESmYsnwLrGzZskyePJkBAwaka1+4cCGTJk3izJkz2VqgPegWmOQHhmEw+dsjLNgZjtkEnzxTh461Stz9oNM/wrbJcGm/9b1bEXh8HNQfqoUURSTfy9FbYBERETRp0iRDe5MmTYiIiMjqcCJyn0wmExM7VqV3w0AsBry0/AArfz1/94PKPQnDv4eei6BoRbh1HTb/Cz6rBweWaA0hESkwshyAKlSowMqVKzO0r1ixgooVK2ZLUSKSOSaTiXc61+CZBtYQ9GrwIeb8fPpeB1m3z3h+N/zjMyhUAmIvwNpR8EUTCPtOawiJyEMvy7fAVq9eTa9evWjZsqXtkfcdO3YQEhLCypUr6dKlS44Umpt0C0zyG8MwmLrxKLN+soaf0c0r8HLrSpl7QjPlFoTOhp8/hMT/bqfxSAPrGkJlmuVYzSIi2S3HH4Pft28fH330EWFhYQBUqVKFl19+mTp16txfxXmMApDkR4Zh8J8fTzFt8zEA+jcqzeR/VMNszuQyFbeiYednsPs/kJJgbavQElpMgIBaOVS1iEj2ybV1gB5WCkCSny3ZfZY31x7GMKBT7RJ80KMWTg5ZuNt98wr89D7sWwCWVGtb9W7Q/A0oWj5HahYRyQ7ZHoBiYzP/qOzDEBgUgCS/W/fbJcauOEiqxeCpR4szo09d3JwdsjbI9dPww7vw+yrre7Mj1B0IT7wKhfyzv2gRkQeU7QHIbDbfcy6BYRiYTCbS0vL/UyQKQPIw+OFoJCOW7CMp1ULDMkWYM6g+Xq5OWR8o4hCEvAUnt1rfO7pBo5HQ9CVw88neokVEHkC2B6Dt27dn+uRPPPFEpvvmVQpA8rAIPXOdoQv2cjMplWolvFg4pCG+nve5KXD4L9Y1hC6EWt+7+sBjY6Hhs+Dkln1Fi4jcJ80BekAKQPIwOXwxhoHzQrkWn0w5Xw8WDwuipM99BhbDgGMbrVeErlofgqBQCXjyNajdDxwcs69wEZEsyvG9wEQk/6he0ptVIxpT0seN01Hx9PhiJ6euxt3fYCYTPNoeRu6Azl+AdyDcvATfvgT/CYI/1mgNIRHJFxSARAqAcsU8CR7ZmPLFPLgUk0iPmbs4fDHm/gc0O0DtPvDCPmj7b3AvCtdOwqqBMLu5dcsNEZE8TAFIpIAI8HZj1Ygm1CjpzfX4ZJ6ZtZs9p6892KCOLtYJ0S8ehCdeB2dPuHQAFnWyvi7uz57iRUSymQKQSAFSxMOZpcODCCpbhLikVAbMC+X7o1cefGBXL2g+3hqEgkaC2cl6FWh2c1g5EKJOPPg5RESyUaYDUGRk5F0/T01NJTQ09IELEpGcVcjViYVDGtKySnGSUi08u2gfaw9ezJ7BPYtBu39bb43V6g2Y4MgamBEE616E2EvZcx4RkQeU6QAUEBCQLgTVqFGD8+f/2nn62rVrNG7cOHurE5Ec4erkwBf96tGlTklSLQZjVhxk8a7w7DtB4dLQZSaM3AmV24ORBvsXwqd1YOsESLiefecSEbkPmQ5Af39aPjw8nJSUlLv2EZG8y8nBzIc9ajGoSRkMA95c+wefhZzI3v8/9qsKvZfBkM1QqjGkJsKOT+CT2tbNV5Pjs+9cIiJZkK1zgDK187SI5Blms4mJHavyUouKAHy49TjvrA/L/n/MlGoEgzdCn1XgVx2SYqxrCX1aB/bOhbSUe48hIpKNNAlapIAzmUz8s1UlJnSoCsCcX87wavAhUtMs2X0iqNQanvsZus4Gn9IQdwXWj4XPG8DvwWDJ5nOKiNxBpgOQyWTi5s2bxMbGEhMTg8lkIi4ujtjYWNtLRPKvIc3K8kGPWjiYTazad4HRSw+QlJoDe/uZzVCzJ4z+FdpNA49icOMMrB4Ks56wrjRtyf97CopI3pbprTD+viHqn5uf/v29NkMVyd82/3GZF5YeIDnNQtMKRZnVvz4eLjm4xUVSHOz+wjo3KPmmtc07EOoOgDr9wSsg584tIg+VHNkLLLMbomozVJH8b+fJKIYv+pX45DRqB/qwYHADfNydc/ak8ddg5yewfxHcumFtMzlApbZQfzCUf8q6ArWIyB1oM9QHpAAkAgfPRzNofijRCSlU8vNk8dAg/Lxcc/7EKYkQtg5+nQ/ndv7V7l3qv1eF+umqkIjcVo5shnrp0iXGjRt327k+MTExvPLKK1y5kg0ryopInlA70IdVzzXGz8uF41fi6PbFTs5ey4XH1p1crXOEhmyEUaHQ6Hlw9YGYc/DD2/BRNVjeF05s01whEblvmQ5A06dPJzY29raJytvbm5s3bzJ9+vRsLU5E7KuiXyGCRzShdFF3Lty4RfeZuwiLyMUHHopVhrZT4eVj0GUWlGpiXVTx6HfwVTfrekI/TYPYiNyrSUQeCpm+BVa9enVmzpxJs2bNbvv5zp07GT58OH/88Ue2FmgPugUmkl7kzUQGzA3l6OWbeLk6Mn9wQ+qVLmynYo7CvgXw2zJIjLa2mRygcjvrXKFyT1mfNBORAidH5gB5eHgQFhZGqVKlbvv5uXPnqFKlCvHx+X9lVwUgkYxiElIYsnAv+87ewM3JgS/71+PxSsXsV1DKLTiy1hqGzu36q92nFNQdaJ0rVMjfbuWJSO7LkTlAbm5uhIeH3/Hz8PBw3NzcMl2kiOQv3u5OLB7akMcrFeNWShpDF+5lw+92vPXk5Aa1noEhm+D53RA0Aly9IfocfD/FOldoRT84GaIFFkUkg0wHoKCgIBYvXnzHzxctWkTDhg2zpSgRyZvcnR2ZM6A+T9cIICXNYPTS/azYe87eZUHxKtDuPetcoc4zIbARWFIh7FtY0hU+/e/eYzf1oIaIWGX6FtgPP/xAq1atGDNmDK+88gp+fn4AXLlyhffff59PPvmELVu28NRTT+VowblBt8BE7i7NYvB/a35nWeh5AP7V/lGefby8nav6mytH/jtXaLl17zHg/9u78/ioqvv/46+ZyQokYQnZSCBhkZ2ENUBYJRVQQ2lVoF+URdFWEUG0FmxFhWq0FkWFAkUUlyrgWkDlJ8ayymYw7HsIW8hCICtkm5nfHwOBCCg4CTfJvJ+Px30Qztx75zNMyLxz7rnnYHZzrE7feQw07a+xQiI1TKXNAzR//nwmTpxISUkJvr6+mEwmcnJycHd357XXXuPhhx92uviqQAFI5JfZ7XZeWrmP+WuSAXikXzP+PLBl1VsUufgc7PnCEYaOb77UXrcJdB4NUfeCT6Bh5YlIxanUiRBPnjzJ0qVLOXToEHa7nVtuuYW7776b0NBQp4quShSARK7f3NWHeXnlPgBGRjdm+m/bYTFXsRB0UfpuSHz3yl6hVnc4eoUi+qlXSKQa00zQTlIAErkxH24+xl+/2IndDnGRIcy8JxIPtyocJIrPwe7PHb1CJ7Zcaq8XfukOsjoBRlUnIr9SpQagrKwsGjRoAMDx48dZsGAB58+fJy4ujj59+vz6qqsQBSCRG7d8eyqTlyZRYrXTr2VD5o7sjLdHNVi7K22XmhSLAwAAIABJREFUIwjtWAJFFyZ5NLtf1ivUV71CItVEpQSgnTt3EhcXx/Hjx2nRogWLFy9m0KBBFBQUYDabKSgo4JNPPmHo0KEV8iKMpAAk8uus3p/Bnz5IpLDERtfwerw1uit+3u5Gl3V9igsu6xXaeqm9XsSlsUJ1DJz3SER+UaUEoMGDB+Pm5saUKVN4//33WbFiBQMHDmTBggUATJgwgcTERDZt2uT8KzCYApDIr/dDyhnGLtpKXmEpbYJ9eff+bjT08TS6rBuTttMxVuinvUKt73T0CoX3Ua+QSBVUKQHI39+f7777jg4dOpCfn4+vry9bt26lc+fOAOzbt4/u3buTnZ3t/CswmAKQiHP2pOYy6u3NnM4vJsK/Nu8/0I3QerWMLuvGFRfArs8cvUInf7jUXr+pY6xQ1Ej1ColUIZUSgMxmM2lpaQQEOAYG+vj4sH37dpo2bQo45gMKCQnBaq3+qzMrAIk478jpAu59azMns88T7OfF+w9E0zygjtFl/XppO+GHd2DHUijOc7SV9QqNhfDeNa9XyHbh57m5GozlEqESA1B6ejoNGzp+2/Hx8WHHjh1EREQACkAicqVTOee5b+EWDmXkU7+2B++O7Ub7UD+jy3JOcQHs+vRCr1Dipfb6TR2Xx6JGQm3/in1Oux1KCx1bSSGUnofSIsd6aOXaL3594fHS89fXfsXxF57DVgoWDwhsC8GREBwFIVEQ0AbcqtllTXEJlRaABg8ejKen45t++fLl3HrrrdSuXRuAoqIiVq5cqQAkIuWcKShmzDtb2HEihzqebiwY1YUezRoYXVbFOLXjwh1kP+0VioPmsWAruSyo/JpAcvHxQkNf5hXM7o7lR0KiHKEoOMoRkty9jK5MXFylBKCxY8de15O/884717Xf5ebMmcMrr7xCWloakZGRvPnmm9dcV2zRokVX1OLp6Ulh4aUfEHa7nWeffZYFCxaQnZ1NTEwMc+fOpUWLFtdVjwKQSMXKLyrlwXd/YGNyFh5uZv71f52IbVODZl8uyr/UK5S6rXKfy2QGN29H2HDzdvTEuHuDm5djc/e6xtcX9i079irtVzumMBtObYfUJDiV5Pj6/Nkr6zK7QcPWjp6ikMtCkUc1HPsllefcGUhZD0fWQtuhEN6rQk9frSZCXLJkCaNGjWLevHlER0cza9YsPv74Y/bv31823uhyixYtYuLEiezfv7+szWQyla1NBvDyyy8THx/Pu+++S0REBM888ww7d+5kz549eHn98m8oCkAiFa+wxMqEj35k1Z50LGYT/7ynA7/rWHNmkC9zajtsew+yDv182Lie9rJAclnQsRg8rYDdDtnHLoWhi8HoXNaV+5os0LDlhV6iC8EoqD141L75dYsxigvg2EZIXgNH1jh6TbkQO7o/AoPiK/TpqlUAio6OpmvXrsyePRsAm81GWFgYEyZMYMqUKVfsv2jRIiZNmnTNu83sdjshISE88cQTPPnkkwDk5OQQGBjIokWLGDFixC/WpAAkUjlKrTae+nQHn207CcDzQ9oyume4sUWJ8+x2yD1ZvpcoNQkKMq7c12QG/1vKjykKag+ePje/bql4pcWOOyaPrHWEnhNbHZeCL+ffEpr2dVwqjqjYCZRv5PPbrUKf+QYVFxeTmJjI1KlTy9rMZjOxsbFs3Ljxmsfl5+fTpEkTbDYbnTp14sUXX6Rt27YAHDlyhLS0NGJjY8v29/PzIzo6mo0bN15XABKRyuFmMfPPuyPx9XJn0fcpPLtsN9nnSnhsQPOqt4iqXD+TCfxCHVvrOx1tdjvknbry8lneKcjc59h2LLl4AmjQ/MKlswvBKLgDeFXzAfOuwGaDtB2O3p0ja+HoRigpKL+PX5hjRvWmfR13S/oGG1PrTxgagE6fPo3Vai13+QogMDCQffv2XfWYli1b8vbbb9OhQwdycnL45z//Sc+ePdm9ezehoaGkpaWVneOn57z42E8VFRVRVFRU9vfc3FxnXpaI/Ayz2cSzcW2oV8uD1749wGvfHiD7fDHP3NEGc1VdRFVunMkEviGOreXgS+156VdePss9CVkHHdvOjy/tW7/ppV6i4EjH5l3v5r8WucRud1zeTV7tCD0p668cE1argaNn52LoqRfh+H6oYgwNQL9Gjx496NGjR9nfe/bsSevWrZk/fz4zZsz4VeeMj4/n+eefr6gSReQXmEwmJsa2wNfbjeeX7+GdDSnkni/l5bva42apYXPpSHk+geAzEG4ZeKktP9MRiE79eCEYbYecY3Am2bHt/uzSvvXCy18+C46CWvVv+stwKTknLl3SOrIW8lLLP+7hA+Exl0JPQJtqMSeWoQHI398fi8VCenp6ufb09HSCgoKu6xzu7u507NiRQ4cOAZQdl56eTnDwpW629PR0oqKirnqOqVOnMnny5LK/5+bmEhYWdkOvRURu3NiYCPy83fnzJzv4dNsJcgtLePMPHfFy18R7LqVOQ2gR69guKsiCtJ9cPjubcmnb899L+/o1hpALPUTBHR3BqKLnYnIlBVmQclngOXO4/OMWTwjr5ujdiegLIR2NH5z/KxgagDw8POjcuTMJCQlli6jabDYSEhJ49NFHr+scVquVnTt3cvvttwMQERFBUFAQCQkJZYEnNzeXzZs38/DDD1/1HJ6enmXzG4nIzfX7TqH4eLkz/sNtrNqTzqi3t/DGiI4E+WlOGZdWuwE0u9WxXXT+7IWeosuC0ZlkR29RzjHYu/zSvr6Nyl8+C2oPdYKqRc/ETVeU5xi7c2SNI/Sk7yz/uMnsCDkXL2mFRTvuSKzmDL8LbMmSJYwePZr58+fTrVs3Zs2axdKlS9m3bx+BgYGMGjWKRo0aER/vuFVu+vTpdO/enebNm5Odnc0rr7zCF198QWJiIm3atAEct8G/9NJL5W6D37Fjh26DF6nCNh7O4sH3fiC/qJR6tdx5+a4O3Nb2+nqCxYUV5jhurb58XFHWIcputb6c2Q18QsCvkSMgXfzz8q9r+df8kFRaBMe3OHp3jqxxzGhuKy2/T0AbR+CJ6OO4vFVNBqRXm7vAAIYPH05mZibTpk0jLS2NqKgoVq5cWTaI+dixY5gv+2Y8e/YsDz74IGlpadSrV4/OnTvz/fffl4UfgKeeeoqCggIeeughsrOz6dWrFytXrryu8CMixujRrAH/fTSGiYt/ZNfJXB56P5GR0Y352x1t8PbQJTG5Bi8/iOjt2C4qynOs3Xb55bPTBxwf8hd7i67F4nFh8Hao488rQlKoY8xRFRzUe002q+Pf4eIlrWObHLOMX65uk0uXtCL6QJ0r5+GraQzvAaqK1AMkYpziUhszV+1n/ppkAJoH1OH1EVG0Dakev4FKFWUthfw0yE11DOrNPQk5Jx1/Xvw6P52r9hz9lJvXhZDUyHHrf7mvGzn+7l3PuJBktzumGbg4cDllPRTllN+ndoAj6DS9EHjqhRtSakWrVhMhVkUKQCLG23DoNJOXJpGeW4SHxcxTg1pyf0yEbpWXymMtccxT9NNglHvyQmhKvfrkjlfjXutSGLoYjH7am1SRl5XOHr10SevI2gth7jKefo5lJy6Gnoatqlcv1nVSAHKSApBI1XC2oJi/fLqDb/Y4fpj3buHPzHsiCfDV5WwxSGmRIwjlnrx2b9LVlgW5Gg+fa1xmu6xn6VozZOdnXgg7FwLP2ZTyj7t5QePuFy5p9XUMBLcYPuql0ikAOUkBSKTqsNvtfLjlGDNW7KGwxEb92h68cncHBrSuQYupSs1Scv5SSMo5CbkXeo8u700qvPpyTlfw9LsQii5cZrN4wNENkLGn/H4mCzTqfGkcT2hXxzpyLkYByEkKQCJVz6GMPB77KIk9pxwztY/q0YSnb2+tOYOkeiouKN+DdEVvUuqV43Z+KrD9pUtaTXpqPTUUgJymACRSNRWVWnll5X7eWn8EgFsC6/D6iI60Dtb/U6mBivKuHI9UnO/o6Ynoo8ker0IByEkKQCJV29oDmTzx8XYy84rwcDMzdXArxvQM14KqIi7uRj6/a/hsTyJSE/W5pSErJ/ZmQKsAikttPL98D2MXbSUzr+iXDxYRQQFIRKqpBnU8eWt0F6b/ti2ebmZW789k8Otr+d++67xNWURcmgKQiFRbJpOJUT3CWT6hF62CfDidX8zYRVt5btluCkusRpcnIlWYApCIVHu3BPrwxfgYxsaEA7Do+xSGztnA/rQ8YwsTkSpLAUhEagQvdwvPxrXlnbFd8a/jwb60PIbMXs97G1PQvR4i8lMKQCJSo/RvGcDXE/vQr2VDikptTPvvbsa9+wNZ+RogLSKXKACJSI3T0MeTd8Z05dm4Nni4mUnYl8Gg19ex9kCm0aWJSBWhACQiNZLJZGJsTAT/HR9Di4A6ZOYVMertLcxYsYeiUg2QFnF1CkAiUqO1DvZl+YRejOrRBICF648wdM73HMrQAGkRV6YAJCI1npe7hem/bcfC0V2oX9uDvadyufPN9Xyw6agGSIu4KAUgEXEZA1oHsnJib3q38KewxMbfvtjFQ+8ncqag2OjSROQmUwASEZcS4OvFu2O78bc7WuNhMbNqTzqDZq1l/cHTRpcmIjeRApCIuByz2cS43k35fHxPmjWsTUZeEfcu3Ez8V3spLrUZXZ6I3AQKQCListqG+LFiQm9GRjcGYP7aZH4/dwOHM/MNrkxEKpsCkIi4NG8PCy/8rj3z7+tM3Vru7DqZy51vrGfxlmMaIC1SgykAiYgAA9sG8f8m9SGmeQPOl1iZ8tlOHv5gG9nnNEBapCZSABIRuSDQ14v3749m6uBWuFtMrNydxqBZ6/j+sAZIi9Q0CkAiIpcxm038sW8zPns4hqb+tUnLLWTkW5t5eeU+SqwaIC1SUygAiYhcRftQP1Y81osRXcOw22Hu6sPcNfd7jpwuMLo0EakACkAiItdQy8ONl+7qwNyRnfDzdmfHiRzueGMdS384rgHSItWcApCIyC8Y3D6YlZN6071pfc4VW3nqkx08+uGP5JwrMbo0EfmVFIBERK5DsJ83/xnXnacGtcTNbOLLnacY/PpaNidnGV2aiPwKCkAiItfJYjbxSL/mfPpwT8Ib1CI1p5A/LNjEP//ffg2QFqlmFIBERG5QZFhdvnysN/d0DsVmh9n/O8Q98zZyNEsDpEWqCwUgEZFfobanG6/cE8ns/+uIj5cbScezuf31dXyaeEIDpEWqAQUgEREn3NkhhJWT+tAtvD4FxVae+Hg7ExcnkVuoAdIiVZkCkIiIkxrV9eajh7rzxG9uwWI2sWx7KoNeW8u3e9KNLk1ErkEBSESkAljMJiYMaMHHf+pB4/qOAdLj3vuBh977gdTs80aXJyI/oQAkIlKBOjWux8pJvflT32a4mU18syed2FfXsGBtsu4UE6lCFIBERCpYLQ83pgxuxZeP9aZLk3qcK7bywld7iXtzPduOnTW6PBFBAUhEpNK0DPJh6R978I+7OlC3ljv70vK4a+73PP35Ts0iLWIwBSARkUpkNpsY1jWM757ox92dQ7Hb4cPNx7h15mo+/1G3zIsYRQFIROQmqF/bg3/eE8nih7rTPKAOWQXFPL5kO/+3YDOHM/ONLk/E5SgAiYjcRN2bNuCrx3rz1KCWeLmb2ZicxeBZ63j1m/0UlliNLk/EZSgAiYjcZB5uZh7p15xVj/elX8uGFFttvPHdIQbOWsvaA5lGlyfiEhSAREQMEla/Fu+M6crckZ0I9PXkaNY5Rr29hUc/3EZGbqHR5YnUaApAIiIGMplMDG4fTMIT/bg/JgKzCVbsOMWAmWt49/sUrDYNkhapDCa7bkG4Qm5uLn5+fuTk5ODr62t0OSLiQnadzOGvn+9k+4kcADqE+vHC0Pa0D/UzuDKRqu9GPr+rRA/QnDlzCA8Px8vLi+joaLZs2XJdxy1evBiTycTQoUPLtY8ZMwaTyVRuGzRoUGWULiJSodo18uOzR2KYMbQdPl5u7DiRw2/nrOe5ZbvJ0wKrIhXG8AC0ZMkSJk+ezLPPPsu2bduIjIxk4MCBZGRk/OxxKSkpPPnkk/Tu3fuqjw8aNIhTp06VbR999FFllC8iUuEsZhP3dW9CwhN9+W1UCDY7LPo+hQEz1/DljlOaO0ikAhgegF599VUefPBBxo4dS5s2bZg3bx61atXi7bffvuYxVquVkSNH8vzzz9O0adOr7uPp6UlQUFDZVq9evcp6CSIilSLAx4vXR3TkgweiifCvTUZeEeM/3MaYd7ZyNKvA6PJEqjVDA1BxcTGJiYnExsaWtZnNZmJjY9m4ceM1j5s+fToBAQE88MAD19xn9erVBAQE0LJlSx5++GGysrKuuW9RURG5ubnlNhGRqqJXC3++ntibiQNa4GExs+ZAJre9tpbZ3x2kqFRzB4n8GoYGoNOnT2O1WgkMDCzXHhgYSFpa2lWPWb9+PQsXLmTBggXXPO+gQYN47733SEhI4OWXX2bNmjUMHjwYq/XqPyji4+Px8/Mr28LCwn79ixIRqQRe7hYe/80trJzUm5jmDSgqtfHPbw5w++vr2Hj42r/gicjVGX4J7Ebk5eVx3333sWDBAvz9/a+534gRIxgyZAjt27dn6NChrFixgq1bt7J69eqr7j916lRycnLKtuPHj1fSKxARcU7ThnX44IFoXh8RhX8dDw5nFvCHBZuYvDSJrPwio8sTqTbcjHxyf39/LBYL6enp5drT09MJCgq6Yv/Dhw+TkpJCXFxcWZvNZgPAzc2N/fv306xZsyuOa9q0Kf7+/hw6dIgBAwZc8binpyeenp7OvhwRkZvCZDLx26hG9LslgFe+2cd/Nh/js20nSdibwdTBrRjWJQyz2WR0mSJVmqE9QB4eHnTu3JmEhISyNpvNRkJCAj169Lhi/1atWrFz506SkpLKtiFDhtC/f3+SkpKueenqxIkTZGVlERwcXGmvRUTkZvOr5c7fh7bns4d70ibYl5zzJUz5bCf3zN/IvjSNZRT5OYb2AAFMnjyZ0aNH06VLF7p168asWbMoKChg7NixAIwaNYpGjRoRHx+Pl5cX7dq1K3d83bp1Acra8/Pzef7557nrrrsICgri8OHDPPXUUzRv3pyBAwfe3BcnInITdGxcj2WPxvDuxqO8+s1+Eo+e5Y431jOuVwQTY1tQy8PwH/UiVY7h/yuGDx9OZmYm06ZNIy0tjaioKFauXFk2MPrYsWOYzdffUWWxWNixYwfvvvsu2dnZhISEcNtttzFjxgxd5hKRGsvNYuaBXhHc3j6I6cv38PWuNOavTWbFjlM8N6Qtv2kT+MsnEXEhWgrjKrQUhohUd9/tS2faf3dz4ux5AH7TJpDnhrSlUV1vgysTqTzVbikMERGpWLe2CmTV4315uF8z3MwmVu1JJ3bmGv699jAlVpvR5YkYTgFIRKSG8vaw8JdBrfhqYm+6htfjfImVF7/aR9yb60k8esbo8kQMpQAkIlLD3RLow5KHevCPuztQr5Y7+9LyuGvuRqZ+toPsc8VGlydiCAUgEREXYDabGNYljIQn+jGsSygAH205zoCZa/hs2wktsCouRwFIRMSF1K/twT/ujmTpH3vQIqAOWQXFTF66nT8s2MShjHyjyxO5aRSARERcULeI+nz5WG/+MqgVXu5mNiWfYfDra5n5zX4KS7TAqtR8CkAiIi7Kw83Mw/2aserxvtzaKoASq503vzvEba+tZc2BTKPLE6lUCkAiIi4urH4tFo7uwrx7OxHk68WxM+cY/fYWxn+4jfTcQqPLE6kUmgjxKjQRooi4qvyiUl5bdYB3NhzBZodaHhaGdQnj/pgIGjeoZXR5Ij/rRj6/FYCuQgFIRFzdrpM5/O2LXSQdzwbAbIKBbYMY1zuCzk3qG1ydyNUpADlJAUhEBOx2O+sPnWbBuiOsvWxMUMfGdRnXqykD2wbiZtFICqk6FICcpAAkIlLe/rQ8Fq5P5osfUym+sJRGaD1vxsZEMKxLKD5e7gZXKKIA5DQFIBGRq8vMK+L9TUf5YNNRzhQ4ZpH28XRjRLcwxsREaLFVMZQCkJMUgEREfl5hiZXPtp3krfXJJGcWAGAxm7ijfTDjekfQIbSuwRWKK1IAcpICkIjI9bHZ7Kw+kMGCtUfYmJxV1t4tvD7jekcwoHUgFrPJwArFlSgAOUkBSETkxu06mcPb64+wbHsqpTbHR0t4g1rc3yuCuzuHUsvDzeAKpaZTAHKSApCIyK+XllPIuxtT+M+mo+QWlgLg5+3OyOjGjO4ZTqCvl7EFSo2lAOQkBSAREecVFJXySeIJFq4/wrEz5wBwt5iIiwxhXK+mtAnRz1epWApATlIAEhGpOFabnVV70lm4PpmtKWfL2mOaN2Bcr6b0vaUhZo0TkgqgAOQkBSARkcqRdDybt9Yl8/WuNKwXxgk1D6jDA70i+F3HRni5WwyuUKozBSAnKQCJiFSuE2fPsWhDCou3Hie/yDFOqEFtD+7t3oT7ejTBv46nwRVKdaQA5CQFIBGRmyOvsIQlW4/zzoYUTmafB8DDzczvOzbigV4RtAj0MbhCqU4UgJykACQicnOVWm18vSuNt9Yls/1ETll7v5YNGderKTHNG2AyaZyQ/DwFICcpAImIGMNut/PD0bO8tS6Zb/akc/ETqlWQD+N6NyUuMhhPN40TkqtTAHKSApCIiPGOZhXw9vojLP3hBOdLrAAE+Hgyumc4I6MbU7eWh8EVSlWjAOQkBSARkaoj51wJ/9lylHe/TyE9twgAb3cLd3cO5f5eEUT41za4QqkqFICcpAAkIlL1FJfaWLEjlbfWHWHPqVwATCaIbR3IuF4RdIuor3FCLk4ByEkKQCIiVZfdbmdjchZvrTvCd/syyto7hPrxQK8Ibm8fjLvFbGCFYhQFICcpAImIVA+HMvJ5e8MRPk08QVGpDYAQPy/GxIQzoltjfL3cDa5QbiYFICcpAImIVC9Z+UV8sOkY729K4XR+MQC1PSwM79qYsTHhhNWvZXCFcjMoADlJAUhEpHoqLLGyLCmVt9YncyA9HwCzCQa1C+KRfs1p18jP4AqlMikAOUkBSESkerPb7aw9eJq31iWz7uDpsvb+LRvy6K0t6NyknoHVSWVRAHKSApCISM2xLy2XeasPs2x7KhfWX6VnswY8emtzejTVDNM1iQKQkxSARERqnpTTBcxdfZhPt52g9EIS6tS4LhNubUG/lg0VhGoABSAnKQCJiNRcJ7PPM3/NYRZvPU7xhTvH2ob4MuHW5tzWJgizWUGoulIAcpICkIhIzZeRW8hb64/wwaajnCt2LLXRIqAO4/s3584OwbhpLqFqRwHISQpAIiKu40xBMe9sOMKiDSnkFZUC0KRBLR7p14zfdQzFw01BqLpQAHKSApCIiOvJLSzh/Y1HeWtdMmfPlQCOSRX/2LcZw7uG4eWuVeirOgUgJykAiYi4rnPFpXy4+Rjz1yaTmedYfNW/jicP9YlgZHQTanu6GVyhXIsCkJMUgEREpLDEyseJJ5i3+jAns88DULeWOw/ERDCqZzh+3lpmo6pRAHKSApCIiFxUYrXx+Y8n+df/DpGSdQ4AH083RvVswv0xETSo42lwhXKRApCTFIBEROSnrDY7K3akMud/h8qW2fB2tzAyujEP9mlKoK+XwRWKApCTFIBERORabDY7q/amM/u7Q+w8mQOAh8XMsK6h/LFPMy28aqAb+fyuEvf2zZkzh/DwcLy8vIiOjmbLli3XddzixYsxmUwMHTq0XLvdbmfatGkEBwfj7e1NbGwsBw8erIzSRUTExZjNJga2DWLZozEsGtuVLk3qUWy18cGmY/T/52r+/PF2kjPzjS5TfoHhAWjJkiVMnjyZZ599lm3bthEZGcnAgQPJyMj42eNSUlJ48skn6d279xWP/eMf/+CNN95g3rx5bN68mdq1azNw4EAKCwsr62WIiIiLMZlM9GsZwMd/6sHih7rTq7k/pTY7HyeeIPbVNUz46Ef2peUaXaZcg+GXwKKjo+natSuzZ88GwGazERYWxoQJE5gyZcpVj7FarfTp04f777+fdevWkZ2dzRdffAE4en9CQkJ44oknePLJJwHIyckhMDCQRYsWMWLEiF+sSZfARETk19h27CxzvjtEwr5Lv8Tf1iaQR29tTofQugZW5hqqzSWw4uJiEhMTiY2NLWszm83ExsaycePGax43ffp0AgICeOCBB6547MiRI6SlpZU7p5+fH9HR0dc8Z1FREbm5ueU2ERGRG9WpcT0WjunKl4/14o72wZhM8M2edIbM3sDot7ewNeWM0SXKBYYGoNOnT2O1WgkMDCzXHhgYSFpa2lWPWb9+PQsXLmTBggVXffzicTdyzvj4ePz8/Mq2sLCwG30pIiIiZdqG+DFnZCdWPd6H33dshMVsYs2BTO6Zt5Hh8zey/uBpdA+SsQwfA3Qj8vLyuO+++1iwYAH+/v4Vdt6pU6eSk5NTth0/frzCzi0iIq6reYAPrw6P4n9P9OMP3RrjbjGx+cgZ7l24md/963u+3ZOuIGQQQ+fz9vf3x2KxkJ6eXq49PT2doKCgK/Y/fPgwKSkpxMXFlbXZbDYA3Nzc2L9/f9lx6enpBAcHlztnVFTUVevw9PTE01MTWYmISOVo3KAW8b9vz2MDmjN/TTIfbTlG0vFsxr33A62DfXm0f3MGtQvCYjYZXarLMLQHyMPDg86dO5OQkFDWZrPZSEhIoEePHlfs36pVK3bu3ElSUlLZNmTIEPr3709SUhJhYWFEREQQFBRU7py5ubls3rz5qucUERG5WYL9vHluSFvW/+VW/tS3GbU9LOw9lcv4D7dx22tr+GzbCUqtNqPLdAmGr+g2efJkRo8eTZcuXejWrRuzZs2ioKCAsWPHAjBq1CgaNWpEfHw8Xl5etGvXrtzxdes6RtVf3j5p0iT+/ve/06JFCyIiInjmmWcICQm5Yr4gERERIzT08WTK4Fb8qW9T3tmQwjtNIZAoAAAOVElEQVQbjnA4s4DJS7fz2rcHeLhvc+7q3AhPN61AX1kMD0DDhw8nMzOTadOmkZaWRlRUFCtXriwbxHzs2DHM5hvrqHrqqacoKCjgoYceIjs7m169erFy5Uq8vDRNuYiIVB11a3nw+G9uYVzvCD7YdIy31iVz/Mx5nv58J28kHOSPfZsyomtjvD0UhCqa4fMAVUWaB0hERIxwvtjKR1uOMX/tYdJziwBoUNuDcb2bcl+PJtTxNLzfokrTWmBOUgASEREjFZVa+STxBHNXH+bE2fMA+Hm7M6ZnOMO6htGorrfBFVZNCkBOUgASEZGqoMRqY1lSKnNWHyI5s6CsvXOTegyJDOH29sE09NFdzBcpADlJAUhERKoSq83O17tO8f7Go2xJOcPFT26zCXo282dIZAgD2wbhV8vd2EINpgDkJAUgERGpqtJyCvly5ymWbU9l+/HssnZ3i4m+tzQkLjKE2NaB1HbB8UIKQE5SABIRkergWNY5lu9IZfn2VPal5ZW1e7tbGNA6gLjIEPq1bOgyt9MrADlJAUhERKqbA+l5LN+eyrLtqRzNOlfW7uPlxsC2QQyJDKFnswa4WarVKlg3RAHISQpAIiJSXdntdnaezGFZUiordpwiLbew7LEGtT24vX0wcZEhdGlSD3MNW3pDAchJCkAiIlIT2Gx2tqacYfmOVL7amcaZguKyx4L9vLizQzBDIhvRrpEvJlP1D0MKQE5SABIRkZqm1Gpjw+EsliWl8s3uNPKKSssei/CvTVwHR89Qi0AfA6t0jgKQkxSARESkJisssbJ6fybLd6SSsDedwpJLC7C2CvIhLjKEuA4hNG5Qy8Aqb5wCkJMUgERExFUUFJXy7d50liWlsvZgJiXWS7EgKqwuQyJDuKNDMIG+VX89TQUgJykAiYiIK8o+V8zKXWks35HKxsNZ2C4kBJMJukc0IC4yhMHtgqhX28PYQq9BAchJCkAiIuLqMvIK+WrHKZbvOEXi0bNl7W5mE71b+BMXGcJtbYOq1AKtCkBOUgASERG55PiZc47Zp5NS2XMqt6zd083Mra0CGBIZQv9WAXi5GzvhogKQkxSAREREru5QRj7Ltztmn04+fWmB1jqebtzWJpC4yBB6tfDH3YAJFxWAnKQAJCIi8vPsdju7U3NZviOVFdtPcTL7fNljdWu5M7hdMEMiQ+gWUR/LTZpwUQHISQpAIiIi189ms/Pj8bMsS0rly52nOJ1/acLFAB9P7uwQQlxkMFFhdSt1wkUFICcpAImIiPw6pVYbm5LPsHx7Kl/vOkVu4aUJF8PqexPXIYQhUSG0DPSp8DCkAOQkBSARERHnFZVaWXfgNMu2p7JqTzrnS6xlj43oGsZLd3Wo0Oe7kc/vqnPvmoiIiNQonm4WYtsEEtsmkHPFpSTszWD59lRW78+kU+N6htamACQiIiKVrpaHm2OJjcgQcs6X4GHAXWKXUwASERGRm8rP293oEjA2fomIiIgYQAFIREREXI4CkIiIiLgcBSARERFxOQpAIiIi4nIUgERERMTlKACJiIiIy1EAEhEREZejACQiIiIuRwFIREREXI4CkIiIiLgcBSARERFxOQpAIiIi4nK0GvxV2O12AHJzcw2uRERERK7Xxc/ti5/jP0cB6Cry8vIACAsLM7gSERERuVF5eXn4+fn97D4m+/XEJBdjs9lITU3Fx8cHk8lUoefOzc0lLCyM48eP4+vrW6Hnlhun96Nq0ftRtej9qFr0fvwyu91OXl4eISEhmM0/P8pHPUBXYTabCQ0NrdTn8PX11TdwFaL3o2rR+1G16P2oWvR+/Lxf6vm5SIOgRURExOUoAImIiIjLsTz33HPPGV2Eq7FYLPTr1w83N12BrAr0flQtej+qFr0fVYvej4qjQdAiIiLicnQJTERERFyOApCIiIi4HAUgERERcTkKQCIiIuJyFIBuojlz5hAeHo6XlxfR0dFs2bLF6JJcUnx8PF27dsXHx4eAgACGDh3K/v37jS5LLnjppZcwmUxMmjTJ6FJc2smTJ7n33ntp0KAB3t7etG/fnh9++MHoslyS1WrlmWeeISIiAm9vb5o1a8aMGTOua70ruTYFoJtkyZIlTJ48mWeffZZt27YRGRnJwIEDycjIMLo0l7NmzRrGjx/Ppk2bWLVqFSUlJdx2220UFBQYXZrL27p1K/Pnz6dDhw5Gl+LSzp49S0xMDO7u7nz99dfs2bOHmTNnUq9ePaNLc0kvv/wyc+fOZfbs2ezdu5eXX36Zf/zjH7z55ptGl1at6Tb4myQ6OpquXbsye/ZswLHeWFhYGBMmTGDKlCkGV+faMjMzCQgIYM2aNfTp08foclxWfn4+nTp14l//+hd///vfiYqKYtasWUaX5ZKmTJnChg0bWLdundGlCHDnnXcSGBjIwoULy9ruuusuvL29+eCDDwysrHpTD9BNUFxcTGJiIrGxsWVtZrOZ2NhYNm7caGBlApCTkwNA/fr1Da7EtY0fP5477rij3P8TMcayZcvo0qUL99xzDwEBAXTs2JEFCxYYXZbL6tmzJwkJCRw4cACA7du3s379egYPHmxwZdWbppK8CU6fPo3VaiUwMLBce2BgIPv27TOoKgFHT9ykSZOIiYmhXbt2RpfjshYvXsy2bdvYunWr0aUIkJyczNy5c5k8eTJPP/00W7du5bHHHsPDw4PRo0cbXZ7LmTJlCrm5ubRq1QqLxYLVauWFF15g5MiRRpdWrSkAiUsbP348u3btYv369UaX4rKOHz/OxIkTWbVqFV5eXkaXIzh+MejSpQsvvvgiAB07dmTXrl3MmzdPAcgAS5cu5T//+Q8ffvghbdu2JSkpiUmTJhESEqL3wwkKQDeBv78/FouF9PT0cu3p6ekEBQUZVJU8+uijrFixgrVr1xIaGmp0OS4rMTGRjIwMOnXqVNZmtVpZu3Yts2fPpqioCIvFYmCFric4OJg2bdqUa2vdujWffvqpQRW5tj//+c9MmTKFESNGANC+fXuOHj1KfHy8ApATNAboJvDw8KBz584kJCSUtdlsNhISEujRo4eBlbkmu93Oo48+yueff853331HRESE0SW5tAEDBrBz506SkpLKti5dujBy5EiSkpIUfgwQExNzxdQQBw4coEmTJgZV5NrOnTuH2Vz+49pisWCz2QyqqGZQD9BNMnnyZEaPHk2XLl3o1q0bs2bNoqCggLFjxxpdmssZP348H374If/973/x8fEhLS0NAD8/P7y9vQ2uzvX4+PhcMf6qdu3aNGjQQOOyDPL444/Ts2dPXnzxRYYNG8aWLVv497//zb///W+jS3NJcXFxvPDCCzRu3Ji2bdvy448/8uqrr3L//fcbXVq1ptvgb6LZs2fzyiuvkJaWRlRUFG+88QbR0dFGl+VyTCbTVdvfeecdxowZc3OLkavq16+fboM32IoVK5g6dSoHDx4kIiKCyZMn8+CDDxpdlkvKy8vjmWee4fPPPycjI4OQkBD+8Ic/MG3aNDw8PIwur9pSABIRERGXozFAIiIi4nIUgERERMTlKACJiIiIy1EAEhEREZejACQiIiIuRwFIREREXI4CkIiIiLgcBSARkeuwevVqTCYT2dnZRpciIhVAAUhERERcjgKQiIiIuBwFIBGpFmw2G/Hx8URERODt7U1kZCSffPIJcOny1JdffkmHDh3w8vKie/fu7Nq1q9w5Pv30U9q2bYunpyfh4eHMnDmz3ONFRUX85S9/ISwsDE9PT5o3b87ChQvL7ZOYmEiXLl2oVasWPXv2vGLVdBGpHhSARKRaiI+P57333mPevHns3r2bxx9/nHvvvZc1a9aU7fPnP/+ZmTNnsnXrVho2bEhcXBwlJSWAI7gMGzaMESNGsHPnTp577jmeeeYZFi1aVHb8qFGj+Oijj3jjjTfYu3cv8+fPp06dOuXq+Otf/8rMmTP54YcfcHNz04rcItWUFkMVkSqvqKiI+vXr8+2339KjR4+y9nHjxnHu3Dkeeugh+vfvz+LFixk+fDgAZ86cITQ0lEWLFjFs2DBGjhxJZmYm33zzTdnxTz31FF9++SW7d+/mwIEDtGzZklWrVhEbG3tFDatXr6Z///58++23DBgwAICvvvqKO+64g/Pnz+Pl5VXJ/woiUpHUAyQiVd6hQ4c4d+4cv/nNb6hTp07Z9t5773H48OGy/S4PR/Xr16dly5bs3bsXgL179xITE1PuvDExMRw8eBCr1UpSUhIWi4W+ffv+bC0dOnQo+zo4OBiAjIwMp1+jiNxcbkYXICLyS/Lz8wH48ssvadSoUbnHPD09y4WgX8vb2/u69nN3dy/72mQyAY7xSSJSvagHSESqvDZt2uDp6cmxY8do3rx5uS0sLKxsv02bNpV9ffbsWQ4cOEDr1q0BaN26NRs2bCh33g0bNnDLLbdgsVho3749Nput3JgiEam51AMkIlWej48PTz75JI8//jg2m41evXqRk5PDhg0b8PX1pUmTJgBMnz6dBg0aEBgYyF//+lf8/f0ZOnQoAE888QRdu3ZlxowZDB8+nI0bNzJ79mz+9a9/ARAeHs7o0aO5//77eeONN4iMjOTo0aNkZGQwbNgww167iFQOBSARqRZmzJhBw4YNiY+PJzk5mbp169KpUyeefvrpsktQL730EhMnTuTgwYNERUWxfPlyPDw8AOjUqRNLly5l2rRpzJgxg+DgYKZPn86YMWPKnmPu3Lk8/fTTPPLII2RlZdG4cWOefvppI16uiFQy3QUmItXexTu0zp49S926dY0uR0SqAY0BEhEREZejACQiIiIuR5fARERExOWoB0hERERcjgKQiIiIuBwFIBEREXE5CkAiIiLichSARERExOUoAImIiIjLUQASERERl6MAJCIiIi5HAUhERERczv8HB12tr+OnXPoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучалась, но произошло переобучение, нужно попробовать уменьшить размер эмбеддинга для слов (в смысле предложений, в смысле не символов); в первой части дз это помогло спастись от переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новый экземпляр модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_II_1 = Sym_Word_CNN(len(symbol2id), len(word2id), 5, 5)\n",
    "optimizer_II_1 = optim.Adam(model_II_1.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model_II_1 = model_II_1.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем процесс обучения и эвалюации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting Epoch 0\n",
      "Training...\n",
      "Train loss: 0.767481803894043\n",
      "Train loss: 0.7266309893492496\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "f1s = []\n",
    "f1s_eval = []\n",
    "accuracies = []\n",
    "accuracies_eval = []\n",
    "precisions = []\n",
    "precisions_eval = []\n",
    "recalls = []\n",
    "recalls_eval = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    print('Training...')\n",
    "    epoch_loss = train_II(model_II_1, train_iterator, optimizer_II_1, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "    print('\\nEvaluating on train...')\n",
    "    f1_on_train, accuracy_on_train, precision_on_train, recall_on_train,_ = evaluate_II(model_II_1, train_iterator, criterion)\n",
    "    f1s.append(f1_on_train)\n",
    "    accuracies.append(accuracy_on_train)\n",
    "    precisions.append(precision_on_train)\n",
    "    recalls.append(recall_on_train)\n",
    "    print('\\nEvaluating on test...')\n",
    "    f1_on_test, accuracy_on_test, precision_on_test, recall_on_test, epoch_loss_on_test = evaluate_II(model_II_1, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)\n",
    "    f1s_eval.append(f1_on_test)\n",
    "    accuracies_eval.append(accuracy_on_test)\n",
    "    precisions_eval.append(precision_on_test)\n",
    "    recalls_eval.append(recall_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses, '\\n\\n', losses_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, действительно, помогло. С таким размером эмбеддинга переобучение не происходит"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ещё одна попытка улучшения модели\n",
    "\n",
    "Можно попробовать кроме размера эмбеддинга менять ещё количество фильтров на сверточном слое. Я не уверена, что это ощутимо улучшит модель, но возможно появятся какие-то изменения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sym_Word_CNN_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, sym_vocab_size, word_vocab_size, sym_embedding_dim, word_embedding_dim):\n",
    "        \n",
    "        super().__init__()          \n",
    "        # указываем в атрибутах класса, какие слои и активации нам понадобятся\n",
    "        self.embedding_word = nn.Embedding(word_vocab_size, word_embedding_dim)\n",
    "        self.linear_words = nn.Linear(in_features=word_embedding_dim, out_features=100)\n",
    "        \n",
    "        self.embedding_sym = nn.Embedding(sym_vocab_size, sym_embedding_dim)\n",
    "        self.bigrams = nn.Conv1d(in_channels=sym_embedding_dim, out_channels=60, kernel_size=2, padding='same')\n",
    "        self.trigrams = nn.Conv1d(in_channels=sym_embedding_dim, out_channels=100, kernel_size=3, padding='same')\n",
    "        self.linear_sym = nn.Linear(in_features=160, out_features=100)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden = nn.Linear(in_features=200, out_features=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self, sym_texts, word_texts): #необходимый метод,  в нем указываем, как именно связываются слои/активации между собой\n",
    "        embedded_words = self.embedding_word(word_texts)   \n",
    "        mean_embedded_words = torch.mean(embedded_words, dim=1)\n",
    "        vec_words = self.dropout(self.relu(self.linear_words(mean_embedded_words)))\n",
    "        \n",
    "        embedded_sym = self.embedding_sym(sym_texts)\n",
    "        embedded_sym = embedded_sym.transpose(1,2)\n",
    "        feature_map_bigrams = self.dropout(self.relu(self.bigrams(embedded_sym)))\n",
    "        feature_map_trigrams = self.dropout(self.relu(self.trigrams(embedded_sym)))\n",
    "        pooling_bi = feature_map_bigrams.max(2)[0]\n",
    "        pooling_tri = feature_map_trigrams.max(2)[0]\n",
    "        concat_sym = torch.cat((pooling_bi, pooling_tri), 1)\n",
    "        vec_sym = self.linear_sym(concat_sym)\n",
    "        \n",
    "        concat = torch.cat((vec_words, vec_sym), 1)\n",
    "        logits = self.hidden(concat) \n",
    "        logits = self.out(logits)      \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем экземпляр новой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_II_2 = Sym_Word_CNN_2(len(symbol2id), len(word2id), 5, 5)\n",
    "optimizer_II_2 = optim.Adam(model_II_2.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# веса модели и значения лосса храним там же, где и все остальные тензоры\n",
    "model_II_2 = model_II_2.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение и эвалюацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_eval = []\n",
    "f1s = []\n",
    "f1s_eval = []\n",
    "accuracies = []\n",
    "accuracies_eval = []\n",
    "precisions = []\n",
    "precisions_eval = []\n",
    "recalls = []\n",
    "recalls_eval = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'\\nstarting Epoch {i}')\n",
    "    print('Training...')\n",
    "    epoch_loss = train_II(model_II_2, train_iterator, optimizer_II_2, criterion)\n",
    "    losses.append(epoch_loss)\n",
    "    print('\\nEvaluating on train...')\n",
    "    f1_on_train, accuracy_on_train, precision_on_train, recall_on_train,_ = evaluate_II(model_II_2, train_iterator, criterion)\n",
    "    f1s.append(f1_on_train)\n",
    "    accuracies.append(accuracy_on_train)\n",
    "    precisions.append(precision_on_train)\n",
    "    recalls.append(recall_on_train)\n",
    "    print('\\nEvaluating on test...')\n",
    "    f1_on_test, accuracy_on_test, precision_on_test, recall_on_test, epoch_loss_on_test = evaluate_II(model_II_2, val_iterator, criterion)\n",
    "    losses_eval.append(epoch_loss_on_test)\n",
    "    f1s_eval.append(f1_on_test)\n",
    "    accuracies_eval.append(accuracy_on_test)\n",
    "    precisions_eval.append(precision_on_test)\n",
    "    recalls_eval.append(recall_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses, '\\n\\n', losses_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(losses_eval)\n",
    "plt.title('BCE loss value')\n",
    "plt.ylabel('BCE loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказания\n",
    "\n",
    "Делаем предсказания на тестовой выборке, и пытаемся немного проанализировать false positive и false negative результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, iterator):\n",
    "    model.eval()\n",
    "    fp = []\n",
    "    fn = []\n",
    "    tp = [] \n",
    "    tn = []\n",
    "    with torch.no_grad():\n",
    "        for i, (sym_texts, words_texts, ys) in enumerate(iterator):   \n",
    "            preds = model(sym_texts, words_texts)  # делаем предсказания на тесте \n",
    "            for pred, gold, text in zip(preds, ys, texts):\n",
    "                text = ' '.join([id2word[int(word)] for word in text if word !=0])\n",
    "                if round(pred.item()) > gold:\n",
    "                    fp.append(text)\n",
    "                elif round(pred.item()) < gold:\n",
    "                    fn.append(text)\n",
    "                elif round(pred.item()) == gold == 1:\n",
    "                    tp.append(text)\n",
    "                elif round(pred.item()) == gold == 0:\n",
    "                    tn.append(text)\n",
    "    return fp, fn, tp, tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp, fn, tp, tn = predict(model_II_2, val_iterator)\n",
    "\n",
    "print('True positive: \\n', tp[:20], '\\n\\n')\n",
    "print('True negative: \\n', tn[:20], '\\n\\n')\n",
    "print('False positive: \\n', fp[:20], '\\n\\n')\n",
    "print('False negative: \\n', fn[:20], '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Небольшой итог\n",
    "\n",
    "В целом, оба варианта моделей обучаются, с помощью работы с гиперпараметрами (такими как количество фильтров и размер эмбеддингов) удалось избежать переобучений. \n",
    "Получилось посмотреть на некоторые предсказания. Можно предположить то, что некоторые позитивные твиты могут считываться моделью как негативные в тех случаях, когда в них присутствует частица \"не\" или какие-то негативно эмоциональные слова. И, наоборот, негативные твиты могут восприниматься как позитивные, когда в них присутствуют слова с какой-то явно позитивной оценкой, вроде \"любить\", \"классно\" и тд. Это довольно очевидные вещи, но предсказания продемонстрировали это.\n",
    "\n",
    "Однако в целом, можно заметить, что всё-таки loss у всех полученных моделей довольно велик, и ещё есть что улучшать. Возможно, можно было ещё попробовать не делать препроцессинг текстов (не убирать пунктуацию, не приводить к нижнему регистру). Можно предположить, что это бы улучшило качество модели. И возможно, позволило бы посмотреть, влияют ли как-то на предсказания различные знаки препинания, типа смайликов из скобочек и тд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
